{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab12-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source - MultiRNNCell only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  3.21959\n",
      "1 loss:  3.1427\n",
      "2 loss:  3.0161\n",
      "3 loss:  2.93585\n",
      "4 loss:  2.90801\n",
      "5 loss:  2.89521\n",
      "6 loss:  2.90573\n",
      "7 loss:  2.891\n",
      "8 loss:  2.87821\n",
      "9 loss:  2.86735\n",
      "10 loss:  2.86547\n",
      "11 loss:  2.84691\n",
      "12 loss:  2.84233\n",
      "13 loss:  2.85622\n",
      "14 loss:  2.83622\n",
      "15 loss:  2.84968\n",
      "16 loss:  2.82588\n",
      "17 loss:  2.8073\n",
      "18 loss:  2.79617\n",
      "19 loss:  2.78655\n",
      "20 loss:  2.77728\n",
      "21 loss:  2.7648\n",
      "22 loss:  2.75336\n",
      "23 loss:  2.74358\n",
      "24 loss:  2.73742\n",
      "25 loss:  2.72619\n",
      "26 loss:  2.71844\n",
      "27 loss:  2.7118\n",
      "28 loss:  2.70446\n",
      "29 loss:  2.69736\n",
      "30 loss:  2.69145\n",
      "31 loss:  2.68528\n",
      "32 loss:  2.67837\n",
      "33 loss:  2.67154\n",
      "34 loss:  2.66644\n",
      "35 loss:  2.66173\n",
      "36 loss:  2.65722\n",
      "37 loss:  2.65392\n",
      "38 loss:  2.64863\n",
      "39 loss:  2.64522\n",
      "40 loss:  2.6417\n",
      "41 loss:  2.6384\n",
      "42 loss:  2.6349\n",
      "43 loss:  2.63188\n",
      "44 loss:  2.62859\n",
      "45 loss:  2.62148\n",
      "46 loss:  2.62002\n",
      "47 loss:  2.61169\n",
      "48 loss:  2.60781\n",
      "49 loss:  2.60522\n",
      "50 loss:  2.59728\n",
      "51 loss:  2.59465\n",
      "52 loss:  2.59137\n",
      "53 loss:  2.58485\n",
      "54 loss:  2.58136\n",
      "55 loss:  2.5757\n",
      "56 loss:  2.5733\n",
      "57 loss:  2.56726\n",
      "58 loss:  2.56678\n",
      "59 loss:  2.5628\n",
      "60 loss:  2.55996\n",
      "61 loss:  2.55711\n",
      "62 loss:  2.55429\n",
      "63 loss:  2.55093\n",
      "64 loss:  2.54994\n",
      "65 loss:  2.54754\n",
      "66 loss:  2.54422\n",
      "67 loss:  2.54239\n",
      "68 loss:  2.54031\n",
      "69 loss:  2.53723\n",
      "70 loss:  2.53335\n",
      "71 loss:  2.53019\n",
      "72 loss:  2.52485\n",
      "73 loss:  2.52661\n",
      "74 loss:  2.51871\n",
      "75 loss:  2.51901\n",
      "76 loss:  2.51499\n",
      "77 loss:  2.51282\n",
      "78 loss:  2.5098\n",
      "79 loss:  2.50592\n",
      "80 loss:  2.50382\n",
      "81 loss:  2.50062\n",
      "82 loss:  2.49679\n",
      "83 loss:  2.49405\n",
      "84 loss:  2.4899\n",
      "85 loss:  2.48751\n",
      "86 loss:  2.48528\n",
      "87 loss:  2.48283\n",
      "88 loss:  2.48089\n",
      "89 loss:  2.47835\n",
      "90 loss:  2.47503\n",
      "91 loss:  2.46948\n",
      "92 loss:  2.46596\n",
      "93 loss:  2.45917\n",
      "94 loss:  2.45089\n",
      "95 loss:  2.44789\n",
      "96 loss:  2.4488\n",
      "97 loss:  2.45293\n",
      "98 loss:  2.43935\n",
      "99 loss:  2.43335\n",
      "100 loss:  2.43226\n",
      "101 loss:  2.42695\n",
      "102 loss:  2.42494\n",
      "103 loss:  2.42195\n",
      "104 loss:  2.41775\n",
      "105 loss:  2.41263\n",
      "106 loss:  2.4109\n",
      "107 loss:  2.40835\n",
      "108 loss:  2.40561\n",
      "109 loss:  2.40229\n",
      "110 loss:  2.40019\n",
      "111 loss:  2.39848\n",
      "112 loss:  2.39548\n",
      "113 loss:  2.3934\n",
      "114 loss:  2.39118\n",
      "115 loss:  2.38898\n",
      "116 loss:  2.3868\n",
      "117 loss:  2.38498\n",
      "118 loss:  2.38372\n",
      "119 loss:  2.38211\n",
      "120 loss:  2.38035\n",
      "121 loss:  2.3789\n",
      "122 loss:  2.37746\n",
      "123 loss:  2.37615\n",
      "124 loss:  2.37468\n",
      "125 loss:  2.37327\n",
      "126 loss:  2.372\n",
      "127 loss:  2.3706\n",
      "128 loss:  2.36917\n",
      "129 loss:  2.36773\n",
      "130 loss:  2.3661\n",
      "131 loss:  2.36403\n",
      "132 loss:  2.36076\n",
      "133 loss:  2.35727\n",
      "134 loss:  2.35677\n",
      "135 loss:  2.35537\n",
      "136 loss:  2.35241\n",
      "137 loss:  2.35174\n",
      "138 loss:  2.35035\n",
      "139 loss:  2.34872\n",
      "140 loss:  2.3474\n",
      "141 loss:  2.34577\n",
      "142 loss:  2.34395\n",
      "143 loss:  2.34199\n",
      "144 loss:  2.33969\n",
      "145 loss:  2.33694\n",
      "146 loss:  2.33355\n",
      "147 loss:  2.3309\n",
      "148 loss:  2.32876\n",
      "149 loss:  2.32647\n",
      "150 loss:  2.32633\n",
      "151 loss:  2.32407\n",
      "152 loss:  2.32432\n",
      "153 loss:  2.32212\n",
      "154 loss:  2.32109\n",
      "155 loss:  2.31955\n",
      "156 loss:  2.31677\n",
      "157 loss:  2.31638\n",
      "158 loss:  2.31487\n",
      "159 loss:  2.31299\n",
      "160 loss:  2.31288\n",
      "161 loss:  2.31095\n",
      "162 loss:  2.30947\n",
      "163 loss:  2.30781\n",
      "164 loss:  2.30671\n",
      "165 loss:  2.30578\n",
      "166 loss:  2.30376\n",
      "167 loss:  2.30046\n",
      "168 loss:  2.29923\n",
      "169 loss:  2.29857\n",
      "170 loss:  2.29785\n",
      "171 loss:  2.29702\n",
      "172 loss:  2.29603\n",
      "173 loss:  2.29536\n",
      "174 loss:  2.2944\n",
      "175 loss:  2.29302\n",
      "176 loss:  2.29113\n",
      "177 loss:  2.28997\n",
      "178 loss:  2.28838\n",
      "179 loss:  2.28724\n",
      "180 loss:  2.28605\n",
      "181 loss:  2.28435\n",
      "182 loss:  2.28344\n",
      "183 loss:  2.28222\n",
      "184 loss:  2.28158\n",
      "185 loss:  2.28035\n",
      "186 loss:  2.27948\n",
      "187 loss:  2.27862\n",
      "188 loss:  2.27781\n",
      "189 loss:  2.27688\n",
      "190 loss:  2.27615\n",
      "191 loss:  2.27546\n",
      "192 loss:  2.27481\n",
      "193 loss:  2.27422\n",
      "194 loss:  2.27357\n",
      "195 loss:  2.27292\n",
      "196 loss:  2.27237\n",
      "197 loss:  2.27169\n",
      "198 loss:  2.27121\n",
      "199 loss:  2.27066\n",
      "200 loss:  2.27001\n",
      "201 loss:  2.26953\n",
      "202 loss:  2.2691\n",
      "203 loss:  2.26881\n",
      "204 loss:  2.2687\n",
      "205 loss:  2.26817\n",
      "206 loss:  2.26774\n",
      "207 loss:  2.26716\n",
      "208 loss:  2.26684\n",
      "209 loss:  2.26637\n",
      "210 loss:  2.26594\n",
      "211 loss:  2.26548\n",
      "212 loss:  2.26504\n",
      "213 loss:  2.26459\n",
      "214 loss:  2.26419\n",
      "215 loss:  2.26375\n",
      "216 loss:  2.26326\n",
      "217 loss:  2.26283\n",
      "218 loss:  2.26241\n",
      "219 loss:  2.26195\n",
      "220 loss:  2.26151\n",
      "221 loss:  2.26114\n",
      "222 loss:  2.2605\n",
      "223 loss:  2.25982\n",
      "224 loss:  2.25838\n",
      "225 loss:  2.25732\n",
      "226 loss:  2.25685\n",
      "227 loss:  2.25691\n",
      "228 loss:  2.25729\n",
      "229 loss:  2.2572\n",
      "230 loss:  2.25638\n",
      "231 loss:  2.25541\n",
      "232 loss:  2.25554\n",
      "233 loss:  2.25546\n",
      "234 loss:  2.25421\n",
      "235 loss:  2.25475\n",
      "236 loss:  2.2553\n",
      "237 loss:  2.25572\n",
      "238 loss:  2.25554\n",
      "239 loss:  2.25612\n",
      "240 loss:  2.25531\n",
      "241 loss:  2.25476\n",
      "242 loss:  2.25396\n",
      "243 loss:  2.25368\n",
      "244 loss:  2.2534\n",
      "245 loss:  2.25242\n",
      "246 loss:  2.25278\n",
      "247 loss:  2.25914\n",
      "248 loss:  2.25815\n",
      "249 loss:  2.25415\n",
      "250 loss:  2.25837\n",
      "251 loss:  2.25454\n",
      "252 loss:  2.25487\n",
      "253 loss:  2.25537\n",
      "254 loss:  2.25261\n",
      "255 loss:  2.25222\n",
      "256 loss:  2.2522\n",
      "257 loss:  2.25176\n",
      "258 loss:  2.25101\n",
      "259 loss:  2.25025\n",
      "260 loss:  2.24934\n",
      "261 loss:  2.2488\n",
      "262 loss:  2.24855\n",
      "263 loss:  2.24815\n",
      "264 loss:  2.24772\n",
      "265 loss:  2.24727\n",
      "266 loss:  2.24684\n",
      "267 loss:  2.24651\n",
      "268 loss:  2.24617\n",
      "269 loss:  2.24579\n",
      "270 loss:  2.24548\n",
      "271 loss:  2.24519\n",
      "272 loss:  2.24493\n",
      "273 loss:  2.24459\n",
      "274 loss:  2.2443\n",
      "275 loss:  2.24404\n",
      "276 loss:  2.24379\n",
      "277 loss:  2.24352\n",
      "278 loss:  2.24328\n",
      "279 loss:  2.24302\n",
      "280 loss:  2.2428\n",
      "281 loss:  2.24261\n",
      "282 loss:  2.2424\n",
      "283 loss:  2.24221\n",
      "284 loss:  2.24201\n",
      "285 loss:  2.24179\n",
      "286 loss:  2.2416\n",
      "287 loss:  2.24138\n",
      "288 loss:  2.24115\n",
      "289 loss:  2.24093\n",
      "290 loss:  2.24068\n",
      "291 loss:  2.24047\n",
      "292 loss:  2.24027\n",
      "293 loss:  2.24008\n",
      "294 loss:  2.2399\n",
      "295 loss:  2.23971\n",
      "296 loss:  2.23953\n",
      "297 loss:  2.23935\n",
      "298 loss:  2.23917\n",
      "299 loss:  2.23899\n",
      "300 loss:  2.23882\n",
      "301 loss:  2.23868\n",
      "302 loss:  2.23853\n",
      "303 loss:  2.23839\n",
      "304 loss:  2.23826\n",
      "305 loss:  2.23813\n",
      "306 loss:  2.238\n",
      "307 loss:  2.23789\n",
      "308 loss:  2.23781\n",
      "309 loss:  2.23766\n",
      "310 loss:  2.23758\n",
      "311 loss:  2.23744\n",
      "312 loss:  2.23735\n",
      "313 loss:  2.23725\n",
      "314 loss:  2.23715\n",
      "315 loss:  2.23706\n",
      "316 loss:  2.23697\n",
      "317 loss:  2.23686\n",
      "318 loss:  2.23677\n",
      "319 loss:  2.23667\n",
      "320 loss:  2.23657\n",
      "321 loss:  2.23648\n",
      "322 loss:  2.23638\n",
      "323 loss:  2.23628\n",
      "324 loss:  2.23619\n",
      "325 loss:  2.2361\n",
      "326 loss:  2.23601\n",
      "327 loss:  2.23591\n",
      "328 loss:  2.23582\n",
      "329 loss:  2.23573\n",
      "330 loss:  2.23564\n",
      "331 loss:  2.23556\n",
      "332 loss:  2.23548\n",
      "333 loss:  2.2354\n",
      "334 loss:  2.23532\n",
      "335 loss:  2.23524\n",
      "336 loss:  2.23517\n",
      "337 loss:  2.23509\n",
      "338 loss:  2.23501\n",
      "339 loss:  2.23494\n",
      "340 loss:  2.23485\n",
      "341 loss:  2.23477\n",
      "342 loss:  2.23469\n",
      "343 loss:  2.23461\n",
      "344 loss:  2.23453\n",
      "345 loss:  2.23445\n",
      "346 loss:  2.23436\n",
      "347 loss:  2.23429\n",
      "348 loss:  2.2342\n",
      "349 loss:  2.23412\n",
      "350 loss:  2.23403\n",
      "351 loss:  2.23393\n",
      "352 loss:  2.23382\n",
      "353 loss:  2.23371\n",
      "354 loss:  2.23358\n",
      "355 loss:  2.23346\n",
      "356 loss:  2.23338\n",
      "357 loss:  2.23325\n",
      "358 loss:  2.23306\n",
      "359 loss:  2.23311\n",
      "360 loss:  2.23395\n",
      "361 loss:  2.23455\n",
      "362 loss:  2.23508\n",
      "363 loss:  2.23487\n",
      "364 loss:  2.23461\n",
      "365 loss:  2.23419\n",
      "366 loss:  2.23386\n",
      "367 loss:  2.23352\n",
      "368 loss:  2.23344\n",
      "369 loss:  2.23313\n",
      "370 loss:  2.23286\n",
      "371 loss:  2.2327\n",
      "372 loss:  2.23247\n",
      "373 loss:  2.23244\n",
      "374 loss:  2.23224\n",
      "375 loss:  2.23196\n",
      "376 loss:  2.23184\n",
      "377 loss:  2.23174\n",
      "378 loss:  2.2316\n",
      "379 loss:  2.23141\n",
      "380 loss:  2.2313\n",
      "381 loss:  2.23118\n",
      "382 loss:  2.23109\n",
      "383 loss:  2.231\n",
      "384 loss:  2.23086\n",
      "385 loss:  2.23076\n",
      "386 loss:  2.23065\n",
      "387 loss:  2.23055\n",
      "388 loss:  2.23046\n",
      "389 loss:  2.23037\n",
      "390 loss:  2.23027\n",
      "391 loss:  2.23018\n",
      "392 loss:  2.23009\n",
      "393 loss:  2.23001\n",
      "394 loss:  2.22993\n",
      "395 loss:  2.22984\n",
      "396 loss:  2.22974\n",
      "397 loss:  2.22962\n",
      "398 loss:  2.22932\n",
      "399 loss:  2.22834\n",
      "400 loss:  2.22985\n",
      "401 loss:  2.22916\n",
      "402 loss:  2.22973\n",
      "403 loss:  2.22973\n",
      "404 loss:  2.22975\n",
      "405 loss:  2.22976\n",
      "406 loss:  2.22971\n",
      "407 loss:  2.22961\n",
      "408 loss:  2.22947\n",
      "409 loss:  2.22971\n",
      "410 loss:  2.23007\n",
      "411 loss:  2.22977\n",
      "412 loss:  2.22987\n",
      "413 loss:  2.22993\n",
      "414 loss:  2.23062\n",
      "415 loss:  2.23134\n",
      "416 loss:  2.23089\n",
      "417 loss:  2.23069\n",
      "418 loss:  2.23134\n",
      "419 loss:  2.2311\n",
      "420 loss:  2.2319\n",
      "421 loss:  2.23179\n",
      "422 loss:  2.23151\n",
      "423 loss:  2.23126\n",
      "424 loss:  2.23138\n",
      "425 loss:  2.23113\n",
      "426 loss:  2.23076\n",
      "427 loss:  2.23032\n",
      "428 loss:  2.23041\n",
      "429 loss:  2.23036\n",
      "430 loss:  2.2301\n",
      "431 loss:  2.22998\n",
      "432 loss:  2.22986\n",
      "433 loss:  2.23005\n",
      "434 loss:  2.23058\n",
      "435 loss:  2.2315\n",
      "436 loss:  2.23101\n",
      "437 loss:  2.23186\n",
      "438 loss:  2.23215\n",
      "439 loss:  2.24624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 loss:  2.24791\n",
      "441 loss:  2.24762\n",
      "442 loss:  2.25653\n",
      "443 loss:  2.25809\n",
      "444 loss:  2.25534\n",
      "445 loss:  2.26445\n",
      "446 loss:  2.26154\n",
      "447 loss:  2.26647\n",
      "448 loss:  2.25947\n",
      "449 loss:  2.25643\n",
      "450 loss:  2.26102\n",
      "451 loss:  2.25691\n",
      "452 loss:  2.25376\n",
      "453 loss:  2.2517\n",
      "454 loss:  2.25293\n",
      "455 loss:  2.25157\n",
      "456 loss:  2.24936\n",
      "457 loss:  2.24635\n",
      "458 loss:  2.24542\n",
      "459 loss:  2.24434\n",
      "460 loss:  2.24303\n",
      "461 loss:  2.24235\n",
      "462 loss:  2.24177\n",
      "463 loss:  2.24019\n",
      "464 loss:  2.23936\n",
      "465 loss:  2.23917\n",
      "466 loss:  2.23842\n",
      "467 loss:  2.23732\n",
      "468 loss:  2.23606\n",
      "469 loss:  2.23289\n",
      "470 loss:  2.22842\n",
      "471 loss:  2.2342\n",
      "472 loss:  2.22546\n",
      "473 loss:  2.22638\n",
      "474 loss:  2.22518\n",
      "475 loss:  2.22208\n",
      "476 loss:  2.21916\n",
      "477 loss:  2.21709\n",
      "478 loss:  2.21429\n",
      "479 loss:  2.21374\n",
      "480 loss:  2.21139\n",
      "481 loss:  2.21017\n",
      "482 loss:  2.2094\n",
      "483 loss:  2.20766\n",
      "484 loss:  2.20647\n",
      "485 loss:  2.20479\n",
      "486 loss:  2.20376\n",
      "487 loss:  2.20247\n",
      "488 loss:  2.20166\n",
      "489 loss:  2.20103\n",
      "490 loss:  2.20039\n",
      "491 loss:  2.19968\n",
      "492 loss:  2.19893\n",
      "493 loss:  2.19837\n",
      "494 loss:  2.19785\n",
      "495 loss:  2.19732\n",
      "496 loss:  2.19689\n",
      "497 loss:  2.19623\n",
      "498 loss:  2.19579\n",
      "499 loss:  2.19533\n",
      "500 loss:  2.19495\n",
      "501 loss:  2.19454\n",
      "502 loss:  2.1941\n",
      "503 loss:  2.19367\n",
      "504 loss:  2.19324\n",
      "505 loss:  2.19294\n",
      "506 loss:  2.19259\n",
      "507 loss:  2.19231\n",
      "508 loss:  2.19201\n",
      "509 loss:  2.19178\n",
      "510 loss:  2.19157\n",
      "511 loss:  2.19132\n",
      "512 loss:  2.19108\n",
      "513 loss:  2.19094\n",
      "514 loss:  2.19075\n",
      "515 loss:  2.19061\n",
      "516 loss:  2.19048\n",
      "517 loss:  2.19031\n",
      "518 loss:  2.19011\n",
      "519 loss:  2.18999\n",
      "520 loss:  2.18979\n",
      "521 loss:  2.18964\n",
      "522 loss:  2.18945\n",
      "523 loss:  2.18929\n",
      "524 loss:  2.18912\n",
      "525 loss:  2.18896\n",
      "526 loss:  2.18885\n",
      "527 loss:  2.18873\n",
      "528 loss:  2.18862\n",
      "529 loss:  2.18845\n",
      "530 loss:  2.18837\n",
      "531 loss:  2.18825\n",
      "532 loss:  2.18812\n",
      "533 loss:  2.18801\n",
      "534 loss:  2.18786\n",
      "535 loss:  2.18772\n",
      "536 loss:  2.18758\n",
      "537 loss:  2.18743\n",
      "538 loss:  2.18735\n",
      "539 loss:  2.18727\n",
      "540 loss:  2.1872\n",
      "541 loss:  2.18709\n",
      "542 loss:  2.18699\n",
      "543 loss:  2.18687\n",
      "544 loss:  2.18676\n",
      "545 loss:  2.18664\n",
      "546 loss:  2.18651\n",
      "547 loss:  2.18636\n",
      "548 loss:  2.18622\n",
      "549 loss:  2.18616\n",
      "550 loss:  2.18609\n",
      "551 loss:  2.186\n",
      "552 loss:  2.18584\n",
      "553 loss:  2.18561\n",
      "554 loss:  2.18549\n",
      "555 loss:  2.18541\n",
      "556 loss:  2.18532\n",
      "557 loss:  2.1852\n",
      "558 loss:  2.18506\n",
      "559 loss:  2.18483\n",
      "560 loss:  2.18366\n",
      "561 loss:  2.18288\n",
      "562 loss:  2.1831\n",
      "563 loss:  2.18302\n",
      "564 loss:  2.1828\n",
      "565 loss:  2.18264\n",
      "566 loss:  2.18244\n",
      "567 loss:  2.18229\n",
      "568 loss:  2.18218\n",
      "569 loss:  2.18212\n",
      "570 loss:  2.18203\n",
      "571 loss:  2.18197\n",
      "572 loss:  2.18188\n",
      "573 loss:  2.1818\n",
      "574 loss:  2.18175\n",
      "575 loss:  2.1817\n",
      "576 loss:  2.18166\n",
      "577 loss:  2.18158\n",
      "578 loss:  2.18152\n",
      "579 loss:  2.18147\n",
      "580 loss:  2.18141\n",
      "581 loss:  2.18137\n",
      "582 loss:  2.18131\n",
      "583 loss:  2.18126\n",
      "584 loss:  2.18122\n",
      "585 loss:  2.18117\n",
      "586 loss:  2.18113\n",
      "587 loss:  2.18108\n",
      "588 loss:  2.18103\n",
      "589 loss:  2.18098\n",
      "590 loss:  2.18094\n",
      "591 loss:  2.1809\n",
      "592 loss:  2.18087\n",
      "593 loss:  2.18084\n",
      "594 loss:  2.18081\n",
      "595 loss:  2.18077\n",
      "596 loss:  2.18074\n",
      "597 loss:  2.18071\n",
      "598 loss:  2.18069\n",
      "599 loss:  2.18067\n",
      "600 loss:  2.18064\n",
      "601 loss:  2.18061\n",
      "602 loss:  2.18059\n",
      "603 loss:  2.18056\n",
      "604 loss:  2.18054\n",
      "605 loss:  2.18051\n",
      "606 loss:  2.18048\n",
      "607 loss:  2.18045\n",
      "608 loss:  2.18042\n",
      "609 loss:  2.18039\n",
      "610 loss:  2.18036\n",
      "611 loss:  2.18033\n",
      "612 loss:  2.1803\n",
      "613 loss:  2.18027\n",
      "614 loss:  2.18024\n",
      "615 loss:  2.18021\n",
      "616 loss:  2.18018\n",
      "617 loss:  2.18016\n",
      "618 loss:  2.18013\n",
      "619 loss:  2.18011\n",
      "620 loss:  2.18008\n",
      "621 loss:  2.18006\n",
      "622 loss:  2.18004\n",
      "623 loss:  2.18002\n",
      "624 loss:  2.18\n",
      "625 loss:  2.17998\n",
      "626 loss:  2.17996\n",
      "627 loss:  2.17994\n",
      "628 loss:  2.17992\n",
      "629 loss:  2.1799\n",
      "630 loss:  2.17988\n",
      "631 loss:  2.17987\n",
      "632 loss:  2.17985\n",
      "633 loss:  2.17983\n",
      "634 loss:  2.17982\n",
      "635 loss:  2.1798\n",
      "636 loss:  2.17979\n",
      "637 loss:  2.17977\n",
      "638 loss:  2.17975\n",
      "639 loss:  2.17974\n",
      "640 loss:  2.17972\n",
      "641 loss:  2.17971\n",
      "642 loss:  2.17969\n",
      "643 loss:  2.17967\n",
      "644 loss:  2.17965\n",
      "645 loss:  2.17962\n",
      "646 loss:  2.1796\n",
      "647 loss:  2.17958\n",
      "648 loss:  2.17956\n",
      "649 loss:  2.17955\n",
      "650 loss:  2.17953\n",
      "651 loss:  2.17952\n",
      "652 loss:  2.1795\n",
      "653 loss:  2.17949\n",
      "654 loss:  2.17947\n",
      "655 loss:  2.17946\n",
      "656 loss:  2.17945\n",
      "657 loss:  2.17943\n",
      "658 loss:  2.17942\n",
      "659 loss:  2.1794\n",
      "660 loss:  2.17938\n",
      "661 loss:  2.17937\n",
      "662 loss:  2.17935\n",
      "663 loss:  2.17933\n",
      "664 loss:  2.17931\n",
      "665 loss:  2.1793\n",
      "666 loss:  2.17927\n",
      "667 loss:  2.17925\n",
      "668 loss:  2.17923\n",
      "669 loss:  2.17922\n",
      "670 loss:  2.1792\n",
      "671 loss:  2.17919\n",
      "672 loss:  2.17918\n",
      "673 loss:  2.17916\n",
      "674 loss:  2.17914\n",
      "675 loss:  2.17913\n",
      "676 loss:  2.17912\n",
      "677 loss:  2.1791\n",
      "678 loss:  2.17909\n",
      "679 loss:  2.17907\n",
      "680 loss:  2.17906\n",
      "681 loss:  2.17903\n",
      "682 loss:  2.17898\n",
      "683 loss:  2.17865\n",
      "684 loss:  2.17638\n",
      "685 loss:  2.17678\n",
      "686 loss:  2.17594\n",
      "687 loss:  2.17633\n",
      "688 loss:  2.17572\n",
      "689 loss:  2.17576\n",
      "690 loss:  2.1758\n",
      "691 loss:  2.17572\n",
      "692 loss:  2.17565\n",
      "693 loss:  2.17559\n",
      "694 loss:  2.17556\n",
      "695 loss:  2.17554\n",
      "696 loss:  2.17554\n",
      "697 loss:  2.17554\n",
      "698 loss:  2.17551\n",
      "699 loss:  2.17549\n",
      "700 loss:  2.17547\n",
      "701 loss:  2.17544\n",
      "702 loss:  2.17543\n",
      "703 loss:  2.17541\n",
      "704 loss:  2.17539\n",
      "705 loss:  2.17538\n",
      "706 loss:  2.17537\n",
      "707 loss:  2.17535\n",
      "708 loss:  2.17534\n",
      "709 loss:  2.17533\n",
      "710 loss:  2.17531\n",
      "711 loss:  2.1753\n",
      "712 loss:  2.17529\n",
      "713 loss:  2.17528\n",
      "714 loss:  2.17526\n",
      "715 loss:  2.17525\n",
      "716 loss:  2.17524\n",
      "717 loss:  2.17523\n",
      "718 loss:  2.17522\n",
      "719 loss:  2.17521\n",
      "720 loss:  2.1752\n",
      "721 loss:  2.17519\n",
      "722 loss:  2.17517\n",
      "723 loss:  2.17516\n",
      "724 loss:  2.17515\n",
      "725 loss:  2.17514\n",
      "726 loss:  2.17513\n",
      "727 loss:  2.17512\n",
      "728 loss:  2.17511\n",
      "729 loss:  2.17509\n",
      "730 loss:  2.17508\n",
      "731 loss:  2.17506\n",
      "732 loss:  2.17504\n",
      "733 loss:  2.175\n",
      "734 loss:  2.17498\n",
      "735 loss:  2.17497\n",
      "736 loss:  2.17494\n",
      "737 loss:  2.17493\n",
      "738 loss:  2.17492\n",
      "739 loss:  2.17491\n",
      "740 loss:  2.1749\n",
      "741 loss:  2.17488\n",
      "742 loss:  2.17487\n",
      "743 loss:  2.17486\n",
      "744 loss:  2.17486\n",
      "745 loss:  2.17485\n",
      "746 loss:  2.17486\n",
      "747 loss:  2.17482\n",
      "748 loss:  2.1748\n",
      "749 loss:  2.17478\n",
      "750 loss:  2.17477\n",
      "751 loss:  2.17475\n",
      "752 loss:  2.17474\n",
      "753 loss:  2.17473\n",
      "754 loss:  2.17471\n",
      "755 loss:  2.1747\n",
      "756 loss:  2.17469\n",
      "757 loss:  2.17468\n",
      "758 loss:  2.17467\n",
      "759 loss:  2.17466\n",
      "760 loss:  2.17465\n",
      "761 loss:  2.17464\n",
      "762 loss:  2.17463\n",
      "763 loss:  2.17462\n",
      "764 loss:  2.17462\n",
      "765 loss:  2.17462\n",
      "766 loss:  2.17462\n",
      "767 loss:  2.17466\n",
      "768 loss:  2.17459\n",
      "769 loss:  2.17457\n",
      "770 loss:  2.17458\n",
      "771 loss:  2.17461\n",
      "772 loss:  2.17478\n",
      "773 loss:  2.17479\n",
      "774 loss:  2.17486\n",
      "775 loss:  2.17492\n",
      "776 loss:  2.17485\n",
      "777 loss:  2.17482\n",
      "778 loss:  2.17481\n",
      "779 loss:  2.17475\n",
      "780 loss:  2.17474\n",
      "781 loss:  2.17478\n",
      "782 loss:  2.17469\n",
      "783 loss:  2.17464\n",
      "784 loss:  2.1747\n",
      "785 loss:  2.17462\n",
      "786 loss:  2.17463\n",
      "787 loss:  2.17466\n",
      "788 loss:  2.17454\n",
      "789 loss:  2.17459\n",
      "790 loss:  2.17474\n",
      "791 loss:  2.17453\n",
      "792 loss:  2.17498\n",
      "793 loss:  2.17628\n",
      "794 loss:  2.17635\n",
      "795 loss:  2.17655\n",
      "796 loss:  2.17593\n",
      "797 loss:  2.1771\n",
      "798 loss:  2.17949\n",
      "799 loss:  2.18027\n",
      "800 loss:  2.19064\n",
      "801 loss:  2.20912\n",
      "802 loss:  2.22671\n",
      "803 loss:  2.26454\n",
      "804 loss:  2.25913\n",
      "805 loss:  2.27961\n",
      "806 loss:  2.27857\n",
      "807 loss:  2.27906\n",
      "808 loss:  2.27276\n",
      "809 loss:  2.25695\n",
      "810 loss:  2.24761\n",
      "811 loss:  2.24303\n",
      "812 loss:  2.24704\n",
      "813 loss:  2.24443\n",
      "814 loss:  2.24006\n",
      "815 loss:  2.24118\n",
      "816 loss:  2.23284\n",
      "817 loss:  2.23817\n",
      "818 loss:  2.2327\n",
      "819 loss:  2.22952\n",
      "820 loss:  2.22956\n",
      "821 loss:  2.22552\n",
      "822 loss:  2.22989\n",
      "823 loss:  2.22624\n",
      "824 loss:  2.22524\n",
      "825 loss:  2.2212\n",
      "826 loss:  2.22244\n",
      "827 loss:  2.21796\n",
      "828 loss:  2.21446\n",
      "829 loss:  2.21187\n",
      "830 loss:  2.21018\n",
      "831 loss:  2.20963\n",
      "832 loss:  2.208\n",
      "833 loss:  2.20464\n",
      "834 loss:  2.20523\n",
      "835 loss:  2.20268\n",
      "836 loss:  2.20069\n",
      "837 loss:  2.19907\n",
      "838 loss:  2.19764\n",
      "839 loss:  2.19655\n",
      "840 loss:  2.19501\n",
      "841 loss:  2.19413\n",
      "842 loss:  2.1933\n",
      "843 loss:  2.19238\n",
      "844 loss:  2.19135\n",
      "845 loss:  2.1904\n",
      "846 loss:  2.1894\n",
      "847 loss:  2.18856\n",
      "848 loss:  2.18778\n",
      "849 loss:  2.18729\n",
      "850 loss:  2.18659\n",
      "851 loss:  2.18612\n",
      "852 loss:  2.18577\n",
      "853 loss:  2.18544\n",
      "854 loss:  2.18503\n",
      "855 loss:  2.18459\n",
      "856 loss:  2.18417\n",
      "857 loss:  2.18372\n",
      "858 loss:  2.18334\n",
      "859 loss:  2.18294\n",
      "860 loss:  2.18264\n",
      "861 loss:  2.18232\n",
      "862 loss:  2.18207\n",
      "863 loss:  2.18178\n",
      "864 loss:  2.18153\n",
      "865 loss:  2.18132\n",
      "866 loss:  2.18109\n",
      "867 loss:  2.18087\n",
      "868 loss:  2.18064\n",
      "869 loss:  2.18046\n",
      "870 loss:  2.18027\n",
      "871 loss:  2.1801\n",
      "872 loss:  2.17993\n",
      "873 loss:  2.17977\n",
      "874 loss:  2.17963\n",
      "875 loss:  2.1795\n",
      "876 loss:  2.17937\n",
      "877 loss:  2.17925\n",
      "878 loss:  2.17913\n",
      "879 loss:  2.17899\n",
      "880 loss:  2.1788\n",
      "881 loss:  2.17864\n",
      "882 loss:  2.17852\n",
      "883 loss:  2.1784\n",
      "884 loss:  2.17826\n",
      "885 loss:  2.17825\n",
      "886 loss:  2.17816\n",
      "887 loss:  2.17808\n",
      "888 loss:  2.17792\n",
      "889 loss:  2.17779\n",
      "890 loss:  2.17769\n",
      "891 loss:  2.17767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892 loss:  2.17752\n",
      "893 loss:  2.17741\n",
      "894 loss:  2.17737\n",
      "895 loss:  2.17733\n",
      "896 loss:  2.17729\n",
      "897 loss:  2.17718\n",
      "898 loss:  2.17717\n",
      "899 loss:  2.17715\n",
      "900 loss:  2.17715\n",
      "901 loss:  2.17701\n",
      "902 loss:  2.17697\n",
      "903 loss:  2.17687\n",
      "904 loss:  2.17682\n",
      "905 loss:  2.17681\n",
      "906 loss:  2.17671\n",
      "907 loss:  2.17672\n",
      "908 loss:  2.17661\n",
      "909 loss:  2.17662\n",
      "910 loss:  2.17655\n",
      "911 loss:  2.17648\n",
      "912 loss:  2.17652\n",
      "913 loss:  2.17649\n",
      "914 loss:  2.17655\n",
      "915 loss:  2.17644\n",
      "916 loss:  2.17637\n",
      "917 loss:  2.1763\n",
      "918 loss:  2.17624\n",
      "919 loss:  2.17623\n",
      "920 loss:  2.17617\n",
      "921 loss:  2.17609\n",
      "922 loss:  2.17604\n",
      "923 loss:  2.17598\n",
      "924 loss:  2.17588\n",
      "925 loss:  2.17587\n",
      "926 loss:  2.17583\n",
      "927 loss:  2.17576\n",
      "928 loss:  2.17571\n",
      "929 loss:  2.17567\n",
      "930 loss:  2.17558\n",
      "931 loss:  2.17552\n",
      "932 loss:  2.17544\n",
      "933 loss:  2.17531\n",
      "934 loss:  2.1752\n",
      "935 loss:  2.17516\n",
      "936 loss:  2.17511\n",
      "937 loss:  2.17508\n",
      "938 loss:  2.17506\n",
      "939 loss:  2.17501\n",
      "940 loss:  2.17497\n",
      "941 loss:  2.17494\n",
      "942 loss:  2.1749\n",
      "943 loss:  2.17487\n",
      "944 loss:  2.17484\n",
      "945 loss:  2.17481\n",
      "946 loss:  2.17478\n",
      "947 loss:  2.17474\n",
      "948 loss:  2.17471\n",
      "949 loss:  2.17468\n",
      "950 loss:  2.17464\n",
      "951 loss:  2.1746\n",
      "952 loss:  2.17457\n",
      "953 loss:  2.17453\n",
      "954 loss:  2.17449\n",
      "955 loss:  2.17444\n",
      "956 loss:  2.1744\n",
      "957 loss:  2.17436\n",
      "958 loss:  2.17432\n",
      "959 loss:  2.17428\n",
      "960 loss:  2.17423\n",
      "961 loss:  2.17417\n",
      "962 loss:  2.17413\n",
      "963 loss:  2.1741\n",
      "964 loss:  2.17407\n",
      "965 loss:  2.17403\n",
      "966 loss:  2.174\n",
      "967 loss:  2.17397\n",
      "968 loss:  2.17394\n",
      "969 loss:  2.17391\n",
      "970 loss:  2.17387\n",
      "971 loss:  2.17384\n",
      "972 loss:  2.1738\n",
      "973 loss:  2.17377\n",
      "974 loss:  2.17375\n",
      "975 loss:  2.17372\n",
      "976 loss:  2.1737\n",
      "977 loss:  2.17367\n",
      "978 loss:  2.17364\n",
      "979 loss:  2.17361\n",
      "980 loss:  2.17358\n",
      "981 loss:  2.17355\n",
      "982 loss:  2.17353\n",
      "983 loss:  2.17351\n",
      "984 loss:  2.17349\n",
      "985 loss:  2.17347\n",
      "986 loss:  2.17346\n",
      "987 loss:  2.17344\n",
      "988 loss:  2.17342\n",
      "989 loss:  2.1734\n",
      "990 loss:  2.17338\n",
      "991 loss:  2.17336\n",
      "992 loss:  2.17334\n",
      "993 loss:  2.17331\n",
      "994 loss:  2.17327\n",
      "995 loss:  2.17323\n",
      "996 loss:  2.17319\n",
      "997 loss:  2.17317\n",
      "998 loss:  2.17315\n",
      "999 loss:  2.17313\n",
      "1000 loss:  2.17311\n",
      "1001 loss:  2.17308\n",
      "1002 loss:  2.17306\n",
      "1003 loss:  2.17304\n",
      "1004 loss:  2.17302\n",
      "1005 loss:  2.173\n",
      "1006 loss:  2.17298\n",
      "1007 loss:  2.17296\n",
      "1008 loss:  2.17295\n",
      "1009 loss:  2.17293\n",
      "1010 loss:  2.17291\n",
      "1011 loss:  2.17289\n",
      "1012 loss:  2.17288\n",
      "1013 loss:  2.17286\n",
      "1014 loss:  2.17284\n",
      "1015 loss:  2.17282\n",
      "1016 loss:  2.17281\n",
      "1017 loss:  2.17279\n",
      "1018 loss:  2.17278\n",
      "1019 loss:  2.17276\n",
      "1020 loss:  2.17275\n",
      "1021 loss:  2.17274\n",
      "1022 loss:  2.17273\n",
      "1023 loss:  2.17272\n",
      "1024 loss:  2.17271\n",
      "1025 loss:  2.17269\n",
      "1026 loss:  2.17268\n",
      "1027 loss:  2.17267\n",
      "1028 loss:  2.17266\n",
      "1029 loss:  2.17265\n",
      "1030 loss:  2.17264\n",
      "1031 loss:  2.17263\n",
      "1032 loss:  2.17263\n",
      "1033 loss:  2.17262\n",
      "1034 loss:  2.17261\n",
      "1035 loss:  2.1726\n",
      "1036 loss:  2.17259\n",
      "1037 loss:  2.17258\n",
      "1038 loss:  2.17258\n",
      "1039 loss:  2.17257\n",
      "1040 loss:  2.17256\n",
      "1041 loss:  2.17255\n",
      "1042 loss:  2.17255\n",
      "1043 loss:  2.17254\n",
      "1044 loss:  2.17253\n",
      "1045 loss:  2.17252\n",
      "1046 loss:  2.17251\n",
      "1047 loss:  2.1725\n",
      "1048 loss:  2.17249\n",
      "1049 loss:  2.17248\n",
      "1050 loss:  2.17247\n",
      "1051 loss:  2.17246\n",
      "1052 loss:  2.17245\n",
      "1053 loss:  2.17244\n",
      "1054 loss:  2.17243\n",
      "1055 loss:  2.17242\n",
      "1056 loss:  2.17241\n",
      "1057 loss:  2.17239\n",
      "1058 loss:  2.17238\n",
      "1059 loss:  2.17237\n",
      "1060 loss:  2.17235\n",
      "1061 loss:  2.17234\n",
      "1062 loss:  2.17232\n",
      "1063 loss:  2.17231\n",
      "1064 loss:  2.1723\n",
      "1065 loss:  2.17229\n",
      "1066 loss:  2.17228\n",
      "1067 loss:  2.17227\n",
      "1068 loss:  2.17226\n",
      "1069 loss:  2.17225\n",
      "1070 loss:  2.17225\n",
      "1071 loss:  2.17224\n",
      "1072 loss:  2.17223\n",
      "1073 loss:  2.17222\n",
      "1074 loss:  2.17221\n",
      "1075 loss:  2.1722\n",
      "1076 loss:  2.17219\n",
      "1077 loss:  2.17217\n",
      "1078 loss:  2.17216\n",
      "1079 loss:  2.17215\n",
      "1080 loss:  2.17214\n",
      "1081 loss:  2.17213\n",
      "1082 loss:  2.17212\n",
      "1083 loss:  2.17211\n",
      "1084 loss:  2.1721\n",
      "1085 loss:  2.17209\n",
      "1086 loss:  2.17208\n",
      "1087 loss:  2.17207\n",
      "1088 loss:  2.17206\n",
      "1089 loss:  2.17205\n",
      "1090 loss:  2.17204\n",
      "1091 loss:  2.17203\n",
      "1092 loss:  2.17202\n",
      "1093 loss:  2.17201\n",
      "1094 loss:  2.172\n",
      "1095 loss:  2.17199\n",
      "1096 loss:  2.17199\n",
      "1097 loss:  2.17198\n",
      "1098 loss:  2.17197\n",
      "1099 loss:  2.17196\n",
      "1100 loss:  2.17196\n",
      "1101 loss:  2.17195\n",
      "1102 loss:  2.17194\n",
      "1103 loss:  2.17193\n",
      "1104 loss:  2.17193\n",
      "1105 loss:  2.17192\n",
      "1106 loss:  2.17191\n",
      "1107 loss:  2.1719\n",
      "1108 loss:  2.17189\n",
      "1109 loss:  2.17187\n",
      "1110 loss:  2.17186\n",
      "1111 loss:  2.17184\n",
      "1112 loss:  2.17181\n",
      "1113 loss:  2.17176\n",
      "1114 loss:  2.17167\n",
      "1115 loss:  2.17159\n",
      "1116 loss:  2.17155\n",
      "1117 loss:  2.17153\n",
      "1118 loss:  2.17152\n",
      "1119 loss:  2.17152\n",
      "1120 loss:  2.17151\n",
      "1121 loss:  2.17151\n",
      "1122 loss:  2.1715\n",
      "1123 loss:  2.17149\n",
      "1124 loss:  2.17149\n",
      "1125 loss:  2.17148\n",
      "1126 loss:  2.17147\n",
      "1127 loss:  2.17146\n",
      "1128 loss:  2.17144\n",
      "1129 loss:  2.17143\n",
      "1130 loss:  2.17142\n",
      "1131 loss:  2.17141\n",
      "1132 loss:  2.1714\n",
      "1133 loss:  2.17138\n",
      "1134 loss:  2.17136\n",
      "1135 loss:  2.17132\n",
      "1136 loss:  2.17127\n",
      "1137 loss:  2.17126\n",
      "1138 loss:  2.1713\n",
      "1139 loss:  2.17133\n",
      "1140 loss:  2.17133\n",
      "1141 loss:  2.17128\n",
      "1142 loss:  2.17118\n",
      "1143 loss:  2.1711\n",
      "1144 loss:  2.17103\n",
      "1145 loss:  2.17098\n",
      "1146 loss:  2.17093\n",
      "1147 loss:  2.1709\n",
      "1148 loss:  2.17086\n",
      "1149 loss:  2.1708\n",
      "1150 loss:  2.17076\n",
      "1151 loss:  2.17072\n",
      "1152 loss:  2.17067\n",
      "1153 loss:  2.17061\n",
      "1154 loss:  2.17058\n",
      "1155 loss:  2.17055\n",
      "1156 loss:  2.17052\n",
      "1157 loss:  2.1705\n",
      "1158 loss:  2.17048\n",
      "1159 loss:  2.17046\n",
      "1160 loss:  2.17044\n",
      "1161 loss:  2.17043\n",
      "1162 loss:  2.17041\n",
      "1163 loss:  2.17039\n",
      "1164 loss:  2.17038\n",
      "1165 loss:  2.17036\n",
      "1166 loss:  2.17034\n",
      "1167 loss:  2.17033\n",
      "1168 loss:  2.17031\n",
      "1169 loss:  2.1703\n",
      "1170 loss:  2.17027\n",
      "1171 loss:  2.17025\n",
      "1172 loss:  2.17023\n",
      "1173 loss:  2.17025\n",
      "1174 loss:  2.17024\n",
      "1175 loss:  2.17008\n",
      "1176 loss:  2.17082\n",
      "1177 loss:  2.17231\n",
      "1178 loss:  2.17551\n",
      "1179 loss:  2.17466\n",
      "1180 loss:  2.17472\n",
      "1181 loss:  2.17441\n",
      "1182 loss:  2.17419\n",
      "1183 loss:  2.17371\n",
      "1184 loss:  2.17343\n",
      "1185 loss:  2.17323\n",
      "1186 loss:  2.1729\n",
      "1187 loss:  2.17308\n",
      "1188 loss:  2.17307\n",
      "1189 loss:  2.17312\n",
      "1190 loss:  2.17277\n",
      "1191 loss:  2.17298\n",
      "1192 loss:  2.17241\n",
      "1193 loss:  2.1721\n",
      "1194 loss:  2.17206\n",
      "1195 loss:  2.17199\n",
      "1196 loss:  2.17196\n",
      "1197 loss:  2.17182\n",
      "1198 loss:  2.17171\n",
      "1199 loss:  2.17153\n",
      "1200 loss:  2.17142\n",
      "1201 loss:  2.17134\n",
      "1202 loss:  2.17123\n",
      "1203 loss:  2.17142\n",
      "1204 loss:  2.17123\n",
      "1205 loss:  2.17148\n",
      "1206 loss:  2.17142\n",
      "1207 loss:  2.17137\n",
      "1208 loss:  2.17139\n",
      "1209 loss:  2.17128\n",
      "1210 loss:  2.17115\n",
      "1211 loss:  2.17106\n",
      "1212 loss:  2.17095\n",
      "1213 loss:  2.17089\n",
      "1214 loss:  2.17083\n",
      "1215 loss:  2.17078\n",
      "1216 loss:  2.17072\n",
      "1217 loss:  2.17065\n",
      "1218 loss:  2.17061\n",
      "1219 loss:  2.17056\n",
      "1220 loss:  2.17053\n",
      "1221 loss:  2.17048\n",
      "1222 loss:  2.17043\n",
      "1223 loss:  2.17039\n",
      "1224 loss:  2.17035\n",
      "1225 loss:  2.17029\n",
      "1226 loss:  2.17023\n",
      "1227 loss:  2.17019\n",
      "1228 loss:  2.17015\n",
      "1229 loss:  2.17011\n",
      "1230 loss:  2.17007\n",
      "1231 loss:  2.17003\n",
      "1232 loss:  2.16999\n",
      "1233 loss:  2.16996\n",
      "1234 loss:  2.16992\n",
      "1235 loss:  2.1699\n",
      "1236 loss:  2.16987\n",
      "1237 loss:  2.16985\n",
      "1238 loss:  2.16982\n",
      "1239 loss:  2.1698\n",
      "1240 loss:  2.16977\n",
      "1241 loss:  2.16976\n",
      "1242 loss:  2.16974\n",
      "1243 loss:  2.16972\n",
      "1244 loss:  2.1697\n",
      "1245 loss:  2.16968\n",
      "1246 loss:  2.16966\n",
      "1247 loss:  2.16965\n",
      "1248 loss:  2.16963\n",
      "1249 loss:  2.16963\n",
      "1250 loss:  2.16963\n",
      "1251 loss:  2.16962\n",
      "1252 loss:  2.16961\n",
      "1253 loss:  2.16959\n",
      "1254 loss:  2.16958\n",
      "1255 loss:  2.16956\n",
      "1256 loss:  2.16953\n",
      "1257 loss:  2.16951\n",
      "1258 loss:  2.16957\n",
      "1259 loss:  2.16949\n",
      "1260 loss:  2.1695\n",
      "1261 loss:  2.16949\n",
      "1262 loss:  2.16948\n",
      "1263 loss:  2.16946\n",
      "1264 loss:  2.16943\n",
      "1265 loss:  2.16942\n",
      "1266 loss:  2.16943\n",
      "1267 loss:  2.16938\n",
      "1268 loss:  2.16937\n",
      "1269 loss:  2.16933\n",
      "1270 loss:  2.16927\n",
      "1271 loss:  2.16928\n",
      "1272 loss:  2.16921\n",
      "1273 loss:  2.16919\n",
      "1274 loss:  2.16917\n",
      "1275 loss:  2.16916\n",
      "1276 loss:  2.16914\n",
      "1277 loss:  2.16913\n",
      "1278 loss:  2.16911\n",
      "1279 loss:  2.16909\n",
      "1280 loss:  2.16906\n",
      "1281 loss:  2.16906\n",
      "1282 loss:  2.16909\n",
      "1283 loss:  2.16905\n",
      "1284 loss:  2.16906\n",
      "1285 loss:  2.16905\n",
      "1286 loss:  2.16905\n",
      "1287 loss:  2.16904\n",
      "1288 loss:  2.16903\n",
      "1289 loss:  2.16901\n",
      "1290 loss:  2.169\n",
      "1291 loss:  2.16899\n",
      "1292 loss:  2.16898\n",
      "1293 loss:  2.16897\n",
      "1294 loss:  2.16896\n",
      "1295 loss:  2.16894\n",
      "1296 loss:  2.16893\n",
      "1297 loss:  2.16891\n",
      "1298 loss:  2.1689\n",
      "1299 loss:  2.16888\n",
      "1300 loss:  2.16887\n",
      "1301 loss:  2.16886\n",
      "1302 loss:  2.16885\n",
      "1303 loss:  2.16884\n",
      "1304 loss:  2.16883\n",
      "1305 loss:  2.16883\n",
      "1306 loss:  2.16882\n",
      "1307 loss:  2.16881\n",
      "1308 loss:  2.16881\n",
      "1309 loss:  2.1688\n",
      "1310 loss:  2.16879\n",
      "1311 loss:  2.16878\n",
      "1312 loss:  2.16878\n",
      "1313 loss:  2.16877\n",
      "1314 loss:  2.16876\n",
      "1315 loss:  2.16875\n",
      "1316 loss:  2.16875\n",
      "1317 loss:  2.16874\n",
      "1318 loss:  2.16874\n",
      "1319 loss:  2.16873\n",
      "1320 loss:  2.16873\n",
      "1321 loss:  2.16872\n",
      "1322 loss:  2.16872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323 loss:  2.16871\n",
      "1324 loss:  2.16871\n",
      "1325 loss:  2.1687\n",
      "1326 loss:  2.1687\n",
      "1327 loss:  2.16869\n",
      "1328 loss:  2.16869\n",
      "1329 loss:  2.16868\n",
      "1330 loss:  2.16867\n",
      "1331 loss:  2.16866\n",
      "1332 loss:  2.16866\n",
      "1333 loss:  2.16865\n",
      "1334 loss:  2.16864\n",
      "1335 loss:  2.16864\n",
      "1336 loss:  2.16863\n",
      "1337 loss:  2.16862\n",
      "1338 loss:  2.16861\n",
      "1339 loss:  2.16858\n",
      "1340 loss:  2.16854\n",
      "1341 loss:  2.16849\n",
      "1342 loss:  2.16845\n",
      "1343 loss:  2.16842\n",
      "1344 loss:  2.1684\n",
      "1345 loss:  2.16839\n",
      "1346 loss:  2.16838\n",
      "1347 loss:  2.16838\n",
      "1348 loss:  2.16837\n",
      "1349 loss:  2.16836\n",
      "1350 loss:  2.16836\n",
      "1351 loss:  2.16835\n",
      "1352 loss:  2.16834\n",
      "1353 loss:  2.16833\n",
      "1354 loss:  2.16833\n",
      "1355 loss:  2.16832\n",
      "1356 loss:  2.16831\n",
      "1357 loss:  2.16831\n",
      "1358 loss:  2.1683\n",
      "1359 loss:  2.1683\n",
      "1360 loss:  2.1683\n",
      "1361 loss:  2.16829\n",
      "1362 loss:  2.16829\n",
      "1363 loss:  2.16828\n",
      "1364 loss:  2.16828\n",
      "1365 loss:  2.16827\n",
      "1366 loss:  2.16827\n",
      "1367 loss:  2.16826\n",
      "1368 loss:  2.16826\n",
      "1369 loss:  2.16826\n",
      "1370 loss:  2.16826\n",
      "1371 loss:  2.16825\n",
      "1372 loss:  2.16825\n",
      "1373 loss:  2.16825\n",
      "1374 loss:  2.16824\n",
      "1375 loss:  2.16824\n",
      "1376 loss:  2.16824\n",
      "1377 loss:  2.16823\n",
      "1378 loss:  2.16823\n",
      "1379 loss:  2.16823\n",
      "1380 loss:  2.16822\n",
      "1381 loss:  2.16822\n",
      "1382 loss:  2.16822\n",
      "1383 loss:  2.16822\n",
      "1384 loss:  2.16821\n",
      "1385 loss:  2.16821\n",
      "1386 loss:  2.16821\n",
      "1387 loss:  2.1682\n",
      "1388 loss:  2.1682\n",
      "1389 loss:  2.1682\n",
      "1390 loss:  2.16819\n",
      "1391 loss:  2.16819\n",
      "1392 loss:  2.16818\n",
      "1393 loss:  2.16818\n",
      "1394 loss:  2.16817\n",
      "1395 loss:  2.16816\n",
      "1396 loss:  2.16815\n",
      "1397 loss:  2.16814\n",
      "1398 loss:  2.1681\n",
      "1399 loss:  2.16797\n",
      "1400 loss:  2.16703\n",
      "1401 loss:  2.16703\n",
      "1402 loss:  2.16621\n",
      "1403 loss:  2.16638\n",
      "1404 loss:  2.16664\n",
      "1405 loss:  2.16638\n",
      "1406 loss:  2.16631\n",
      "1407 loss:  2.16667\n",
      "1408 loss:  2.16682\n",
      "1409 loss:  2.16615\n",
      "1410 loss:  2.16665\n",
      "1411 loss:  2.16652\n",
      "1412 loss:  2.16593\n",
      "1413 loss:  2.16576\n",
      "1414 loss:  2.16576\n",
      "1415 loss:  2.16563\n",
      "1416 loss:  2.16553\n",
      "1417 loss:  2.16646\n",
      "1418 loss:  2.17383\n",
      "1419 loss:  2.16902\n",
      "1420 loss:  2.17047\n",
      "1421 loss:  2.17289\n",
      "1422 loss:  2.17068\n",
      "1423 loss:  2.17082\n",
      "1424 loss:  2.17062\n",
      "1425 loss:  2.1696\n",
      "1426 loss:  2.16873\n",
      "1427 loss:  2.16798\n",
      "1428 loss:  2.16774\n",
      "1429 loss:  2.16764\n",
      "1430 loss:  2.16743\n",
      "1431 loss:  2.16707\n",
      "1432 loss:  2.16677\n",
      "1433 loss:  2.16663\n",
      "1434 loss:  2.16636\n",
      "1435 loss:  2.16613\n",
      "1436 loss:  2.16601\n",
      "1437 loss:  2.16592\n",
      "1438 loss:  2.16585\n",
      "1439 loss:  2.16575\n",
      "1440 loss:  2.16566\n",
      "1441 loss:  2.16552\n",
      "1442 loss:  2.16541\n",
      "1443 loss:  2.16527\n",
      "1444 loss:  2.16515\n",
      "1445 loss:  2.16511\n",
      "1446 loss:  2.16499\n",
      "1447 loss:  2.16484\n",
      "1448 loss:  2.16481\n",
      "1449 loss:  2.16474\n",
      "1450 loss:  2.16467\n",
      "1451 loss:  2.16461\n",
      "1452 loss:  2.16455\n",
      "1453 loss:  2.1645\n",
      "1454 loss:  2.16444\n",
      "1455 loss:  2.1644\n",
      "1456 loss:  2.16436\n",
      "1457 loss:  2.16432\n",
      "1458 loss:  2.16427\n",
      "1459 loss:  2.16424\n",
      "1460 loss:  2.1642\n",
      "1461 loss:  2.16416\n",
      "1462 loss:  2.16411\n",
      "1463 loss:  2.16406\n",
      "1464 loss:  2.16401\n",
      "1465 loss:  2.16395\n",
      "1466 loss:  2.16392\n",
      "1467 loss:  2.16389\n",
      "1468 loss:  2.16388\n",
      "1469 loss:  2.16386\n",
      "1470 loss:  2.16383\n",
      "1471 loss:  2.1638\n",
      "1472 loss:  2.16377\n",
      "1473 loss:  2.16374\n",
      "1474 loss:  2.16371\n",
      "1475 loss:  2.1637\n",
      "1476 loss:  2.16367\n",
      "1477 loss:  2.16365\n",
      "1478 loss:  2.16363\n",
      "1479 loss:  2.16361\n",
      "1480 loss:  2.1636\n",
      "1481 loss:  2.16358\n",
      "1482 loss:  2.16357\n",
      "1483 loss:  2.16355\n",
      "1484 loss:  2.16354\n",
      "1485 loss:  2.16352\n",
      "1486 loss:  2.1635\n",
      "1487 loss:  2.16349\n",
      "1488 loss:  2.16348\n",
      "1489 loss:  2.16347\n",
      "1490 loss:  2.16346\n",
      "1491 loss:  2.16345\n",
      "1492 loss:  2.16343\n",
      "1493 loss:  2.16342\n",
      "1494 loss:  2.16341\n",
      "1495 loss:  2.1634\n",
      "1496 loss:  2.16339\n",
      "1497 loss:  2.16338\n",
      "1498 loss:  2.16337\n",
      "1499 loss:  2.16336\n",
      "1500 loss:  2.16335\n",
      "1501 loss:  2.16334\n",
      "1502 loss:  2.16332\n",
      "1503 loss:  2.16331\n",
      "1504 loss:  2.1633\n",
      "1505 loss:  2.16328\n",
      "1506 loss:  2.16327\n",
      "1507 loss:  2.16324\n",
      "1508 loss:  2.1632\n",
      "1509 loss:  2.16316\n",
      "1510 loss:  2.16313\n",
      "1511 loss:  2.16311\n",
      "1512 loss:  2.16308\n",
      "1513 loss:  2.16309\n",
      "1514 loss:  2.16308\n",
      "1515 loss:  2.16307\n",
      "1516 loss:  2.16303\n",
      "1517 loss:  2.16297\n",
      "1518 loss:  2.16296\n",
      "1519 loss:  2.16292\n",
      "1520 loss:  2.16291\n",
      "1521 loss:  2.16292\n",
      "1522 loss:  2.16289\n",
      "1523 loss:  2.16288\n",
      "1524 loss:  2.16291\n",
      "1525 loss:  2.16293\n",
      "1526 loss:  2.16285\n",
      "1527 loss:  2.16281\n",
      "1528 loss:  2.1628\n",
      "1529 loss:  2.16276\n",
      "1530 loss:  2.16275\n",
      "1531 loss:  2.16273\n",
      "1532 loss:  2.16273\n",
      "1533 loss:  2.16269\n",
      "1534 loss:  2.16267\n",
      "1535 loss:  2.16267\n",
      "1536 loss:  2.16267\n",
      "1537 loss:  2.16265\n",
      "1538 loss:  2.16264\n",
      "1539 loss:  2.16261\n",
      "1540 loss:  2.16259\n",
      "1541 loss:  2.16256\n",
      "1542 loss:  2.16255\n",
      "1543 loss:  2.16253\n",
      "1544 loss:  2.16355\n",
      "1545 loss:  2.16942\n",
      "1546 loss:  2.19727\n",
      "1547 loss:  2.18611\n",
      "1548 loss:  2.18871\n",
      "1549 loss:  2.19192\n",
      "1550 loss:  2.19001\n",
      "1551 loss:  2.19202\n",
      "1552 loss:  2.19006\n",
      "1553 loss:  2.19026\n",
      "1554 loss:  2.19132\n",
      "1555 loss:  2.18723\n",
      "1556 loss:  2.18688\n",
      "1557 loss:  2.18529\n",
      "1558 loss:  2.18319\n",
      "1559 loss:  2.18074\n",
      "1560 loss:  2.18052\n",
      "1561 loss:  2.17879\n",
      "1562 loss:  2.17773\n",
      "1563 loss:  2.17685\n",
      "1564 loss:  2.17631\n",
      "1565 loss:  2.17546\n",
      "1566 loss:  2.17459\n",
      "1567 loss:  2.17366\n",
      "1568 loss:  2.1729\n",
      "1569 loss:  2.1724\n",
      "1570 loss:  2.17181\n",
      "1571 loss:  2.17137\n",
      "1572 loss:  2.17101\n",
      "1573 loss:  2.17056\n",
      "1574 loss:  2.17136\n",
      "1575 loss:  2.17099\n",
      "1576 loss:  2.17102\n",
      "1577 loss:  2.1708\n",
      "1578 loss:  2.17063\n",
      "1579 loss:  2.17045\n",
      "1580 loss:  2.16952\n",
      "1581 loss:  2.17166\n",
      "1582 loss:  2.17362\n",
      "1583 loss:  2.18121\n",
      "1584 loss:  2.17662\n",
      "1585 loss:  2.17719\n",
      "1586 loss:  2.17836\n",
      "1587 loss:  2.17838\n",
      "1588 loss:  2.17845\n",
      "1589 loss:  2.17744\n",
      "1590 loss:  2.17596\n",
      "1591 loss:  2.17512\n",
      "1592 loss:  2.1759\n",
      "1593 loss:  2.17613\n",
      "1594 loss:  2.17468\n",
      "1595 loss:  2.17405\n",
      "1596 loss:  2.17382\n",
      "1597 loss:  2.17296\n",
      "1598 loss:  2.1726\n",
      "1599 loss:  2.17222\n",
      "1600 loss:  2.17184\n",
      "1601 loss:  2.17163\n",
      "1602 loss:  2.17143\n",
      "1603 loss:  2.1712\n",
      "1604 loss:  2.17091\n",
      "1605 loss:  2.1706\n",
      "1606 loss:  2.17027\n",
      "1607 loss:  2.16973\n",
      "1608 loss:  2.16862\n",
      "1609 loss:  2.16818\n",
      "1610 loss:  2.16801\n",
      "1611 loss:  2.16863\n",
      "1612 loss:  2.16756\n",
      "1613 loss:  2.16742\n",
      "1614 loss:  2.1672\n",
      "1615 loss:  2.16696\n",
      "1616 loss:  2.1668\n",
      "1617 loss:  2.16668\n",
      "1618 loss:  2.16658\n",
      "1619 loss:  2.16644\n",
      "1620 loss:  2.16629\n",
      "1621 loss:  2.16614\n",
      "1622 loss:  2.16599\n",
      "1623 loss:  2.16582\n",
      "1624 loss:  2.16566\n",
      "1625 loss:  2.16552\n",
      "1626 loss:  2.16534\n",
      "1627 loss:  2.16507\n",
      "1628 loss:  2.16488\n",
      "1629 loss:  2.16483\n",
      "1630 loss:  2.16476\n",
      "1631 loss:  2.16464\n",
      "1632 loss:  2.16449\n",
      "1633 loss:  2.16441\n",
      "1634 loss:  2.16433\n",
      "1635 loss:  2.16424\n",
      "1636 loss:  2.16416\n",
      "1637 loss:  2.16412\n",
      "1638 loss:  2.16408\n",
      "1639 loss:  2.16404\n",
      "1640 loss:  2.16399\n",
      "1641 loss:  2.16395\n",
      "1642 loss:  2.16391\n",
      "1643 loss:  2.16387\n",
      "1644 loss:  2.16384\n",
      "1645 loss:  2.1638\n",
      "1646 loss:  2.16376\n",
      "1647 loss:  2.16372\n",
      "1648 loss:  2.16369\n",
      "1649 loss:  2.16365\n",
      "1650 loss:  2.16361\n",
      "1651 loss:  2.16358\n",
      "1652 loss:  2.16354\n",
      "1653 loss:  2.16351\n",
      "1654 loss:  2.16348\n",
      "1655 loss:  2.16345\n",
      "1656 loss:  2.16343\n",
      "1657 loss:  2.1634\n",
      "1658 loss:  2.16338\n",
      "1659 loss:  2.16336\n",
      "1660 loss:  2.16333\n",
      "1661 loss:  2.1633\n",
      "1662 loss:  2.16328\n",
      "1663 loss:  2.16326\n",
      "1664 loss:  2.16324\n",
      "1665 loss:  2.16323\n",
      "1666 loss:  2.16321\n",
      "1667 loss:  2.16319\n",
      "1668 loss:  2.16317\n",
      "1669 loss:  2.16315\n",
      "1670 loss:  2.16312\n",
      "1671 loss:  2.1631\n",
      "1672 loss:  2.16307\n",
      "1673 loss:  2.16305\n",
      "1674 loss:  2.16304\n",
      "1675 loss:  2.16303\n",
      "1676 loss:  2.16301\n",
      "1677 loss:  2.163\n",
      "1678 loss:  2.16299\n",
      "1679 loss:  2.16298\n",
      "1680 loss:  2.16297\n",
      "1681 loss:  2.16296\n",
      "1682 loss:  2.16295\n",
      "1683 loss:  2.16294\n",
      "1684 loss:  2.16293\n",
      "1685 loss:  2.16292\n",
      "1686 loss:  2.16292\n",
      "1687 loss:  2.16291\n",
      "1688 loss:  2.1629\n",
      "1689 loss:  2.16289\n",
      "1690 loss:  2.16288\n",
      "1691 loss:  2.16287\n",
      "1692 loss:  2.16286\n",
      "1693 loss:  2.16286\n",
      "1694 loss:  2.16285\n",
      "1695 loss:  2.16284\n",
      "1696 loss:  2.16283\n",
      "1697 loss:  2.16282\n",
      "1698 loss:  2.16281\n",
      "1699 loss:  2.16279\n",
      "1700 loss:  2.16278\n",
      "1701 loss:  2.16278\n",
      "1702 loss:  2.16278\n",
      "1703 loss:  2.16277\n",
      "1704 loss:  2.16278\n",
      "1705 loss:  2.16289\n",
      "1706 loss:  2.16297\n",
      "1707 loss:  2.16304\n",
      "1708 loss:  2.16307\n",
      "1709 loss:  2.16304\n",
      "1710 loss:  2.16299\n",
      "1711 loss:  2.16296\n",
      "1712 loss:  2.16293\n",
      "1713 loss:  2.1629\n",
      "1714 loss:  2.1629\n",
      "1715 loss:  2.16288\n",
      "1716 loss:  2.16286\n",
      "1717 loss:  2.16285\n",
      "1718 loss:  2.16284\n",
      "1719 loss:  2.16281\n",
      "1720 loss:  2.16279\n",
      "1721 loss:  2.16278\n",
      "1722 loss:  2.16277\n",
      "1723 loss:  2.16275\n",
      "1724 loss:  2.16274\n",
      "1725 loss:  2.16273\n",
      "1726 loss:  2.16271\n",
      "1727 loss:  2.1627\n",
      "1728 loss:  2.16268\n",
      "1729 loss:  2.16267\n",
      "1730 loss:  2.16265\n",
      "1731 loss:  2.16263\n",
      "1732 loss:  2.16261\n",
      "1733 loss:  2.16259\n",
      "1734 loss:  2.16257\n",
      "1735 loss:  2.16255\n",
      "1736 loss:  2.16253\n",
      "1737 loss:  2.16252\n",
      "1738 loss:  2.1625\n",
      "1739 loss:  2.1625\n",
      "1740 loss:  2.16249\n",
      "1741 loss:  2.16248\n",
      "1742 loss:  2.16247\n",
      "1743 loss:  2.16246\n",
      "1744 loss:  2.16245\n",
      "1745 loss:  2.16243\n",
      "1746 loss:  2.16241\n",
      "1747 loss:  2.16239\n",
      "1748 loss:  2.16238\n",
      "1749 loss:  2.16236\n",
      "1750 loss:  2.16238\n",
      "1751 loss:  2.16274\n",
      "1752 loss:  2.16287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1753 loss:  2.16353\n",
      "1754 loss:  2.16377\n",
      "1755 loss:  2.16343\n",
      "1756 loss:  2.16319\n",
      "1757 loss:  2.16329\n",
      "1758 loss:  2.16321\n",
      "1759 loss:  2.16308\n",
      "1760 loss:  2.16295\n",
      "1761 loss:  2.163\n",
      "1762 loss:  2.16275\n",
      "1763 loss:  2.16272\n",
      "1764 loss:  2.1627\n",
      "1765 loss:  2.16267\n",
      "1766 loss:  2.16264\n",
      "1767 loss:  2.16262\n",
      "1768 loss:  2.16258\n",
      "1769 loss:  2.16253\n",
      "1770 loss:  2.16247\n",
      "1771 loss:  2.16245\n",
      "1772 loss:  2.16239\n",
      "1773 loss:  2.16235\n",
      "1774 loss:  2.16232\n",
      "1775 loss:  2.16231\n",
      "1776 loss:  2.16227\n",
      "1777 loss:  2.16226\n",
      "1778 loss:  2.16228\n",
      "1779 loss:  2.16226\n",
      "1780 loss:  2.16224\n",
      "1781 loss:  2.16222\n",
      "1782 loss:  2.1622\n",
      "1783 loss:  2.16219\n",
      "1784 loss:  2.16217\n",
      "1785 loss:  2.16212\n",
      "1786 loss:  2.1621\n",
      "1787 loss:  2.16209\n",
      "1788 loss:  2.16207\n",
      "1789 loss:  2.16205\n",
      "1790 loss:  2.16217\n",
      "1791 loss:  2.16232\n",
      "1792 loss:  2.16265\n",
      "1793 loss:  2.16297\n",
      "1794 loss:  2.16292\n",
      "1795 loss:  2.16303\n",
      "1796 loss:  2.16282\n",
      "1797 loss:  2.16286\n",
      "1798 loss:  2.16282\n",
      "1799 loss:  2.16287\n",
      "1800 loss:  2.16283\n",
      "1801 loss:  2.16278\n",
      "1802 loss:  2.16276\n",
      "1803 loss:  2.16267\n",
      "1804 loss:  2.16262\n",
      "1805 loss:  2.16253\n",
      "1806 loss:  2.16247\n",
      "1807 loss:  2.16244\n",
      "1808 loss:  2.1624\n",
      "1809 loss:  2.1624\n",
      "1810 loss:  2.16238\n",
      "1811 loss:  2.16236\n",
      "1812 loss:  2.16233\n",
      "1813 loss:  2.1623\n",
      "1814 loss:  2.16229\n",
      "1815 loss:  2.16226\n",
      "1816 loss:  2.16225\n",
      "1817 loss:  2.16223\n",
      "1818 loss:  2.16222\n",
      "1819 loss:  2.1622\n",
      "1820 loss:  2.16219\n",
      "1821 loss:  2.16218\n",
      "1822 loss:  2.16216\n",
      "1823 loss:  2.16216\n",
      "1824 loss:  2.16214\n",
      "1825 loss:  2.16213\n",
      "1826 loss:  2.16211\n",
      "1827 loss:  2.1621\n",
      "1828 loss:  2.16209\n",
      "1829 loss:  2.16207\n",
      "1830 loss:  2.16205\n",
      "1831 loss:  2.16203\n",
      "1832 loss:  2.16201\n",
      "1833 loss:  2.16198\n",
      "1834 loss:  2.16195\n",
      "1835 loss:  2.16193\n",
      "1836 loss:  2.16191\n",
      "1837 loss:  2.1619\n",
      "1838 loss:  2.16189\n",
      "1839 loss:  2.16188\n",
      "1840 loss:  2.16187\n",
      "1841 loss:  2.16186\n",
      "1842 loss:  2.16185\n",
      "1843 loss:  2.16184\n",
      "1844 loss:  2.16183\n",
      "1845 loss:  2.16182\n",
      "1846 loss:  2.16181\n",
      "1847 loss:  2.1618\n",
      "1848 loss:  2.16179\n",
      "1849 loss:  2.16178\n",
      "1850 loss:  2.16177\n",
      "1851 loss:  2.16177\n",
      "1852 loss:  2.16176\n",
      "1853 loss:  2.16175\n",
      "1854 loss:  2.16175\n",
      "1855 loss:  2.16174\n",
      "1856 loss:  2.16173\n",
      "1857 loss:  2.16173\n",
      "1858 loss:  2.16172\n",
      "1859 loss:  2.16172\n",
      "1860 loss:  2.16171\n",
      "1861 loss:  2.1617\n",
      "1862 loss:  2.1617\n",
      "1863 loss:  2.16169\n",
      "1864 loss:  2.16169\n",
      "1865 loss:  2.16168\n",
      "1866 loss:  2.16168\n",
      "1867 loss:  2.16167\n",
      "1868 loss:  2.16167\n",
      "1869 loss:  2.16166\n",
      "1870 loss:  2.16166\n",
      "1871 loss:  2.16166\n",
      "1872 loss:  2.16165\n",
      "1873 loss:  2.16165\n",
      "1874 loss:  2.16164\n",
      "1875 loss:  2.16164\n",
      "1876 loss:  2.16163\n",
      "1877 loss:  2.16163\n",
      "1878 loss:  2.16162\n",
      "1879 loss:  2.16162\n",
      "1880 loss:  2.16161\n",
      "1881 loss:  2.16161\n",
      "1882 loss:  2.1616\n",
      "1883 loss:  2.1616\n",
      "1884 loss:  2.16159\n",
      "1885 loss:  2.16159\n",
      "1886 loss:  2.16159\n",
      "1887 loss:  2.16158\n",
      "1888 loss:  2.16158\n",
      "1889 loss:  2.16157\n",
      "1890 loss:  2.16157\n",
      "1891 loss:  2.16157\n",
      "1892 loss:  2.16156\n",
      "1893 loss:  2.16156\n",
      "1894 loss:  2.16155\n",
      "1895 loss:  2.16155\n",
      "1896 loss:  2.16155\n",
      "1897 loss:  2.16154\n",
      "1898 loss:  2.16154\n",
      "1899 loss:  2.16154\n",
      "1900 loss:  2.16153\n",
      "1901 loss:  2.16153\n",
      "1902 loss:  2.16152\n",
      "1903 loss:  2.16152\n",
      "1904 loss:  2.16152\n",
      "1905 loss:  2.16151\n",
      "1906 loss:  2.16151\n",
      "1907 loss:  2.1615\n",
      "1908 loss:  2.1615\n",
      "1909 loss:  2.16149\n",
      "1910 loss:  2.16149\n",
      "1911 loss:  2.16148\n",
      "1912 loss:  2.16148\n",
      "1913 loss:  2.16147\n",
      "1914 loss:  2.16147\n",
      "1915 loss:  2.16146\n",
      "1916 loss:  2.16145\n",
      "1917 loss:  2.16145\n",
      "1918 loss:  2.16144\n",
      "1919 loss:  2.16144\n",
      "1920 loss:  2.16143\n",
      "1921 loss:  2.16142\n",
      "1922 loss:  2.16142\n",
      "1923 loss:  2.16141\n",
      "1924 loss:  2.1614\n",
      "1925 loss:  2.16139\n",
      "1926 loss:  2.16138\n",
      "1927 loss:  2.16137\n",
      "1928 loss:  2.16136\n",
      "1929 loss:  2.16136\n",
      "1930 loss:  2.16135\n",
      "1931 loss:  2.16134\n",
      "1932 loss:  2.16133\n",
      "1933 loss:  2.16132\n",
      "1934 loss:  2.16131\n",
      "1935 loss:  2.1613\n",
      "1936 loss:  2.16129\n",
      "1937 loss:  2.16129\n",
      "1938 loss:  2.16128\n",
      "1939 loss:  2.16127\n",
      "1940 loss:  2.16127\n",
      "1941 loss:  2.16126\n",
      "1942 loss:  2.16126\n",
      "1943 loss:  2.16125\n",
      "1944 loss:  2.16125\n",
      "1945 loss:  2.16125\n",
      "1946 loss:  2.16124\n",
      "1947 loss:  2.16124\n",
      "1948 loss:  2.16123\n",
      "1949 loss:  2.16123\n",
      "1950 loss:  2.16123\n",
      "1951 loss:  2.16122\n",
      "1952 loss:  2.16122\n",
      "1953 loss:  2.16122\n",
      "1954 loss:  2.16121\n",
      "1955 loss:  2.16121\n",
      "1956 loss:  2.16121\n",
      "1957 loss:  2.16121\n",
      "1958 loss:  2.1612\n",
      "1959 loss:  2.1612\n",
      "1960 loss:  2.1612\n",
      "1961 loss:  2.16119\n",
      "1962 loss:  2.16119\n",
      "1963 loss:  2.16119\n",
      "1964 loss:  2.16118\n",
      "1965 loss:  2.16118\n",
      "1966 loss:  2.16117\n",
      "1967 loss:  2.16117\n",
      "1968 loss:  2.16116\n",
      "1969 loss:  2.16115\n",
      "1970 loss:  2.16115\n",
      "1971 loss:  2.16115\n",
      "1972 loss:  2.16114\n",
      "1973 loss:  2.16114\n",
      "1974 loss:  2.16114\n",
      "1975 loss:  2.16113\n",
      "1976 loss:  2.16113\n",
      "1977 loss:  2.16113\n",
      "1978 loss:  2.16112\n",
      "1979 loss:  2.16112\n",
      "1980 loss:  2.16111\n",
      "1981 loss:  2.1611\n",
      "1982 loss:  2.16109\n",
      "1983 loss:  2.16108\n",
      "1984 loss:  2.16108\n",
      "1985 loss:  2.16107\n",
      "1986 loss:  2.16107\n",
      "1987 loss:  2.16106\n",
      "1988 loss:  2.16106\n",
      "1989 loss:  2.16106\n",
      "1990 loss:  2.16105\n",
      "1991 loss:  2.16105\n",
      "1992 loss:  2.16105\n",
      "1993 loss:  2.16104\n",
      "1994 loss:  2.16104\n",
      "1995 loss:  2.16104\n",
      "1996 loss:  2.16103\n",
      "1997 loss:  2.16103\n",
      "1998 loss:  2.16103\n",
      "1999 loss:  2.16102\n",
      "2000 loss:  2.16102\n",
      "2001 loss:  2.16102\n",
      "2002 loss:  2.16101\n",
      "2003 loss:  2.16101\n",
      "2004 loss:  2.161\n",
      "2005 loss:  2.16099\n",
      "2006 loss:  2.16098\n",
      "2007 loss:  2.16096\n",
      "2008 loss:  2.16096\n",
      "2009 loss:  2.1609\n",
      "2010 loss:  2.16143\n",
      "2011 loss:  2.1692\n",
      "2012 loss:  2.16823\n",
      "2013 loss:  2.16576\n",
      "2014 loss:  2.16592\n",
      "2015 loss:  2.16757\n",
      "2016 loss:  2.16607\n",
      "2017 loss:  2.16578\n",
      "2018 loss:  2.16525\n",
      "2019 loss:  2.16603\n",
      "2020 loss:  2.16521\n",
      "2021 loss:  2.16696\n",
      "2022 loss:  2.16952\n",
      "2023 loss:  2.16526\n",
      "2024 loss:  2.16759\n",
      "2025 loss:  2.16606\n",
      "2026 loss:  2.16548\n",
      "2027 loss:  2.16605\n",
      "2028 loss:  2.16645\n",
      "2029 loss:  2.16613\n",
      "2030 loss:  2.16523\n",
      "2031 loss:  2.16483\n",
      "2032 loss:  2.16458\n",
      "2033 loss:  2.16482\n",
      "2034 loss:  2.16434\n",
      "2035 loss:  2.16399\n",
      "2036 loss:  2.16365\n",
      "2037 loss:  2.16337\n",
      "2038 loss:  2.1631\n",
      "2039 loss:  2.1629\n",
      "2040 loss:  2.16273\n",
      "2041 loss:  2.16254\n",
      "2042 loss:  2.16239\n",
      "2043 loss:  2.16226\n",
      "2044 loss:  2.16216\n",
      "2045 loss:  2.16204\n",
      "2046 loss:  2.16193\n",
      "2047 loss:  2.16186\n",
      "2048 loss:  2.16181\n",
      "2049 loss:  2.16178\n",
      "2050 loss:  2.16173\n",
      "2051 loss:  2.16169\n",
      "2052 loss:  2.16164\n",
      "2053 loss:  2.16158\n",
      "2054 loss:  2.16154\n",
      "2055 loss:  2.16151\n",
      "2056 loss:  2.16146\n",
      "2057 loss:  2.16142\n",
      "2058 loss:  2.16138\n",
      "2059 loss:  2.16134\n",
      "2060 loss:  2.1613\n",
      "2061 loss:  2.16127\n",
      "2062 loss:  2.16124\n",
      "2063 loss:  2.16121\n",
      "2064 loss:  2.16119\n",
      "2065 loss:  2.16117\n",
      "2066 loss:  2.16114\n",
      "2067 loss:  2.16112\n",
      "2068 loss:  2.16111\n",
      "2069 loss:  2.16109\n",
      "2070 loss:  2.16108\n",
      "2071 loss:  2.16106\n",
      "2072 loss:  2.16104\n",
      "2073 loss:  2.16103\n",
      "2074 loss:  2.16101\n",
      "2075 loss:  2.161\n",
      "2076 loss:  2.16099\n",
      "2077 loss:  2.16098\n",
      "2078 loss:  2.16097\n",
      "2079 loss:  2.16096\n",
      "2080 loss:  2.16095\n",
      "2081 loss:  2.16094\n",
      "2082 loss:  2.16093\n",
      "2083 loss:  2.16092\n",
      "2084 loss:  2.16091\n",
      "2085 loss:  2.1609\n",
      "2086 loss:  2.16089\n",
      "2087 loss:  2.16088\n",
      "2088 loss:  2.16088\n",
      "2089 loss:  2.16087\n",
      "2090 loss:  2.16086\n",
      "2091 loss:  2.16085\n",
      "2092 loss:  2.16085\n",
      "2093 loss:  2.16084\n",
      "2094 loss:  2.16083\n",
      "2095 loss:  2.16082\n",
      "2096 loss:  2.16081\n",
      "2097 loss:  2.16079\n",
      "2098 loss:  2.16079\n",
      "2099 loss:  2.16079\n",
      "2100 loss:  2.16079\n",
      "2101 loss:  2.16078\n",
      "2102 loss:  2.16077\n",
      "2103 loss:  2.16076\n",
      "2104 loss:  2.16075\n",
      "2105 loss:  2.16074\n",
      "2106 loss:  2.16074\n",
      "2107 loss:  2.16073\n",
      "2108 loss:  2.16072\n",
      "2109 loss:  2.16072\n",
      "2110 loss:  2.16071\n",
      "2111 loss:  2.16071\n",
      "2112 loss:  2.1607\n",
      "2113 loss:  2.1607\n",
      "2114 loss:  2.16069\n",
      "2115 loss:  2.16069\n",
      "2116 loss:  2.16068\n",
      "2117 loss:  2.16067\n",
      "2118 loss:  2.16066\n",
      "2119 loss:  2.16065\n",
      "2120 loss:  2.16065\n",
      "2121 loss:  2.16064\n",
      "2122 loss:  2.16063\n",
      "2123 loss:  2.16063\n",
      "2124 loss:  2.16062\n",
      "2125 loss:  2.16062\n",
      "2126 loss:  2.16061\n",
      "2127 loss:  2.16061\n",
      "2128 loss:  2.1606\n",
      "2129 loss:  2.1606\n",
      "2130 loss:  2.1606\n",
      "2131 loss:  2.16059\n",
      "2132 loss:  2.16059\n",
      "2133 loss:  2.16058\n",
      "2134 loss:  2.16058\n",
      "2135 loss:  2.16058\n",
      "2136 loss:  2.16057\n",
      "2137 loss:  2.16057\n",
      "2138 loss:  2.16057\n",
      "2139 loss:  2.16056\n",
      "2140 loss:  2.16056\n",
      "2141 loss:  2.16055\n",
      "2142 loss:  2.16055\n",
      "2143 loss:  2.16055\n",
      "2144 loss:  2.16054\n",
      "2145 loss:  2.16054\n",
      "2146 loss:  2.16054\n",
      "2147 loss:  2.16053\n",
      "2148 loss:  2.16053\n",
      "2149 loss:  2.16053\n",
      "2150 loss:  2.16052\n",
      "2151 loss:  2.16052\n",
      "2152 loss:  2.16051\n",
      "2153 loss:  2.1605\n",
      "2154 loss:  2.16049\n",
      "2155 loss:  2.16048\n",
      "2156 loss:  2.16047\n",
      "2157 loss:  2.16047\n",
      "2158 loss:  2.16046\n",
      "2159 loss:  2.16045\n",
      "2160 loss:  2.16044\n",
      "2161 loss:  2.16044\n",
      "2162 loss:  2.16043\n",
      "2163 loss:  2.16043\n",
      "2164 loss:  2.16043\n",
      "2165 loss:  2.16042\n",
      "2166 loss:  2.16042\n",
      "2167 loss:  2.16041\n",
      "2168 loss:  2.16041\n",
      "2169 loss:  2.16041\n",
      "2170 loss:  2.1604\n",
      "2171 loss:  2.1604\n",
      "2172 loss:  2.1604\n",
      "2173 loss:  2.16039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174 loss:  2.16039\n",
      "2175 loss:  2.16039\n",
      "2176 loss:  2.16038\n",
      "2177 loss:  2.16038\n",
      "2178 loss:  2.16038\n",
      "2179 loss:  2.16037\n",
      "2180 loss:  2.16037\n",
      "2181 loss:  2.16036\n",
      "2182 loss:  2.16035\n",
      "2183 loss:  2.16032\n",
      "2184 loss:  2.16027\n",
      "2185 loss:  2.16025\n",
      "2186 loss:  2.16024\n",
      "2187 loss:  2.16021\n",
      "2188 loss:  2.16014\n",
      "2189 loss:  2.1601\n",
      "2190 loss:  2.16009\n",
      "2191 loss:  2.1601\n",
      "2192 loss:  2.1601\n",
      "2193 loss:  2.1601\n",
      "2194 loss:  2.1601\n",
      "2195 loss:  2.1601\n",
      "2196 loss:  2.16009\n",
      "2197 loss:  2.16009\n",
      "2198 loss:  2.16008\n",
      "2199 loss:  2.16007\n",
      "2200 loss:  2.16006\n",
      "2201 loss:  2.16006\n",
      "2202 loss:  2.16005\n",
      "2203 loss:  2.16004\n",
      "2204 loss:  2.16004\n",
      "2205 loss:  2.16003\n",
      "2206 loss:  2.16003\n",
      "2207 loss:  2.16002\n",
      "2208 loss:  2.16002\n",
      "2209 loss:  2.16001\n",
      "2210 loss:  2.16\n",
      "2211 loss:  2.16\n",
      "2212 loss:  2.15999\n",
      "2213 loss:  2.15999\n",
      "2214 loss:  2.15998\n",
      "2215 loss:  2.15998\n",
      "2216 loss:  2.15998\n",
      "2217 loss:  2.15997\n",
      "2218 loss:  2.15997\n",
      "2219 loss:  2.15997\n",
      "2220 loss:  2.15997\n",
      "2221 loss:  2.15996\n",
      "2222 loss:  2.15996\n",
      "2223 loss:  2.15996\n",
      "2224 loss:  2.15996\n",
      "2225 loss:  2.15995\n",
      "2226 loss:  2.15995\n",
      "2227 loss:  2.15995\n",
      "2228 loss:  2.15995\n",
      "2229 loss:  2.15994\n",
      "2230 loss:  2.15994\n",
      "2231 loss:  2.15994\n",
      "2232 loss:  2.15994\n",
      "2233 loss:  2.15994\n",
      "2234 loss:  2.15993\n",
      "2235 loss:  2.15993\n",
      "2236 loss:  2.15993\n",
      "2237 loss:  2.15993\n",
      "2238 loss:  2.15993\n",
      "2239 loss:  2.15992\n",
      "2240 loss:  2.15992\n",
      "2241 loss:  2.15992\n",
      "2242 loss:  2.15992\n",
      "2243 loss:  2.15991\n",
      "2244 loss:  2.15991\n",
      "2245 loss:  2.15991\n",
      "2246 loss:  2.15991\n",
      "2247 loss:  2.1599\n",
      "2248 loss:  2.1599\n",
      "2249 loss:  2.1599\n",
      "2250 loss:  2.15989\n",
      "2251 loss:  2.15989\n",
      "2252 loss:  2.15988\n",
      "2253 loss:  2.15988\n",
      "2254 loss:  2.15988\n",
      "2255 loss:  2.15987\n",
      "2256 loss:  2.15987\n",
      "2257 loss:  2.15986\n",
      "2258 loss:  2.15986\n",
      "2259 loss:  2.15986\n",
      "2260 loss:  2.15985\n",
      "2261 loss:  2.15985\n",
      "2262 loss:  2.15985\n",
      "2263 loss:  2.15984\n",
      "2264 loss:  2.15984\n",
      "2265 loss:  2.15984\n",
      "2266 loss:  2.15984\n",
      "2267 loss:  2.15983\n",
      "2268 loss:  2.15983\n",
      "2269 loss:  2.15983\n",
      "2270 loss:  2.15983\n",
      "2271 loss:  2.15982\n",
      "2272 loss:  2.15982\n",
      "2273 loss:  2.15982\n",
      "2274 loss:  2.15982\n",
      "2275 loss:  2.15982\n",
      "2276 loss:  2.15981\n",
      "2277 loss:  2.15981\n",
      "2278 loss:  2.15981\n",
      "2279 loss:  2.15981\n",
      "2280 loss:  2.15981\n",
      "2281 loss:  2.15981\n",
      "2282 loss:  2.15981\n",
      "2283 loss:  2.1598\n",
      "2284 loss:  2.1598\n",
      "2285 loss:  2.1598\n",
      "2286 loss:  2.1598\n",
      "2287 loss:  2.1598\n",
      "2288 loss:  2.1598\n",
      "2289 loss:  2.15979\n",
      "2290 loss:  2.15979\n",
      "2291 loss:  2.15979\n",
      "2292 loss:  2.15979\n",
      "2293 loss:  2.15979\n",
      "2294 loss:  2.15979\n",
      "2295 loss:  2.15978\n",
      "2296 loss:  2.15978\n",
      "2297 loss:  2.15978\n",
      "2298 loss:  2.15978\n",
      "2299 loss:  2.15978\n",
      "2300 loss:  2.15977\n",
      "2301 loss:  2.15977\n",
      "2302 loss:  2.15977\n",
      "2303 loss:  2.15976\n",
      "2304 loss:  2.15976\n",
      "2305 loss:  2.15976\n",
      "2306 loss:  2.15975\n",
      "2307 loss:  2.15975\n",
      "2308 loss:  2.15974\n",
      "2309 loss:  2.15973\n",
      "2310 loss:  2.15973\n",
      "2311 loss:  2.15972\n",
      "2312 loss:  2.15972\n",
      "2313 loss:  2.15971\n",
      "2314 loss:  2.15971\n",
      "2315 loss:  2.1597\n",
      "2316 loss:  2.1597\n",
      "2317 loss:  2.15969\n",
      "2318 loss:  2.15969\n",
      "2319 loss:  2.15968\n",
      "2320 loss:  2.15967\n",
      "2321 loss:  2.15967\n",
      "2322 loss:  2.15966\n",
      "2323 loss:  2.15965\n",
      "2324 loss:  2.15964\n",
      "2325 loss:  2.15963\n",
      "2326 loss:  2.15962\n",
      "2327 loss:  2.15961\n",
      "2328 loss:  2.1596\n",
      "2329 loss:  2.15959\n",
      "2330 loss:  2.15959\n",
      "2331 loss:  2.15972\n",
      "2332 loss:  2.16183\n",
      "2333 loss:  2.1606\n",
      "2334 loss:  2.16119\n",
      "2335 loss:  2.16213\n",
      "2336 loss:  2.16182\n",
      "2337 loss:  2.16185\n",
      "2338 loss:  2.16178\n",
      "2339 loss:  2.16128\n",
      "2340 loss:  2.16214\n",
      "2341 loss:  2.16116\n",
      "2342 loss:  2.16124\n",
      "2343 loss:  2.16139\n",
      "2344 loss:  2.16137\n",
      "2345 loss:  2.16123\n",
      "2346 loss:  2.16104\n",
      "2347 loss:  2.16089\n",
      "2348 loss:  2.16078\n",
      "2349 loss:  2.16069\n",
      "2350 loss:  2.16059\n",
      "2351 loss:  2.16047\n",
      "2352 loss:  2.16039\n",
      "2353 loss:  2.16029\n",
      "2354 loss:  2.16017\n",
      "2355 loss:  2.16003\n",
      "2356 loss:  2.15981\n",
      "2357 loss:  2.15969\n",
      "2358 loss:  2.15959\n",
      "2359 loss:  2.1595\n",
      "2360 loss:  2.15948\n",
      "2361 loss:  2.15944\n",
      "2362 loss:  2.15939\n",
      "2363 loss:  2.15931\n",
      "2364 loss:  2.15932\n",
      "2365 loss:  2.15927\n",
      "2366 loss:  2.15927\n",
      "2367 loss:  2.15928\n",
      "2368 loss:  2.16033\n",
      "2369 loss:  2.15948\n",
      "2370 loss:  2.15973\n",
      "2371 loss:  2.15983\n",
      "2372 loss:  2.16006\n",
      "2373 loss:  2.15981\n",
      "2374 loss:  2.15972\n",
      "2375 loss:  2.15963\n",
      "2376 loss:  2.15955\n",
      "2377 loss:  2.15951\n",
      "2378 loss:  2.15947\n",
      "2379 loss:  2.15944\n",
      "2380 loss:  2.15941\n",
      "2381 loss:  2.15939\n",
      "2382 loss:  2.15934\n",
      "2383 loss:  2.1593\n",
      "2384 loss:  2.15926\n",
      "2385 loss:  2.15924\n",
      "2386 loss:  2.15921\n",
      "2387 loss:  2.15919\n",
      "2388 loss:  2.15916\n",
      "2389 loss:  2.15915\n",
      "2390 loss:  2.15915\n",
      "2391 loss:  2.15913\n",
      "2392 loss:  2.15911\n",
      "2393 loss:  2.1591\n",
      "2394 loss:  2.15908\n",
      "2395 loss:  2.15907\n",
      "2396 loss:  2.15906\n",
      "2397 loss:  2.15905\n",
      "2398 loss:  2.15904\n",
      "2399 loss:  2.15902\n",
      "2400 loss:  2.15901\n",
      "2401 loss:  2.15901\n",
      "2402 loss:  2.15899\n",
      "2403 loss:  2.15898\n",
      "2404 loss:  2.15897\n",
      "2405 loss:  2.15896\n",
      "2406 loss:  2.15895\n",
      "2407 loss:  2.15895\n",
      "2408 loss:  2.15893\n",
      "2409 loss:  2.15894\n",
      "2410 loss:  2.15898\n",
      "2411 loss:  2.159\n",
      "2412 loss:  2.15897\n",
      "2413 loss:  2.15896\n",
      "2414 loss:  2.15896\n",
      "2415 loss:  2.15894\n",
      "2416 loss:  2.15891\n",
      "2417 loss:  2.1589\n",
      "2418 loss:  2.15889\n",
      "2419 loss:  2.15888\n",
      "2420 loss:  2.15887\n",
      "2421 loss:  2.15887\n",
      "2422 loss:  2.15887\n",
      "2423 loss:  2.15885\n",
      "2424 loss:  2.15884\n",
      "2425 loss:  2.15885\n",
      "2426 loss:  2.15883\n",
      "2427 loss:  2.15883\n",
      "2428 loss:  2.15882\n",
      "2429 loss:  2.15881\n",
      "2430 loss:  2.15881\n",
      "2431 loss:  2.1588\n",
      "2432 loss:  2.15879\n",
      "2433 loss:  2.15877\n",
      "2434 loss:  2.1587\n",
      "2435 loss:  2.15868\n",
      "2436 loss:  2.15867\n",
      "2437 loss:  2.15864\n",
      "2438 loss:  2.15934\n",
      "2439 loss:  2.16056\n",
      "2440 loss:  2.16674\n",
      "2441 loss:  2.16566\n",
      "2442 loss:  2.16555\n",
      "2443 loss:  2.16905\n",
      "2444 loss:  2.1658\n",
      "2445 loss:  2.16484\n",
      "2446 loss:  2.16449\n",
      "2447 loss:  2.16732\n",
      "2448 loss:  2.16626\n",
      "2449 loss:  2.18056\n",
      "2450 loss:  2.17363\n",
      "2451 loss:  2.16882\n",
      "2452 loss:  2.16907\n",
      "2453 loss:  2.17337\n",
      "2454 loss:  2.17426\n",
      "2455 loss:  2.17343\n",
      "2456 loss:  2.17162\n",
      "2457 loss:  2.17015\n",
      "2458 loss:  2.16904\n",
      "2459 loss:  2.16824\n",
      "2460 loss:  2.16766\n",
      "2461 loss:  2.17042\n",
      "2462 loss:  2.16822\n",
      "2463 loss:  2.16739\n",
      "2464 loss:  2.1674\n",
      "2465 loss:  2.17306\n",
      "2466 loss:  2.1769\n",
      "2467 loss:  2.17898\n",
      "2468 loss:  2.18953\n",
      "2469 loss:  2.18224\n",
      "2470 loss:  2.1809\n",
      "2471 loss:  2.17919\n",
      "2472 loss:  2.17974\n",
      "2473 loss:  2.18104\n",
      "2474 loss:  2.17595\n",
      "2475 loss:  2.1757\n",
      "2476 loss:  2.17383\n",
      "2477 loss:  2.17323\n",
      "2478 loss:  2.17374\n",
      "2479 loss:  2.17285\n",
      "2480 loss:  2.17313\n",
      "2481 loss:  2.17162\n",
      "2482 loss:  2.1723\n",
      "2483 loss:  2.17471\n",
      "2484 loss:  2.17339\n",
      "2485 loss:  2.17268\n",
      "2486 loss:  2.17237\n",
      "2487 loss:  2.17068\n",
      "2488 loss:  2.16914\n",
      "2489 loss:  2.16828\n",
      "2490 loss:  2.16773\n",
      "2491 loss:  2.16778\n",
      "2492 loss:  2.16725\n",
      "2493 loss:  2.16661\n",
      "2494 loss:  2.16629\n",
      "2495 loss:  2.16579\n",
      "2496 loss:  2.16518\n",
      "2497 loss:  2.16537\n",
      "2498 loss:  2.16467\n",
      "2499 loss:  2.16452\n",
      "2500 loss:  2.16422\n",
      "2501 loss:  2.16393\n",
      "2502 loss:  2.16358\n",
      "2503 loss:  2.16435\n",
      "2504 loss:  2.16372\n",
      "2505 loss:  2.16291\n",
      "2506 loss:  2.16281\n",
      "2507 loss:  2.16266\n",
      "2508 loss:  2.16255\n",
      "2509 loss:  2.16256\n",
      "2510 loss:  2.16264\n",
      "2511 loss:  2.16247\n",
      "2512 loss:  2.16228\n",
      "2513 loss:  2.16215\n",
      "2514 loss:  2.16191\n",
      "2515 loss:  2.16188\n",
      "2516 loss:  2.16169\n",
      "2517 loss:  2.16157\n",
      "2518 loss:  2.16145\n",
      "2519 loss:  2.16231\n",
      "2520 loss:  2.16248\n",
      "2521 loss:  2.16744\n",
      "2522 loss:  2.19332\n",
      "2523 loss:  2.18797\n",
      "2524 loss:  2.18493\n",
      "2525 loss:  2.19598\n",
      "2526 loss:  2.19272\n",
      "2527 loss:  2.20068\n",
      "2528 loss:  2.20108\n",
      "2529 loss:  2.19269\n",
      "2530 loss:  2.19665\n",
      "2531 loss:  2.19246\n",
      "2532 loss:  2.19174\n",
      "2533 loss:  2.19095\n",
      "2534 loss:  2.18531\n",
      "2535 loss:  2.1818\n",
      "2536 loss:  2.18863\n",
      "2537 loss:  2.18763\n",
      "2538 loss:  2.19313\n",
      "2539 loss:  2.19661\n",
      "2540 loss:  2.18752\n",
      "2541 loss:  2.18999\n",
      "2542 loss:  2.1831\n",
      "2543 loss:  2.18484\n",
      "2544 loss:  2.18006\n",
      "2545 loss:  2.17992\n",
      "2546 loss:  2.18077\n",
      "2547 loss:  2.17689\n",
      "2548 loss:  2.1782\n",
      "2549 loss:  2.17485\n",
      "2550 loss:  2.17333\n",
      "2551 loss:  2.17212\n",
      "2552 loss:  2.16875\n",
      "2553 loss:  2.16915\n",
      "2554 loss:  2.1682\n",
      "2555 loss:  2.17156\n",
      "2556 loss:  2.17037\n",
      "2557 loss:  2.16672\n",
      "2558 loss:  2.16473\n",
      "2559 loss:  2.16459\n",
      "2560 loss:  2.16467\n",
      "2561 loss:  2.16527\n",
      "2562 loss:  2.16425\n",
      "2563 loss:  2.16294\n",
      "2564 loss:  2.16317\n",
      "2565 loss:  2.16218\n",
      "2566 loss:  2.16155\n",
      "2567 loss:  2.16106\n",
      "2568 loss:  2.16065\n",
      "2569 loss:  2.1611\n",
      "2570 loss:  2.16065\n",
      "2571 loss:  2.16054\n",
      "2572 loss:  2.16006\n",
      "2573 loss:  2.15972\n",
      "2574 loss:  2.15915\n",
      "2575 loss:  2.15839\n",
      "2576 loss:  2.15795\n",
      "2577 loss:  2.1576\n",
      "2578 loss:  2.15738\n",
      "2579 loss:  2.15777\n",
      "2580 loss:  2.15913\n",
      "2581 loss:  2.15767\n",
      "2582 loss:  2.15862\n",
      "2583 loss:  2.15822\n",
      "2584 loss:  2.15864\n",
      "2585 loss:  2.15837\n",
      "2586 loss:  2.15805\n",
      "2587 loss:  2.15777\n",
      "2588 loss:  2.15753\n",
      "2589 loss:  2.15748\n",
      "2590 loss:  2.15726\n",
      "2591 loss:  2.1571\n",
      "2592 loss:  2.15697\n",
      "2593 loss:  2.15679\n",
      "2594 loss:  2.15662\n",
      "2595 loss:  2.15646\n",
      "2596 loss:  2.1563\n",
      "2597 loss:  2.15615\n",
      "2598 loss:  2.15598\n",
      "2599 loss:  2.15584\n",
      "2600 loss:  2.15573\n",
      "2601 loss:  2.15565\n",
      "2602 loss:  2.15554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2603 loss:  2.15545\n",
      "2604 loss:  2.15536\n",
      "2605 loss:  2.1553\n",
      "2606 loss:  2.15524\n",
      "2607 loss:  2.15518\n",
      "2608 loss:  2.15512\n",
      "2609 loss:  2.15506\n",
      "2610 loss:  2.155\n",
      "2611 loss:  2.15496\n",
      "2612 loss:  2.1549\n",
      "2613 loss:  2.15485\n",
      "2614 loss:  2.15477\n",
      "2615 loss:  2.15474\n",
      "2616 loss:  2.15466\n",
      "2617 loss:  2.15457\n",
      "2618 loss:  2.15447\n",
      "2619 loss:  2.15434\n",
      "2620 loss:  2.15423\n",
      "2621 loss:  2.15406\n",
      "2622 loss:  2.15387\n",
      "2623 loss:  2.15382\n",
      "2624 loss:  2.15377\n",
      "2625 loss:  2.15368\n",
      "2626 loss:  2.15363\n",
      "2627 loss:  2.15355\n",
      "2628 loss:  2.15355\n",
      "2629 loss:  2.15357\n",
      "2630 loss:  2.15357\n",
      "2631 loss:  2.15357\n",
      "2632 loss:  2.15346\n",
      "2633 loss:  2.15376\n",
      "2634 loss:  2.15402\n",
      "2635 loss:  2.15393\n",
      "2636 loss:  2.15396\n",
      "2637 loss:  2.15405\n",
      "2638 loss:  2.15412\n",
      "2639 loss:  2.15412\n",
      "2640 loss:  2.15406\n",
      "2641 loss:  2.15397\n",
      "2642 loss:  2.15389\n",
      "2643 loss:  2.15382\n",
      "2644 loss:  2.15376\n",
      "2645 loss:  2.15367\n",
      "2646 loss:  2.1536\n",
      "2647 loss:  2.15352\n",
      "2648 loss:  2.15346\n",
      "2649 loss:  2.15343\n",
      "2650 loss:  2.15343\n",
      "2651 loss:  2.15341\n",
      "2652 loss:  2.15331\n",
      "2653 loss:  2.15327\n",
      "2654 loss:  2.15322\n",
      "2655 loss:  2.15319\n",
      "2656 loss:  2.15316\n",
      "2657 loss:  2.15312\n",
      "2658 loss:  2.15308\n",
      "2659 loss:  2.15303\n",
      "2660 loss:  2.153\n",
      "2661 loss:  2.153\n",
      "2662 loss:  2.15296\n",
      "2663 loss:  2.15294\n",
      "2664 loss:  2.15293\n",
      "2665 loss:  2.15291\n",
      "2666 loss:  2.15289\n",
      "2667 loss:  2.15287\n",
      "2668 loss:  2.15285\n",
      "2669 loss:  2.15283\n",
      "2670 loss:  2.15282\n",
      "2671 loss:  2.1528\n",
      "2672 loss:  2.15279\n",
      "2673 loss:  2.15277\n",
      "2674 loss:  2.15275\n",
      "2675 loss:  2.15274\n",
      "2676 loss:  2.15272\n",
      "2677 loss:  2.15274\n",
      "2678 loss:  2.15278\n",
      "2679 loss:  2.15291\n",
      "2680 loss:  2.15302\n",
      "2681 loss:  2.15307\n",
      "2682 loss:  2.1531\n",
      "2683 loss:  2.15309\n",
      "2684 loss:  2.15306\n",
      "2685 loss:  2.153\n",
      "2686 loss:  2.15294\n",
      "2687 loss:  2.15287\n",
      "2688 loss:  2.1528\n",
      "2689 loss:  2.15273\n",
      "2690 loss:  2.15269\n",
      "2691 loss:  2.1527\n",
      "2692 loss:  2.15272\n",
      "2693 loss:  2.15265\n",
      "2694 loss:  2.15259\n",
      "2695 loss:  2.15256\n",
      "2696 loss:  2.15255\n",
      "2697 loss:  2.15253\n",
      "2698 loss:  2.15252\n",
      "2699 loss:  2.1525\n",
      "2700 loss:  2.15247\n",
      "2701 loss:  2.15244\n",
      "2702 loss:  2.15241\n",
      "2703 loss:  2.15239\n",
      "2704 loss:  2.15237\n",
      "2705 loss:  2.15235\n",
      "2706 loss:  2.15233\n",
      "2707 loss:  2.1523\n",
      "2708 loss:  2.15228\n",
      "2709 loss:  2.15226\n",
      "2710 loss:  2.15223\n",
      "2711 loss:  2.1522\n",
      "2712 loss:  2.15218\n",
      "2713 loss:  2.15215\n",
      "2714 loss:  2.15213\n",
      "2715 loss:  2.1521\n",
      "2716 loss:  2.15207\n",
      "2717 loss:  2.15204\n",
      "2718 loss:  2.152\n",
      "2719 loss:  2.15197\n",
      "2720 loss:  2.15194\n",
      "2721 loss:  2.15191\n",
      "2722 loss:  2.15189\n",
      "2723 loss:  2.15187\n",
      "2724 loss:  2.15185\n",
      "2725 loss:  2.15183\n",
      "2726 loss:  2.15181\n",
      "2727 loss:  2.15179\n",
      "2728 loss:  2.15174\n",
      "2729 loss:  2.15165\n",
      "2730 loss:  2.15155\n",
      "2731 loss:  2.1515\n",
      "2732 loss:  2.15151\n",
      "2733 loss:  2.15149\n",
      "2734 loss:  2.15144\n",
      "2735 loss:  2.1514\n",
      "2736 loss:  2.15137\n",
      "2737 loss:  2.15135\n",
      "2738 loss:  2.15131\n",
      "2739 loss:  2.15127\n",
      "2740 loss:  2.15124\n",
      "2741 loss:  2.15122\n",
      "2742 loss:  2.15119\n",
      "2743 loss:  2.15116\n",
      "2744 loss:  2.15112\n",
      "2745 loss:  2.15108\n",
      "2746 loss:  2.15104\n",
      "2747 loss:  2.15099\n",
      "2748 loss:  2.15095\n",
      "2749 loss:  2.15093\n",
      "2750 loss:  2.15091\n",
      "2751 loss:  2.1509\n",
      "2752 loss:  2.15089\n",
      "2753 loss:  2.15088\n",
      "2754 loss:  2.15087\n",
      "2755 loss:  2.15086\n",
      "2756 loss:  2.15084\n",
      "2757 loss:  2.15083\n",
      "2758 loss:  2.15081\n",
      "2759 loss:  2.15079\n",
      "2760 loss:  2.15077\n",
      "2761 loss:  2.15072\n",
      "2762 loss:  2.15069\n",
      "2763 loss:  2.15068\n",
      "2764 loss:  2.15067\n",
      "2765 loss:  2.15066\n",
      "2766 loss:  2.15065\n",
      "2767 loss:  2.15063\n",
      "2768 loss:  2.15062\n",
      "2769 loss:  2.1506\n",
      "2770 loss:  2.15059\n",
      "2771 loss:  2.15057\n",
      "2772 loss:  2.15056\n",
      "2773 loss:  2.15055\n",
      "2774 loss:  2.15055\n",
      "2775 loss:  2.15054\n",
      "2776 loss:  2.15053\n",
      "2777 loss:  2.15052\n",
      "2778 loss:  2.15051\n",
      "2779 loss:  2.1505\n",
      "2780 loss:  2.15049\n",
      "2781 loss:  2.15046\n",
      "2782 loss:  2.15043\n",
      "2783 loss:  2.15038\n",
      "2784 loss:  2.15037\n",
      "2785 loss:  2.15036\n",
      "2786 loss:  2.15035\n",
      "2787 loss:  2.15036\n",
      "2788 loss:  2.15036\n",
      "2789 loss:  2.15035\n",
      "2790 loss:  2.15035\n",
      "2791 loss:  2.15034\n",
      "2792 loss:  2.15034\n",
      "2793 loss:  2.15033\n",
      "2794 loss:  2.15032\n",
      "2795 loss:  2.15031\n",
      "2796 loss:  2.15029\n",
      "2797 loss:  2.15028\n",
      "2798 loss:  2.15025\n",
      "2799 loss:  2.1502\n",
      "2800 loss:  2.15024\n",
      "2801 loss:  2.15016\n",
      "2802 loss:  2.15017\n",
      "2803 loss:  2.15017\n",
      "2804 loss:  2.15013\n",
      "2805 loss:  2.15011\n",
      "2806 loss:  2.15011\n",
      "2807 loss:  2.15007\n",
      "2808 loss:  2.15007\n",
      "2809 loss:  2.15003\n",
      "2810 loss:  2.15\n",
      "2811 loss:  2.14997\n",
      "2812 loss:  2.14993\n",
      "2813 loss:  2.14991\n",
      "2814 loss:  2.14988\n",
      "2815 loss:  2.14985\n",
      "2816 loss:  2.14985\n",
      "2817 loss:  2.14983\n",
      "2818 loss:  2.14982\n",
      "2819 loss:  2.1498\n",
      "2820 loss:  2.14978\n",
      "2821 loss:  2.14977\n",
      "2822 loss:  2.14976\n",
      "2823 loss:  2.14974\n",
      "2824 loss:  2.14973\n",
      "2825 loss:  2.14972\n",
      "2826 loss:  2.14971\n",
      "2827 loss:  2.1497\n",
      "2828 loss:  2.14969\n",
      "2829 loss:  2.14967\n",
      "2830 loss:  2.14966\n",
      "2831 loss:  2.14965\n",
      "2832 loss:  2.14964\n",
      "2833 loss:  2.14963\n",
      "2834 loss:  2.14961\n",
      "2835 loss:  2.14959\n",
      "2836 loss:  2.14957\n",
      "2837 loss:  2.14955\n",
      "2838 loss:  2.14952\n",
      "2839 loss:  2.14948\n",
      "2840 loss:  2.14943\n",
      "2841 loss:  2.14938\n",
      "2842 loss:  2.14932\n",
      "2843 loss:  2.14954\n",
      "2844 loss:  2.14928\n",
      "2845 loss:  2.14946\n",
      "2846 loss:  2.14947\n",
      "2847 loss:  2.1494\n",
      "2848 loss:  2.14934\n",
      "2849 loss:  2.14928\n",
      "2850 loss:  2.14939\n",
      "2851 loss:  2.14951\n",
      "2852 loss:  2.14952\n",
      "2853 loss:  2.14946\n",
      "2854 loss:  2.14947\n",
      "2855 loss:  2.14929\n",
      "2856 loss:  2.14917\n",
      "2857 loss:  2.14917\n",
      "2858 loss:  2.14915\n",
      "2859 loss:  2.14911\n",
      "2860 loss:  2.14905\n",
      "2861 loss:  2.149\n",
      "2862 loss:  2.14896\n",
      "2863 loss:  2.14891\n",
      "2864 loss:  2.14888\n",
      "2865 loss:  2.14885\n",
      "2866 loss:  2.14883\n",
      "2867 loss:  2.1488\n",
      "2868 loss:  2.14876\n",
      "2869 loss:  2.14872\n",
      "2870 loss:  2.1487\n",
      "2871 loss:  2.14868\n",
      "2872 loss:  2.14867\n",
      "2873 loss:  2.14863\n",
      "2874 loss:  2.14858\n",
      "2875 loss:  2.14855\n",
      "2876 loss:  2.14854\n",
      "2877 loss:  2.14852\n",
      "2878 loss:  2.14852\n",
      "2879 loss:  2.1485\n",
      "2880 loss:  2.14848\n",
      "2881 loss:  2.14846\n",
      "2882 loss:  2.14844\n",
      "2883 loss:  2.14841\n",
      "2884 loss:  2.14836\n",
      "2885 loss:  2.14829\n",
      "2886 loss:  2.14821\n",
      "2887 loss:  2.14815\n",
      "2888 loss:  2.14811\n",
      "2889 loss:  2.14809\n",
      "2890 loss:  2.14806\n",
      "2891 loss:  2.14805\n",
      "2892 loss:  2.14803\n",
      "2893 loss:  2.14801\n",
      "2894 loss:  2.14797\n",
      "2895 loss:  2.14793\n",
      "2896 loss:  2.14789\n",
      "2897 loss:  2.14783\n",
      "2898 loss:  2.14778\n",
      "2899 loss:  2.14772\n",
      "2900 loss:  2.14764\n",
      "2901 loss:  2.14754\n",
      "2902 loss:  2.14746\n",
      "2903 loss:  2.14738\n",
      "2904 loss:  2.14731\n",
      "2905 loss:  2.14729\n",
      "2906 loss:  2.14725\n",
      "2907 loss:  2.14719\n",
      "2908 loss:  2.14717\n",
      "2909 loss:  2.14714\n",
      "2910 loss:  2.1471\n",
      "2911 loss:  2.14706\n",
      "2912 loss:  2.14702\n",
      "2913 loss:  2.14697\n",
      "2914 loss:  2.1469\n",
      "2915 loss:  2.14684\n",
      "2916 loss:  2.14675\n",
      "2917 loss:  2.14668\n",
      "2918 loss:  2.14663\n",
      "2919 loss:  2.1466\n",
      "2920 loss:  2.14655\n",
      "2921 loss:  2.14648\n",
      "2922 loss:  2.14642\n",
      "2923 loss:  2.14637\n",
      "2924 loss:  2.14635\n",
      "2925 loss:  2.14632\n",
      "2926 loss:  2.14628\n",
      "2927 loss:  2.14621\n",
      "2928 loss:  2.14616\n",
      "2929 loss:  2.14614\n",
      "2930 loss:  2.1461\n",
      "2931 loss:  2.14605\n",
      "2932 loss:  2.14601\n",
      "2933 loss:  2.14593\n",
      "2934 loss:  2.14579\n",
      "2935 loss:  2.14683\n",
      "2936 loss:  2.15024\n",
      "2937 loss:  2.16366\n",
      "2938 loss:  2.15196\n",
      "2939 loss:  2.15387\n",
      "2940 loss:  2.15758\n",
      "2941 loss:  2.16038\n",
      "2942 loss:  2.15918\n",
      "2943 loss:  2.15996\n",
      "2944 loss:  2.1588\n",
      "2945 loss:  2.16456\n",
      "2946 loss:  2.1629\n",
      "2947 loss:  2.16386\n",
      "2948 loss:  2.16113\n",
      "2949 loss:  2.16377\n",
      "2950 loss:  2.16231\n",
      "2951 loss:  2.16065\n",
      "2952 loss:  2.15858\n",
      "2953 loss:  2.15809\n",
      "2954 loss:  2.15786\n",
      "2955 loss:  2.15589\n",
      "2956 loss:  2.15473\n",
      "2957 loss:  2.15416\n",
      "2958 loss:  2.15354\n",
      "2959 loss:  2.15333\n",
      "2960 loss:  2.15236\n",
      "2961 loss:  2.15182\n",
      "2962 loss:  2.15159\n",
      "2963 loss:  2.15141\n",
      "2964 loss:  2.15032\n",
      "2965 loss:  2.14976\n",
      "2966 loss:  2.14927\n",
      "2967 loss:  2.14877\n",
      "2968 loss:  2.14873\n",
      "2969 loss:  2.1479\n",
      "2970 loss:  2.14777\n",
      "2971 loss:  2.14739\n",
      "2972 loss:  2.1472\n",
      "2973 loss:  2.14686\n",
      "2974 loss:  2.14666\n",
      "2975 loss:  2.14646\n",
      "2976 loss:  2.14625\n",
      "2977 loss:  2.14624\n",
      "2978 loss:  2.146\n",
      "2979 loss:  2.14587\n",
      "2980 loss:  2.1456\n",
      "2981 loss:  2.14549\n",
      "2982 loss:  2.14526\n",
      "2983 loss:  2.14526\n",
      "2984 loss:  2.14508\n",
      "2985 loss:  2.14502\n",
      "2986 loss:  2.14486\n",
      "2987 loss:  2.14477\n",
      "2988 loss:  2.14445\n",
      "2989 loss:  2.14441\n",
      "2990 loss:  2.14426\n",
      "2991 loss:  2.14421\n",
      "2992 loss:  2.14413\n",
      "2993 loss:  2.14402\n",
      "2994 loss:  2.14394\n",
      "2995 loss:  2.14384\n",
      "2996 loss:  2.14373\n",
      "2997 loss:  2.14368\n",
      "2998 loss:  2.14366\n",
      "2999 loss:  2.14361\n",
      "3000 loss:  2.14356\n",
      "3001 loss:  2.14349\n",
      "3002 loss:  2.14348\n",
      "3003 loss:  2.14345\n",
      "3004 loss:  2.14347\n",
      "3005 loss:  2.1434\n",
      "3006 loss:  2.14332\n",
      "3007 loss:  2.1433\n",
      "3008 loss:  2.14325\n",
      "3009 loss:  2.14324\n",
      "3010 loss:  2.14325\n",
      "3011 loss:  2.14315\n",
      "3012 loss:  2.14327\n",
      "3013 loss:  2.1434\n",
      "3014 loss:  2.1433\n",
      "3015 loss:  2.1435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3016 loss:  2.14338\n",
      "3017 loss:  2.14336\n",
      "3018 loss:  2.14333\n",
      "3019 loss:  2.1433\n",
      "3020 loss:  2.14322\n",
      "3021 loss:  2.14317\n",
      "3022 loss:  2.14305\n",
      "3023 loss:  2.143\n",
      "3024 loss:  2.14292\n",
      "3025 loss:  2.14281\n",
      "3026 loss:  2.1428\n",
      "3027 loss:  2.14277\n",
      "3028 loss:  2.14272\n",
      "3029 loss:  2.14266\n",
      "3030 loss:  2.14265\n",
      "3031 loss:  2.14258\n",
      "3032 loss:  2.14251\n",
      "3033 loss:  2.14249\n",
      "3034 loss:  2.14242\n",
      "3035 loss:  2.14236\n",
      "3036 loss:  2.14232\n",
      "3037 loss:  2.14226\n",
      "3038 loss:  2.14221\n",
      "3039 loss:  2.14217\n",
      "3040 loss:  2.1421\n",
      "3041 loss:  2.14204\n",
      "3042 loss:  2.142\n",
      "3043 loss:  2.14193\n",
      "3044 loss:  2.14187\n",
      "3045 loss:  2.1418\n",
      "3046 loss:  2.14175\n",
      "3047 loss:  2.14171\n",
      "3048 loss:  2.14169\n",
      "3049 loss:  2.14166\n",
      "3050 loss:  2.14163\n",
      "3051 loss:  2.1416\n",
      "3052 loss:  2.14156\n",
      "3053 loss:  2.14151\n",
      "3054 loss:  2.14166\n",
      "3055 loss:  2.14147\n",
      "3056 loss:  2.14144\n",
      "3057 loss:  2.14143\n",
      "3058 loss:  2.1414\n",
      "3059 loss:  2.14139\n",
      "3060 loss:  2.14137\n",
      "3061 loss:  2.14135\n",
      "3062 loss:  2.14134\n",
      "3063 loss:  2.14133\n",
      "3064 loss:  2.14132\n",
      "3065 loss:  2.1413\n",
      "3066 loss:  2.14128\n",
      "3067 loss:  2.14126\n",
      "3068 loss:  2.14124\n",
      "3069 loss:  2.14123\n",
      "3070 loss:  2.14122\n",
      "3071 loss:  2.14121\n",
      "3072 loss:  2.14119\n",
      "3073 loss:  2.14118\n",
      "3074 loss:  2.14117\n",
      "3075 loss:  2.14116\n",
      "3076 loss:  2.14114\n",
      "3077 loss:  2.14113\n",
      "3078 loss:  2.14111\n",
      "3079 loss:  2.14108\n",
      "3080 loss:  2.14105\n",
      "3081 loss:  2.14101\n",
      "3082 loss:  2.14097\n",
      "3083 loss:  2.14095\n",
      "3084 loss:  2.14093\n",
      "3085 loss:  2.1409\n",
      "3086 loss:  2.14089\n",
      "3087 loss:  2.14087\n",
      "3088 loss:  2.14085\n",
      "3089 loss:  2.14084\n",
      "3090 loss:  2.14083\n",
      "3091 loss:  2.14081\n",
      "3092 loss:  2.1408\n",
      "3093 loss:  2.14079\n",
      "3094 loss:  2.14078\n",
      "3095 loss:  2.14077\n",
      "3096 loss:  2.14076\n",
      "3097 loss:  2.14076\n",
      "3098 loss:  2.14078\n",
      "3099 loss:  2.14075\n",
      "3100 loss:  2.14073\n",
      "3101 loss:  2.14072\n",
      "3102 loss:  2.14071\n",
      "3103 loss:  2.14071\n",
      "3104 loss:  2.1407\n",
      "3105 loss:  2.14069\n",
      "3106 loss:  2.14067\n",
      "3107 loss:  2.14066\n",
      "3108 loss:  2.14065\n",
      "3109 loss:  2.14064\n",
      "3110 loss:  2.14062\n",
      "3111 loss:  2.1406\n",
      "3112 loss:  2.14057\n",
      "3113 loss:  2.14054\n",
      "3114 loss:  2.14052\n",
      "3115 loss:  2.1405\n",
      "3116 loss:  2.1405\n",
      "3117 loss:  2.14049\n",
      "3118 loss:  2.14049\n",
      "3119 loss:  2.14049\n",
      "3120 loss:  2.14048\n",
      "3121 loss:  2.14048\n",
      "3122 loss:  2.14047\n",
      "3123 loss:  2.14046\n",
      "3124 loss:  2.14046\n",
      "3125 loss:  2.14045\n",
      "3126 loss:  2.14044\n",
      "3127 loss:  2.14044\n",
      "3128 loss:  2.14043\n",
      "3129 loss:  2.14042\n",
      "3130 loss:  2.14041\n",
      "3131 loss:  2.14039\n",
      "3132 loss:  2.14036\n",
      "3133 loss:  2.14034\n",
      "3134 loss:  2.14032\n",
      "3135 loss:  2.14032\n",
      "3136 loss:  2.14031\n",
      "3137 loss:  2.14031\n",
      "3138 loss:  2.14029\n",
      "3139 loss:  2.14028\n",
      "3140 loss:  2.14027\n",
      "3141 loss:  2.14026\n",
      "3142 loss:  2.14025\n",
      "3143 loss:  2.14025\n",
      "3144 loss:  2.14024\n",
      "3145 loss:  2.14023\n",
      "3146 loss:  2.14022\n",
      "3147 loss:  2.14021\n",
      "3148 loss:  2.1402\n",
      "3149 loss:  2.14018\n",
      "3150 loss:  2.14018\n",
      "3151 loss:  2.14015\n",
      "3152 loss:  2.14013\n",
      "3153 loss:  2.1401\n",
      "3154 loss:  2.14007\n",
      "3155 loss:  2.14004\n",
      "3156 loss:  2.14001\n",
      "3157 loss:  2.13996\n",
      "3158 loss:  2.13991\n",
      "3159 loss:  2.13986\n",
      "3160 loss:  2.13985\n",
      "3161 loss:  2.13984\n",
      "3162 loss:  2.13983\n",
      "3163 loss:  2.13981\n",
      "3164 loss:  2.13981\n",
      "3165 loss:  2.1398\n",
      "3166 loss:  2.13978\n",
      "3167 loss:  2.13978\n",
      "3168 loss:  2.13975\n",
      "3169 loss:  2.13974\n",
      "3170 loss:  2.13971\n",
      "3171 loss:  2.13969\n",
      "3172 loss:  2.13967\n",
      "3173 loss:  2.13966\n",
      "3174 loss:  2.13965\n",
      "3175 loss:  2.13963\n",
      "3176 loss:  2.1396\n",
      "3177 loss:  2.13956\n",
      "3178 loss:  2.13953\n",
      "3179 loss:  2.13949\n",
      "3180 loss:  2.13944\n",
      "3181 loss:  2.13941\n",
      "3182 loss:  2.13938\n",
      "3183 loss:  2.13936\n",
      "3184 loss:  2.13934\n",
      "3185 loss:  2.13933\n",
      "3186 loss:  2.13932\n",
      "3187 loss:  2.13931\n",
      "3188 loss:  2.13931\n",
      "3189 loss:  2.13929\n",
      "3190 loss:  2.13928\n",
      "3191 loss:  2.13926\n",
      "3192 loss:  2.13925\n",
      "3193 loss:  2.13924\n",
      "3194 loss:  2.13923\n",
      "3195 loss:  2.13922\n",
      "3196 loss:  2.13921\n",
      "3197 loss:  2.1392\n",
      "3198 loss:  2.1392\n",
      "3199 loss:  2.13919\n",
      "3200 loss:  2.13918\n",
      "3201 loss:  2.13917\n",
      "3202 loss:  2.13916\n",
      "3203 loss:  2.13915\n",
      "3204 loss:  2.13915\n",
      "3205 loss:  2.13914\n",
      "3206 loss:  2.13913\n",
      "3207 loss:  2.13913\n",
      "3208 loss:  2.13912\n",
      "3209 loss:  2.13911\n",
      "3210 loss:  2.13911\n",
      "3211 loss:  2.1391\n",
      "3212 loss:  2.1391\n",
      "3213 loss:  2.1391\n",
      "3214 loss:  2.13909\n",
      "3215 loss:  2.13908\n",
      "3216 loss:  2.13906\n",
      "3217 loss:  2.13906\n",
      "3218 loss:  2.13908\n",
      "3219 loss:  2.13906\n",
      "3220 loss:  2.13904\n",
      "3221 loss:  2.13906\n",
      "3222 loss:  2.13904\n",
      "3223 loss:  2.13907\n",
      "3224 loss:  2.13906\n",
      "3225 loss:  2.13904\n",
      "3226 loss:  2.139\n",
      "3227 loss:  2.13895\n",
      "3228 loss:  2.13893\n",
      "3229 loss:  2.13893\n",
      "3230 loss:  2.13893\n",
      "3231 loss:  2.13889\n",
      "3232 loss:  2.13887\n",
      "3233 loss:  2.13887\n",
      "3234 loss:  2.13887\n",
      "3235 loss:  2.13886\n",
      "3236 loss:  2.13884\n",
      "3237 loss:  2.13884\n",
      "3238 loss:  2.13884\n",
      "3239 loss:  2.13882\n",
      "3240 loss:  2.13881\n",
      "3241 loss:  2.1388\n",
      "3242 loss:  2.1388\n",
      "3243 loss:  2.13879\n",
      "3244 loss:  2.13878\n",
      "3245 loss:  2.13877\n",
      "3246 loss:  2.13876\n",
      "3247 loss:  2.13874\n",
      "3248 loss:  2.13873\n",
      "3249 loss:  2.13872\n",
      "3250 loss:  2.13871\n",
      "3251 loss:  2.13869\n",
      "3252 loss:  2.13867\n",
      "3253 loss:  2.13865\n",
      "3254 loss:  2.13862\n",
      "3255 loss:  2.1386\n",
      "3256 loss:  2.13855\n",
      "3257 loss:  2.13847\n",
      "3258 loss:  2.13839\n",
      "3259 loss:  2.13836\n",
      "3260 loss:  2.13834\n",
      "3261 loss:  2.13832\n",
      "3262 loss:  2.13829\n",
      "3263 loss:  2.13825\n",
      "3264 loss:  2.13823\n",
      "3265 loss:  2.1382\n",
      "3266 loss:  2.13812\n",
      "3267 loss:  2.13804\n",
      "3268 loss:  2.13794\n",
      "3269 loss:  2.13782\n",
      "3270 loss:  2.13769\n",
      "3271 loss:  2.13761\n",
      "3272 loss:  2.13752\n",
      "3273 loss:  2.13742\n",
      "3274 loss:  2.13731\n",
      "3275 loss:  2.13722\n",
      "3276 loss:  2.13716\n",
      "3277 loss:  2.13705\n",
      "3278 loss:  2.13697\n",
      "3279 loss:  2.13686\n",
      "3280 loss:  2.13673\n",
      "3281 loss:  2.13664\n",
      "3282 loss:  2.13654\n",
      "3283 loss:  2.13645\n",
      "3284 loss:  2.13636\n",
      "3285 loss:  2.1363\n",
      "3286 loss:  2.13622\n",
      "3287 loss:  2.13616\n",
      "3288 loss:  2.13609\n",
      "3289 loss:  2.13598\n",
      "3290 loss:  2.13588\n",
      "3291 loss:  2.13581\n",
      "3292 loss:  2.13575\n",
      "3293 loss:  2.13568\n",
      "3294 loss:  2.13559\n",
      "3295 loss:  2.13554\n",
      "3296 loss:  2.13548\n",
      "3297 loss:  2.13545\n",
      "3298 loss:  2.13541\n",
      "3299 loss:  2.13534\n",
      "3300 loss:  2.13527\n",
      "3301 loss:  2.13521\n",
      "3302 loss:  2.13517\n",
      "3303 loss:  2.13513\n",
      "3304 loss:  2.1351\n",
      "3305 loss:  2.13506\n",
      "3306 loss:  2.13502\n",
      "3307 loss:  2.13497\n",
      "3308 loss:  2.13494\n",
      "3309 loss:  2.13489\n",
      "3310 loss:  2.13485\n",
      "3311 loss:  2.13476\n",
      "3312 loss:  2.13466\n",
      "3313 loss:  2.13462\n",
      "3314 loss:  2.13458\n",
      "3315 loss:  2.13455\n",
      "3316 loss:  2.13453\n",
      "3317 loss:  2.1345\n",
      "3318 loss:  2.13446\n",
      "3319 loss:  2.13441\n",
      "3320 loss:  2.13438\n",
      "3321 loss:  2.13432\n",
      "3322 loss:  2.13428\n",
      "3323 loss:  2.13421\n",
      "3324 loss:  2.1341\n",
      "3325 loss:  2.13403\n",
      "3326 loss:  2.13402\n",
      "3327 loss:  2.13402\n",
      "3328 loss:  2.13397\n",
      "3329 loss:  2.13393\n",
      "3330 loss:  2.1339\n",
      "3331 loss:  2.13386\n",
      "3332 loss:  2.13384\n",
      "3333 loss:  2.13381\n",
      "3334 loss:  2.13379\n",
      "3335 loss:  2.13377\n",
      "3336 loss:  2.13375\n",
      "3337 loss:  2.13372\n",
      "3338 loss:  2.1337\n",
      "3339 loss:  2.13367\n",
      "3340 loss:  2.13365\n",
      "3341 loss:  2.13362\n",
      "3342 loss:  2.13359\n",
      "3343 loss:  2.13356\n",
      "3344 loss:  2.13354\n",
      "3345 loss:  2.13352\n",
      "3346 loss:  2.13349\n",
      "3347 loss:  2.13347\n",
      "3348 loss:  2.13345\n",
      "3349 loss:  2.13343\n",
      "3350 loss:  2.13341\n",
      "3351 loss:  2.13339\n",
      "3352 loss:  2.13337\n",
      "3353 loss:  2.13336\n",
      "3354 loss:  2.13334\n",
      "3355 loss:  2.13333\n",
      "3356 loss:  2.13331\n",
      "3357 loss:  2.1333\n",
      "3358 loss:  2.13328\n",
      "3359 loss:  2.13326\n",
      "3360 loss:  2.13322\n",
      "3361 loss:  2.13317\n",
      "3362 loss:  2.13308\n",
      "3363 loss:  2.13301\n",
      "3364 loss:  2.13296\n",
      "3365 loss:  2.13294\n",
      "3366 loss:  2.13291\n",
      "3367 loss:  2.1329\n",
      "3368 loss:  2.13279\n",
      "3369 loss:  2.13258\n",
      "3370 loss:  2.13257\n",
      "3371 loss:  2.13256\n",
      "3372 loss:  2.14076\n",
      "3373 loss:  2.13528\n",
      "3374 loss:  2.13847\n",
      "3375 loss:  2.13863\n",
      "3376 loss:  2.14802\n",
      "3377 loss:  2.15225\n",
      "3378 loss:  2.15846\n",
      "3379 loss:  2.16825\n",
      "3380 loss:  2.15606\n",
      "3381 loss:  2.15499\n",
      "3382 loss:  2.15861\n",
      "3383 loss:  2.15441\n",
      "3384 loss:  2.15587\n",
      "3385 loss:  2.15874\n",
      "3386 loss:  2.16483\n",
      "3387 loss:  2.17325\n",
      "3388 loss:  2.17177\n",
      "3389 loss:  2.17411\n",
      "3390 loss:  2.17336\n",
      "3391 loss:  2.17064\n",
      "3392 loss:  2.16214\n",
      "3393 loss:  2.16891\n",
      "3394 loss:  2.16881\n",
      "3395 loss:  2.16736\n",
      "3396 loss:  2.1671\n",
      "3397 loss:  2.16514\n",
      "3398 loss:  2.16153\n",
      "3399 loss:  2.15999\n",
      "3400 loss:  2.16106\n",
      "3401 loss:  2.15716\n",
      "3402 loss:  2.15331\n",
      "3403 loss:  2.15326\n",
      "3404 loss:  2.15375\n",
      "3405 loss:  2.15536\n",
      "3406 loss:  2.15796\n",
      "3407 loss:  2.15105\n",
      "3408 loss:  2.15356\n",
      "3409 loss:  2.1526\n",
      "3410 loss:  2.15084\n",
      "3411 loss:  2.14973\n",
      "3412 loss:  2.14958\n",
      "3413 loss:  2.14605\n",
      "3414 loss:  2.14449\n",
      "3415 loss:  2.14495\n",
      "3416 loss:  2.14453\n",
      "3417 loss:  2.14288\n",
      "3418 loss:  2.14385\n",
      "3419 loss:  2.14323\n",
      "3420 loss:  2.14305\n",
      "3421 loss:  2.14638\n",
      "3422 loss:  2.1432\n",
      "3423 loss:  2.14438\n",
      "3424 loss:  2.14462\n",
      "3425 loss:  2.14383\n",
      "3426 loss:  2.14347\n",
      "3427 loss:  2.14247\n",
      "3428 loss:  2.14248\n",
      "3429 loss:  2.14305\n",
      "3430 loss:  2.14207\n",
      "3431 loss:  2.14296\n",
      "3432 loss:  2.14317\n",
      "3433 loss:  2.14156\n",
      "3434 loss:  2.14065\n",
      "3435 loss:  2.14128\n",
      "3436 loss:  2.14128\n",
      "3437 loss:  2.14073\n",
      "3438 loss:  2.14082\n",
      "3439 loss:  2.13962\n",
      "3440 loss:  2.13923\n",
      "3441 loss:  2.13893\n",
      "3442 loss:  2.13637\n",
      "3443 loss:  2.13594\n",
      "3444 loss:  2.13665\n",
      "3445 loss:  2.13572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3446 loss:  2.13595\n",
      "3447 loss:  2.13552\n",
      "3448 loss:  2.13465\n",
      "3449 loss:  2.13396\n",
      "3450 loss:  2.13331\n",
      "3451 loss:  2.13347\n",
      "3452 loss:  2.13324\n",
      "3453 loss:  2.13266\n",
      "3454 loss:  2.13263\n",
      "3455 loss:  2.13239\n",
      "3456 loss:  2.1316\n",
      "3457 loss:  2.13131\n",
      "3458 loss:  2.13102\n",
      "3459 loss:  2.13073\n",
      "3460 loss:  2.13028\n",
      "3461 loss:  2.13015\n",
      "3462 loss:  2.12957\n",
      "3463 loss:  2.12924\n",
      "3464 loss:  2.12907\n",
      "3465 loss:  2.13033\n",
      "3466 loss:  2.12932\n",
      "3467 loss:  2.12951\n",
      "3468 loss:  2.13571\n",
      "3469 loss:  2.14558\n",
      "3470 loss:  2.14313\n",
      "3471 loss:  2.1447\n",
      "3472 loss:  2.14127\n",
      "3473 loss:  2.14121\n",
      "3474 loss:  2.1416\n",
      "3475 loss:  2.13927\n",
      "3476 loss:  2.13808\n",
      "3477 loss:  2.137\n",
      "3478 loss:  2.13494\n",
      "3479 loss:  2.13417\n",
      "3480 loss:  2.13579\n",
      "3481 loss:  2.13394\n",
      "3482 loss:  2.1337\n",
      "3483 loss:  2.13309\n",
      "3484 loss:  2.13386\n",
      "3485 loss:  2.13541\n",
      "3486 loss:  2.13462\n",
      "3487 loss:  2.13456\n",
      "3488 loss:  2.13277\n",
      "3489 loss:  2.1313\n",
      "3490 loss:  2.13108\n",
      "3491 loss:  2.131\n",
      "3492 loss:  2.12977\n",
      "3493 loss:  2.12874\n",
      "3494 loss:  2.1316\n",
      "3495 loss:  2.13439\n",
      "3496 loss:  2.12911\n",
      "3497 loss:  2.12914\n",
      "3498 loss:  2.12948\n",
      "3499 loss:  2.1284\n",
      "3500 loss:  2.12795\n",
      "3501 loss:  2.12738\n",
      "3502 loss:  2.12694\n",
      "3503 loss:  2.12668\n",
      "3504 loss:  2.12882\n",
      "3505 loss:  2.12806\n",
      "3506 loss:  2.12732\n",
      "3507 loss:  2.12718\n",
      "3508 loss:  2.12725\n",
      "3509 loss:  2.12646\n",
      "3510 loss:  2.12634\n",
      "3511 loss:  2.12561\n",
      "3512 loss:  2.12549\n",
      "3513 loss:  2.12565\n",
      "3514 loss:  2.12508\n",
      "3515 loss:  2.12486\n",
      "3516 loss:  2.12474\n",
      "3517 loss:  2.12452\n",
      "3518 loss:  2.12431\n",
      "3519 loss:  2.12418\n",
      "3520 loss:  2.12398\n",
      "3521 loss:  2.12359\n",
      "3522 loss:  2.12313\n",
      "3523 loss:  2.12312\n",
      "3524 loss:  2.12286\n",
      "3525 loss:  2.12273\n",
      "3526 loss:  2.12262\n",
      "3527 loss:  2.12249\n",
      "3528 loss:  2.12238\n",
      "3529 loss:  2.12226\n",
      "3530 loss:  2.12214\n",
      "3531 loss:  2.12198\n",
      "3532 loss:  2.12182\n",
      "3533 loss:  2.12177\n",
      "3534 loss:  2.12163\n",
      "3535 loss:  2.12144\n",
      "3536 loss:  2.12127\n",
      "3537 loss:  2.12121\n",
      "3538 loss:  2.12106\n",
      "3539 loss:  2.12098\n",
      "3540 loss:  2.1209\n",
      "3541 loss:  2.12077\n",
      "3542 loss:  2.12066\n",
      "3543 loss:  2.12054\n",
      "3544 loss:  2.12036\n",
      "3545 loss:  2.12019\n",
      "3546 loss:  2.12003\n",
      "3547 loss:  2.11991\n",
      "3548 loss:  2.11974\n",
      "3549 loss:  2.11958\n",
      "3550 loss:  2.11945\n",
      "3551 loss:  2.11934\n",
      "3552 loss:  2.11923\n",
      "3553 loss:  2.11917\n",
      "3554 loss:  2.11907\n",
      "3555 loss:  2.11899\n",
      "3556 loss:  2.11892\n",
      "3557 loss:  2.1188\n",
      "3558 loss:  2.11872\n",
      "3559 loss:  2.11866\n",
      "3560 loss:  2.11864\n",
      "3561 loss:  2.11871\n",
      "3562 loss:  2.11857\n",
      "3563 loss:  2.11904\n",
      "3564 loss:  2.12496\n",
      "3565 loss:  2.12617\n",
      "3566 loss:  2.12473\n",
      "3567 loss:  2.12291\n",
      "3568 loss:  2.1246\n",
      "3569 loss:  2.13\n",
      "3570 loss:  2.12948\n",
      "3571 loss:  2.12658\n",
      "3572 loss:  2.12447\n",
      "3573 loss:  2.12627\n",
      "3574 loss:  2.12638\n",
      "3575 loss:  2.12931\n",
      "3576 loss:  2.12898\n",
      "3577 loss:  2.13121\n",
      "3578 loss:  2.12569\n",
      "3579 loss:  2.12486\n",
      "3580 loss:  2.12514\n",
      "3581 loss:  2.12564\n",
      "3582 loss:  2.12613\n",
      "3583 loss:  2.12533\n",
      "3584 loss:  2.12472\n",
      "3585 loss:  2.12439\n",
      "3586 loss:  2.12419\n",
      "3587 loss:  2.12418\n",
      "3588 loss:  2.12388\n",
      "3589 loss:  2.12373\n",
      "3590 loss:  2.12365\n",
      "3591 loss:  2.12357\n",
      "3592 loss:  2.12325\n",
      "3593 loss:  2.12267\n",
      "3594 loss:  2.12252\n",
      "3595 loss:  2.12229\n",
      "3596 loss:  2.12219\n",
      "3597 loss:  2.12208\n",
      "3598 loss:  2.122\n",
      "3599 loss:  2.12188\n",
      "3600 loss:  2.12168\n",
      "3601 loss:  2.12153\n",
      "3602 loss:  2.1214\n",
      "3603 loss:  2.12125\n",
      "3604 loss:  2.12113\n",
      "3605 loss:  2.12106\n",
      "3606 loss:  2.12099\n",
      "3607 loss:  2.12092\n",
      "3608 loss:  2.12085\n",
      "3609 loss:  2.12077\n",
      "3610 loss:  2.1207\n",
      "3611 loss:  2.12065\n",
      "3612 loss:  2.12059\n",
      "3613 loss:  2.12054\n",
      "3614 loss:  2.1205\n",
      "3615 loss:  2.12046\n",
      "3616 loss:  2.1204\n",
      "3617 loss:  2.12036\n",
      "3618 loss:  2.12031\n",
      "3619 loss:  2.12027\n",
      "3620 loss:  2.12023\n",
      "3621 loss:  2.12019\n",
      "3622 loss:  2.12015\n",
      "3623 loss:  2.12012\n",
      "3624 loss:  2.12008\n",
      "3625 loss:  2.12004\n",
      "3626 loss:  2.12002\n",
      "3627 loss:  2.11999\n",
      "3628 loss:  2.11997\n",
      "3629 loss:  2.11994\n",
      "3630 loss:  2.11992\n",
      "3631 loss:  2.11989\n",
      "3632 loss:  2.11987\n",
      "3633 loss:  2.11985\n",
      "3634 loss:  2.11982\n",
      "3635 loss:  2.11979\n",
      "3636 loss:  2.11977\n",
      "3637 loss:  2.11974\n",
      "3638 loss:  2.1197\n",
      "3639 loss:  2.11966\n",
      "3640 loss:  2.11963\n",
      "3641 loss:  2.11958\n",
      "3642 loss:  2.11954\n",
      "3643 loss:  2.11951\n",
      "3644 loss:  2.11948\n",
      "3645 loss:  2.11945\n",
      "3646 loss:  2.11942\n",
      "3647 loss:  2.11938\n",
      "3648 loss:  2.11935\n",
      "3649 loss:  2.11932\n",
      "3650 loss:  2.1193\n",
      "3651 loss:  2.11928\n",
      "3652 loss:  2.11926\n",
      "3653 loss:  2.11924\n",
      "3654 loss:  2.11921\n",
      "3655 loss:  2.11918\n",
      "3656 loss:  2.11913\n",
      "3657 loss:  2.11908\n",
      "3658 loss:  2.119\n",
      "3659 loss:  2.1189\n",
      "3660 loss:  2.11881\n",
      "3661 loss:  2.11877\n",
      "3662 loss:  2.11872\n",
      "3663 loss:  2.11868\n",
      "3664 loss:  2.11864\n",
      "3665 loss:  2.11861\n",
      "3666 loss:  2.11859\n",
      "3667 loss:  2.11855\n",
      "3668 loss:  2.11853\n",
      "3669 loss:  2.11851\n",
      "3670 loss:  2.11849\n",
      "3671 loss:  2.11846\n",
      "3672 loss:  2.11844\n",
      "3673 loss:  2.11842\n",
      "3674 loss:  2.1184\n",
      "3675 loss:  2.11837\n",
      "3676 loss:  2.11835\n",
      "3677 loss:  2.11834\n",
      "3678 loss:  2.11832\n",
      "3679 loss:  2.1183\n",
      "3680 loss:  2.11829\n",
      "3681 loss:  2.11827\n",
      "3682 loss:  2.11826\n",
      "3683 loss:  2.11824\n",
      "3684 loss:  2.11823\n",
      "3685 loss:  2.11821\n",
      "3686 loss:  2.1182\n",
      "3687 loss:  2.11818\n",
      "3688 loss:  2.11817\n",
      "3689 loss:  2.11815\n",
      "3690 loss:  2.11813\n",
      "3691 loss:  2.11812\n",
      "3692 loss:  2.1181\n",
      "3693 loss:  2.11808\n",
      "3694 loss:  2.11805\n",
      "3695 loss:  2.11799\n",
      "3696 loss:  2.11797\n",
      "3697 loss:  2.11795\n",
      "3698 loss:  2.11793\n",
      "3699 loss:  2.11788\n",
      "3700 loss:  2.1178\n",
      "3701 loss:  2.11769\n",
      "3702 loss:  2.1177\n",
      "3703 loss:  2.11753\n",
      "3704 loss:  2.11746\n",
      "3705 loss:  2.11741\n",
      "3706 loss:  2.11732\n",
      "3707 loss:  2.11727\n",
      "3708 loss:  2.11726\n",
      "3709 loss:  2.11721\n",
      "3710 loss:  2.11715\n",
      "3711 loss:  2.11711\n",
      "3712 loss:  2.11709\n",
      "3713 loss:  2.11706\n",
      "3714 loss:  2.11703\n",
      "3715 loss:  2.11701\n",
      "3716 loss:  2.11699\n",
      "3717 loss:  2.11697\n",
      "3718 loss:  2.11695\n",
      "3719 loss:  2.11693\n",
      "3720 loss:  2.11691\n",
      "3721 loss:  2.11689\n",
      "3722 loss:  2.11687\n",
      "3723 loss:  2.11685\n",
      "3724 loss:  2.11683\n",
      "3725 loss:  2.11679\n",
      "3726 loss:  2.11675\n",
      "3727 loss:  2.1167\n",
      "3728 loss:  2.11669\n",
      "3729 loss:  2.11667\n",
      "3730 loss:  2.11663\n",
      "3731 loss:  2.1166\n",
      "3732 loss:  2.11658\n",
      "3733 loss:  2.11655\n",
      "3734 loss:  2.11652\n",
      "3735 loss:  2.11649\n",
      "3736 loss:  2.11645\n",
      "3737 loss:  2.11641\n",
      "3738 loss:  2.11637\n",
      "3739 loss:  2.11633\n",
      "3740 loss:  2.1163\n",
      "3741 loss:  2.11628\n",
      "3742 loss:  2.11626\n",
      "3743 loss:  2.11624\n",
      "3744 loss:  2.11622\n",
      "3745 loss:  2.1162\n",
      "3746 loss:  2.11618\n",
      "3747 loss:  2.11616\n",
      "3748 loss:  2.11614\n",
      "3749 loss:  2.11612\n",
      "3750 loss:  2.11611\n",
      "3751 loss:  2.11609\n",
      "3752 loss:  2.11608\n",
      "3753 loss:  2.11607\n",
      "3754 loss:  2.11605\n",
      "3755 loss:  2.11604\n",
      "3756 loss:  2.11602\n",
      "3757 loss:  2.116\n",
      "3758 loss:  2.11605\n",
      "3759 loss:  2.11599\n",
      "3760 loss:  2.11598\n",
      "3761 loss:  2.11597\n",
      "3762 loss:  2.11596\n",
      "3763 loss:  2.11594\n",
      "3764 loss:  2.11592\n",
      "3765 loss:  2.1159\n",
      "3766 loss:  2.11589\n",
      "3767 loss:  2.11587\n",
      "3768 loss:  2.11586\n",
      "3769 loss:  2.11585\n",
      "3770 loss:  2.11584\n",
      "3771 loss:  2.11583\n",
      "3772 loss:  2.11582\n",
      "3773 loss:  2.11581\n",
      "3774 loss:  2.1158\n",
      "3775 loss:  2.11579\n",
      "3776 loss:  2.11578\n",
      "3777 loss:  2.11577\n",
      "3778 loss:  2.11576\n",
      "3779 loss:  2.11575\n",
      "3780 loss:  2.11574\n",
      "3781 loss:  2.11572\n",
      "3782 loss:  2.11571\n",
      "3783 loss:  2.1157\n",
      "3784 loss:  2.11569\n",
      "3785 loss:  2.11568\n",
      "3786 loss:  2.11567\n",
      "3787 loss:  2.11566\n",
      "3788 loss:  2.11566\n",
      "3789 loss:  2.11565\n",
      "3790 loss:  2.11564\n",
      "3791 loss:  2.11563\n",
      "3792 loss:  2.11562\n",
      "3793 loss:  2.11561\n",
      "3794 loss:  2.11561\n",
      "3795 loss:  2.1156\n",
      "3796 loss:  2.11559\n",
      "3797 loss:  2.11558\n",
      "3798 loss:  2.11557\n",
      "3799 loss:  2.11556\n",
      "3800 loss:  2.11555\n",
      "3801 loss:  2.11554\n",
      "3802 loss:  2.11554\n",
      "3803 loss:  2.11553\n",
      "3804 loss:  2.11552\n",
      "3805 loss:  2.11551\n",
      "3806 loss:  2.1155\n",
      "3807 loss:  2.11549\n",
      "3808 loss:  2.11547\n",
      "3809 loss:  2.11546\n",
      "3810 loss:  2.11546\n",
      "3811 loss:  2.11545\n",
      "3812 loss:  2.11545\n",
      "3813 loss:  2.11544\n",
      "3814 loss:  2.11544\n",
      "3815 loss:  2.11543\n",
      "3816 loss:  2.11542\n",
      "3817 loss:  2.11541\n",
      "3818 loss:  2.1154\n",
      "3819 loss:  2.11539\n",
      "3820 loss:  2.11539\n",
      "3821 loss:  2.11538\n",
      "3822 loss:  2.11537\n",
      "3823 loss:  2.11537\n",
      "3824 loss:  2.11536\n",
      "3825 loss:  2.11535\n",
      "3826 loss:  2.11534\n",
      "3827 loss:  2.11533\n",
      "3828 loss:  2.11533\n",
      "3829 loss:  2.11532\n",
      "3830 loss:  2.11531\n",
      "3831 loss:  2.1153\n",
      "3832 loss:  2.11529\n",
      "3833 loss:  2.11528\n",
      "3834 loss:  2.11526\n",
      "3835 loss:  2.11526\n",
      "3836 loss:  2.11524\n",
      "3837 loss:  2.11522\n",
      "3838 loss:  2.11525\n",
      "3839 loss:  2.11521\n",
      "3840 loss:  2.11521\n",
      "3841 loss:  2.11522\n",
      "3842 loss:  2.11519\n",
      "3843 loss:  2.11518\n",
      "3844 loss:  2.11519\n",
      "3845 loss:  2.11518\n",
      "3846 loss:  2.11517\n",
      "3847 loss:  2.11518\n",
      "3848 loss:  2.11517\n",
      "3849 loss:  2.11515\n",
      "3850 loss:  2.11518\n",
      "3851 loss:  2.11515\n",
      "3852 loss:  2.11515\n",
      "3853 loss:  2.11516\n",
      "3854 loss:  2.11514\n",
      "3855 loss:  2.11513\n",
      "3856 loss:  2.11514\n",
      "3857 loss:  2.11513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3858 loss:  2.11512\n",
      "3859 loss:  2.11513\n",
      "3860 loss:  2.11512\n",
      "3861 loss:  2.11511\n",
      "3862 loss:  2.11512\n",
      "3863 loss:  2.11511\n",
      "3864 loss:  2.11509\n",
      "3865 loss:  2.11507\n",
      "3866 loss:  2.11504\n",
      "3867 loss:  2.115\n",
      "3868 loss:  2.11476\n",
      "3869 loss:  2.11475\n",
      "3870 loss:  2.1148\n",
      "3871 loss:  2.11477\n",
      "3872 loss:  2.11474\n",
      "3873 loss:  2.11472\n",
      "3874 loss:  2.11472\n",
      "3875 loss:  2.11472\n",
      "3876 loss:  2.11471\n",
      "3877 loss:  2.11471\n",
      "3878 loss:  2.1147\n",
      "3879 loss:  2.11469\n",
      "3880 loss:  2.1147\n",
      "3881 loss:  2.1147\n",
      "3882 loss:  2.11467\n",
      "3883 loss:  2.11468\n",
      "3884 loss:  2.11468\n",
      "3885 loss:  2.11467\n",
      "3886 loss:  2.11467\n",
      "3887 loss:  2.11465\n",
      "3888 loss:  2.11464\n",
      "3889 loss:  2.11464\n",
      "3890 loss:  2.11463\n",
      "3891 loss:  2.11462\n",
      "3892 loss:  2.11462\n",
      "3893 loss:  2.11461\n",
      "3894 loss:  2.1146\n",
      "3895 loss:  2.1146\n",
      "3896 loss:  2.11459\n",
      "3897 loss:  2.11458\n",
      "3898 loss:  2.11458\n",
      "3899 loss:  2.11457\n",
      "3900 loss:  2.11457\n",
      "3901 loss:  2.11456\n",
      "3902 loss:  2.11456\n",
      "3903 loss:  2.11455\n",
      "3904 loss:  2.11455\n",
      "3905 loss:  2.11454\n",
      "3906 loss:  2.11453\n",
      "3907 loss:  2.11453\n",
      "3908 loss:  2.11452\n",
      "3909 loss:  2.1145\n",
      "3910 loss:  2.11447\n",
      "3911 loss:  2.11444\n",
      "3912 loss:  2.11452\n",
      "3913 loss:  2.1145\n",
      "3914 loss:  2.11453\n",
      "3915 loss:  2.11456\n",
      "3916 loss:  2.11455\n",
      "3917 loss:  2.11457\n",
      "3918 loss:  2.11456\n",
      "3919 loss:  2.11455\n",
      "3920 loss:  2.11455\n",
      "3921 loss:  2.11453\n",
      "3922 loss:  2.11454\n",
      "3923 loss:  2.11452\n",
      "3924 loss:  2.11452\n",
      "3925 loss:  2.11451\n",
      "3926 loss:  2.1145\n",
      "3927 loss:  2.11448\n",
      "3928 loss:  2.11447\n",
      "3929 loss:  2.11446\n",
      "3930 loss:  2.11443\n",
      "3931 loss:  2.11441\n",
      "3932 loss:  2.11438\n",
      "3933 loss:  2.11433\n",
      "3934 loss:  2.11425\n",
      "3935 loss:  2.11416\n",
      "3936 loss:  2.11409\n",
      "3937 loss:  2.11396\n",
      "3938 loss:  2.1139\n",
      "3939 loss:  2.11376\n",
      "3940 loss:  2.1136\n",
      "3941 loss:  2.11347\n",
      "3942 loss:  2.11397\n",
      "3943 loss:  2.11361\n",
      "3944 loss:  2.11368\n",
      "3945 loss:  2.11374\n",
      "3946 loss:  2.11372\n",
      "3947 loss:  2.11373\n",
      "3948 loss:  2.11371\n",
      "3949 loss:  2.1137\n",
      "3950 loss:  2.11369\n",
      "3951 loss:  2.11367\n",
      "3952 loss:  2.11365\n",
      "3953 loss:  2.11363\n",
      "3954 loss:  2.11361\n",
      "3955 loss:  2.11358\n",
      "3956 loss:  2.11355\n",
      "3957 loss:  2.11353\n",
      "3958 loss:  2.11352\n",
      "3959 loss:  2.11351\n",
      "3960 loss:  2.1135\n",
      "3961 loss:  2.1135\n",
      "3962 loss:  2.11349\n",
      "3963 loss:  2.11349\n",
      "3964 loss:  2.11348\n",
      "3965 loss:  2.11347\n",
      "3966 loss:  2.11345\n",
      "3967 loss:  2.11344\n",
      "3968 loss:  2.11343\n",
      "3969 loss:  2.11341\n",
      "3970 loss:  2.1134\n",
      "3971 loss:  2.11338\n",
      "3972 loss:  2.11337\n",
      "3973 loss:  2.11336\n",
      "3974 loss:  2.11335\n",
      "3975 loss:  2.11334\n",
      "3976 loss:  2.11333\n",
      "3977 loss:  2.11332\n",
      "3978 loss:  2.11331\n",
      "3979 loss:  2.1133\n",
      "3980 loss:  2.11329\n",
      "3981 loss:  2.11327\n",
      "3982 loss:  2.11327\n",
      "3983 loss:  2.11326\n",
      "3984 loss:  2.11325\n",
      "3985 loss:  2.11324\n",
      "3986 loss:  2.11323\n",
      "3987 loss:  2.11322\n",
      "3988 loss:  2.11321\n",
      "3989 loss:  2.1132\n",
      "3990 loss:  2.1132\n",
      "3991 loss:  2.11319\n",
      "3992 loss:  2.11319\n",
      "3993 loss:  2.11318\n",
      "3994 loss:  2.11317\n",
      "3995 loss:  2.11317\n",
      "3996 loss:  2.11316\n",
      "3997 loss:  2.11316\n",
      "3998 loss:  2.11315\n",
      "3999 loss:  2.11315\n",
      "4000 loss:  2.11314\n",
      "4001 loss:  2.11314\n",
      "4002 loss:  2.11313\n",
      "4003 loss:  2.11313\n",
      "4004 loss:  2.11313\n",
      "4005 loss:  2.11312\n",
      "4006 loss:  2.11312\n",
      "4007 loss:  2.11312\n",
      "4008 loss:  2.11312\n",
      "4009 loss:  2.11311\n",
      "4010 loss:  2.11311\n",
      "4011 loss:  2.11311\n",
      "4012 loss:  2.11311\n",
      "4013 loss:  2.1131\n",
      "4014 loss:  2.1131\n",
      "4015 loss:  2.1131\n",
      "4016 loss:  2.1131\n",
      "4017 loss:  2.11309\n",
      "4018 loss:  2.11309\n",
      "4019 loss:  2.11309\n",
      "4020 loss:  2.11309\n",
      "4021 loss:  2.11309\n",
      "4022 loss:  2.11309\n",
      "4023 loss:  2.11308\n",
      "4024 loss:  2.11308\n",
      "4025 loss:  2.11308\n",
      "4026 loss:  2.11308\n",
      "4027 loss:  2.11308\n",
      "4028 loss:  2.11307\n",
      "4029 loss:  2.11307\n",
      "4030 loss:  2.11307\n",
      "4031 loss:  2.11307\n",
      "4032 loss:  2.11307\n",
      "4033 loss:  2.11307\n",
      "4034 loss:  2.11307\n",
      "4035 loss:  2.11306\n",
      "4036 loss:  2.11306\n",
      "4037 loss:  2.11306\n",
      "4038 loss:  2.11306\n",
      "4039 loss:  2.11306\n",
      "4040 loss:  2.11306\n",
      "4041 loss:  2.11306\n",
      "4042 loss:  2.11305\n",
      "4043 loss:  2.11305\n",
      "4044 loss:  2.11305\n",
      "4045 loss:  2.11305\n",
      "4046 loss:  2.11305\n",
      "4047 loss:  2.11305\n",
      "4048 loss:  2.11305\n",
      "4049 loss:  2.11305\n",
      "4050 loss:  2.11304\n",
      "4051 loss:  2.11304\n",
      "4052 loss:  2.11304\n",
      "4053 loss:  2.11304\n",
      "4054 loss:  2.11304\n",
      "4055 loss:  2.11303\n",
      "4056 loss:  2.11302\n",
      "4057 loss:  2.113\n",
      "4058 loss:  2.11299\n",
      "4059 loss:  2.11298\n",
      "4060 loss:  2.11298\n",
      "4061 loss:  2.11298\n",
      "4062 loss:  2.11296\n",
      "4063 loss:  2.11295\n",
      "4064 loss:  2.11291\n",
      "4065 loss:  2.11292\n",
      "4066 loss:  2.1129\n",
      "4067 loss:  2.11288\n",
      "4068 loss:  2.11286\n",
      "4069 loss:  2.11284\n",
      "4070 loss:  2.11282\n",
      "4071 loss:  2.11282\n",
      "4072 loss:  2.11281\n",
      "4073 loss:  2.1128\n",
      "4074 loss:  2.1128\n",
      "4075 loss:  2.11279\n",
      "4076 loss:  2.11278\n",
      "4077 loss:  2.11277\n",
      "4078 loss:  2.11276\n",
      "4079 loss:  2.11275\n",
      "4080 loss:  2.11274\n",
      "4081 loss:  2.11272\n",
      "4082 loss:  2.11271\n",
      "4083 loss:  2.11271\n",
      "4084 loss:  2.1127\n",
      "4085 loss:  2.1127\n",
      "4086 loss:  2.11269\n",
      "4087 loss:  2.11268\n",
      "4088 loss:  2.11268\n",
      "4089 loss:  2.11268\n",
      "4090 loss:  2.11271\n",
      "4091 loss:  2.11268\n",
      "4092 loss:  2.11268\n",
      "4093 loss:  2.11269\n",
      "4094 loss:  2.11274\n",
      "4095 loss:  2.11273\n",
      "4096 loss:  2.11273\n",
      "4097 loss:  2.11271\n",
      "4098 loss:  2.1127\n",
      "4099 loss:  2.1127\n",
      "4100 loss:  2.11269\n",
      "4101 loss:  2.11268\n",
      "4102 loss:  2.11268\n",
      "4103 loss:  2.11267\n",
      "4104 loss:  2.11267\n",
      "4105 loss:  2.11267\n",
      "4106 loss:  2.11266\n",
      "4107 loss:  2.11266\n",
      "4108 loss:  2.11266\n",
      "4109 loss:  2.11265\n",
      "4110 loss:  2.11265\n",
      "4111 loss:  2.11264\n",
      "4112 loss:  2.11263\n",
      "4113 loss:  2.11262\n",
      "4114 loss:  2.11262\n",
      "4115 loss:  2.11261\n",
      "4116 loss:  2.11261\n",
      "4117 loss:  2.11267\n",
      "4118 loss:  2.11264\n",
      "4119 loss:  2.11263\n",
      "4120 loss:  2.11264\n",
      "4121 loss:  2.11265\n",
      "4122 loss:  2.11267\n",
      "4123 loss:  2.11266\n",
      "4124 loss:  2.11264\n",
      "4125 loss:  2.11263\n",
      "4126 loss:  2.11262\n",
      "4127 loss:  2.11261\n",
      "4128 loss:  2.11261\n",
      "4129 loss:  2.11261\n",
      "4130 loss:  2.1126\n",
      "4131 loss:  2.11259\n",
      "4132 loss:  2.11261\n",
      "4133 loss:  2.11258\n",
      "4134 loss:  2.1126\n",
      "4135 loss:  2.11259\n",
      "4136 loss:  2.11257\n",
      "4137 loss:  2.11257\n",
      "4138 loss:  2.11258\n",
      "4139 loss:  2.11256\n",
      "4140 loss:  2.11256\n",
      "4141 loss:  2.11256\n",
      "4142 loss:  2.11256\n",
      "4143 loss:  2.11254\n",
      "4144 loss:  2.11254\n",
      "4145 loss:  2.11254\n",
      "4146 loss:  2.11254\n",
      "4147 loss:  2.11253\n",
      "4148 loss:  2.11253\n",
      "4149 loss:  2.11253\n",
      "4150 loss:  2.11253\n",
      "4151 loss:  2.11252\n",
      "4152 loss:  2.11251\n",
      "4153 loss:  2.11251\n",
      "4154 loss:  2.11249\n",
      "4155 loss:  2.11246\n",
      "4156 loss:  2.11248\n",
      "4157 loss:  2.11253\n",
      "4158 loss:  2.11259\n",
      "4159 loss:  2.11262\n",
      "4160 loss:  2.11265\n",
      "4161 loss:  2.11263\n",
      "4162 loss:  2.11259\n",
      "4163 loss:  2.11258\n",
      "4164 loss:  2.11258\n",
      "4165 loss:  2.11258\n",
      "4166 loss:  2.11259\n",
      "4167 loss:  2.11258\n",
      "4168 loss:  2.11257\n",
      "4169 loss:  2.11257\n",
      "4170 loss:  2.11257\n",
      "4171 loss:  2.11255\n",
      "4172 loss:  2.11253\n",
      "4173 loss:  2.11238\n",
      "4174 loss:  2.1124\n",
      "4175 loss:  2.11241\n",
      "4176 loss:  2.1124\n",
      "4177 loss:  2.11239\n",
      "4178 loss:  2.11236\n",
      "4179 loss:  2.11236\n",
      "4180 loss:  2.11236\n",
      "4181 loss:  2.11233\n",
      "4182 loss:  2.11235\n",
      "4183 loss:  2.11234\n",
      "4184 loss:  2.11233\n",
      "4185 loss:  2.11234\n",
      "4186 loss:  2.11232\n",
      "4187 loss:  2.11231\n",
      "4188 loss:  2.11233\n",
      "4189 loss:  2.11232\n",
      "4190 loss:  2.1123\n",
      "4191 loss:  2.11232\n",
      "4192 loss:  2.11232\n",
      "4193 loss:  2.1123\n",
      "4194 loss:  2.11231\n",
      "4195 loss:  2.11231\n",
      "4196 loss:  2.1123\n",
      "4197 loss:  2.1123\n",
      "4198 loss:  2.11231\n",
      "4199 loss:  2.11229\n",
      "4200 loss:  2.11229\n",
      "4201 loss:  2.1123\n",
      "4202 loss:  2.11229\n",
      "4203 loss:  2.11228\n",
      "4204 loss:  2.11229\n",
      "4205 loss:  2.11229\n",
      "4206 loss:  2.11228\n",
      "4207 loss:  2.11228\n",
      "4208 loss:  2.11228\n",
      "4209 loss:  2.11228\n",
      "4210 loss:  2.11227\n",
      "4211 loss:  2.11227\n",
      "4212 loss:  2.11227\n",
      "4213 loss:  2.11227\n",
      "4214 loss:  2.11226\n",
      "4215 loss:  2.11224\n",
      "4216 loss:  2.11223\n",
      "4217 loss:  2.11223\n",
      "4218 loss:  2.11223\n",
      "4219 loss:  2.11223\n",
      "4220 loss:  2.11223\n",
      "4221 loss:  2.11223\n",
      "4222 loss:  2.11223\n",
      "4223 loss:  2.11222\n",
      "4224 loss:  2.11222\n",
      "4225 loss:  2.11222\n",
      "4226 loss:  2.11222\n",
      "4227 loss:  2.11221\n",
      "4228 loss:  2.11221\n",
      "4229 loss:  2.11221\n",
      "4230 loss:  2.11221\n",
      "4231 loss:  2.1122\n",
      "4232 loss:  2.1122\n",
      "4233 loss:  2.1122\n",
      "4234 loss:  2.1122\n",
      "4235 loss:  2.1122\n",
      "4236 loss:  2.1122\n",
      "4237 loss:  2.11219\n",
      "4238 loss:  2.11219\n",
      "4239 loss:  2.11219\n",
      "4240 loss:  2.11219\n",
      "4241 loss:  2.11219\n",
      "4242 loss:  2.11219\n",
      "4243 loss:  2.11219\n",
      "4244 loss:  2.11219\n",
      "4245 loss:  2.11219\n",
      "4246 loss:  2.11219\n",
      "4247 loss:  2.11219\n",
      "4248 loss:  2.11218\n",
      "4249 loss:  2.11218\n",
      "4250 loss:  2.11218\n",
      "4251 loss:  2.11218\n",
      "4252 loss:  2.11218\n",
      "4253 loss:  2.11218\n",
      "4254 loss:  2.11218\n",
      "4255 loss:  2.11218\n",
      "4256 loss:  2.11218\n",
      "4257 loss:  2.11217\n",
      "4258 loss:  2.11217\n",
      "4259 loss:  2.11217\n",
      "4260 loss:  2.11217\n",
      "4261 loss:  2.11216\n",
      "4262 loss:  2.11214\n",
      "4263 loss:  2.1121\n",
      "4264 loss:  2.112\n",
      "4265 loss:  2.1127\n",
      "4266 loss:  2.11343\n",
      "4267 loss:  2.11588\n",
      "4268 loss:  2.11638\n",
      "4269 loss:  2.11749\n",
      "4270 loss:  2.12027\n",
      "4271 loss:  2.12074\n",
      "4272 loss:  2.12156\n",
      "4273 loss:  2.11932\n",
      "4274 loss:  2.11906\n",
      "4275 loss:  2.11835\n",
      "4276 loss:  2.11843\n",
      "4277 loss:  2.11762\n",
      "4278 loss:  2.11755\n",
      "4279 loss:  2.11745\n",
      "4280 loss:  2.1175\n",
      "4281 loss:  2.11717\n",
      "4282 loss:  2.11701\n",
      "4283 loss:  2.1166\n",
      "4284 loss:  2.1163\n",
      "4285 loss:  2.11608\n",
      "4286 loss:  2.11591\n",
      "4287 loss:  2.11584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4288 loss:  2.11567\n",
      "4289 loss:  2.11548\n",
      "4290 loss:  2.11558\n",
      "4291 loss:  2.11795\n",
      "4292 loss:  2.12\n",
      "4293 loss:  2.11895\n",
      "4294 loss:  2.11965\n",
      "4295 loss:  2.12001\n",
      "4296 loss:  2.11755\n",
      "4297 loss:  2.11679\n",
      "4298 loss:  2.11713\n",
      "4299 loss:  2.1166\n",
      "4300 loss:  2.11639\n",
      "4301 loss:  2.11635\n",
      "4302 loss:  2.11575\n",
      "4303 loss:  2.1155\n",
      "4304 loss:  2.11496\n",
      "4305 loss:  2.11485\n",
      "4306 loss:  2.11455\n",
      "4307 loss:  2.1161\n",
      "4308 loss:  2.11471\n",
      "4309 loss:  2.11475\n",
      "4310 loss:  2.11445\n",
      "4311 loss:  2.11451\n",
      "4312 loss:  2.11429\n",
      "4313 loss:  2.11789\n",
      "4314 loss:  2.11415\n",
      "4315 loss:  2.11427\n",
      "4316 loss:  2.11528\n",
      "4317 loss:  2.11618\n",
      "4318 loss:  2.11532\n",
      "4319 loss:  2.11548\n",
      "4320 loss:  2.11486\n",
      "4321 loss:  2.11476\n",
      "4322 loss:  2.11464\n",
      "4323 loss:  2.11413\n",
      "4324 loss:  2.11382\n",
      "4325 loss:  2.11361\n",
      "4326 loss:  2.11358\n",
      "4327 loss:  2.11357\n",
      "4328 loss:  2.1134\n",
      "4329 loss:  2.11332\n",
      "4330 loss:  2.11276\n",
      "4331 loss:  2.11255\n",
      "4332 loss:  2.11253\n",
      "4333 loss:  2.11246\n",
      "4334 loss:  2.11242\n",
      "4335 loss:  2.1123\n",
      "4336 loss:  2.11219\n",
      "4337 loss:  2.11209\n",
      "4338 loss:  2.11202\n",
      "4339 loss:  2.11197\n",
      "4340 loss:  2.11192\n",
      "4341 loss:  2.11183\n",
      "4342 loss:  2.11169\n",
      "4343 loss:  2.11243\n",
      "4344 loss:  2.11157\n",
      "4345 loss:  2.11147\n",
      "4346 loss:  2.11138\n",
      "4347 loss:  2.11132\n",
      "4348 loss:  2.11127\n",
      "4349 loss:  2.11124\n",
      "4350 loss:  2.11119\n",
      "4351 loss:  2.11116\n",
      "4352 loss:  2.11114\n",
      "4353 loss:  2.1111\n",
      "4354 loss:  2.11105\n",
      "4355 loss:  2.11101\n",
      "4356 loss:  2.11098\n",
      "4357 loss:  2.11094\n",
      "4358 loss:  2.11096\n",
      "4359 loss:  2.11093\n",
      "4360 loss:  2.11089\n",
      "4361 loss:  2.11089\n",
      "4362 loss:  2.11089\n",
      "4363 loss:  2.11086\n",
      "4364 loss:  2.11085\n",
      "4365 loss:  2.11083\n",
      "4366 loss:  2.1108\n",
      "4367 loss:  2.11078\n",
      "4368 loss:  2.11076\n",
      "4369 loss:  2.11075\n",
      "4370 loss:  2.11074\n",
      "4371 loss:  2.11072\n",
      "4372 loss:  2.1107\n",
      "4373 loss:  2.11069\n",
      "4374 loss:  2.11054\n",
      "4375 loss:  2.11033\n",
      "4376 loss:  2.11038\n",
      "4377 loss:  2.11063\n",
      "4378 loss:  2.11074\n",
      "4379 loss:  2.11076\n",
      "4380 loss:  2.11076\n",
      "4381 loss:  2.11104\n",
      "4382 loss:  2.11073\n",
      "4383 loss:  2.11059\n",
      "4384 loss:  2.11039\n",
      "4385 loss:  2.11038\n",
      "4386 loss:  2.11036\n",
      "4387 loss:  2.11033\n",
      "4388 loss:  2.11032\n",
      "4389 loss:  2.11029\n",
      "4390 loss:  2.11027\n",
      "4391 loss:  2.11027\n",
      "4392 loss:  2.11026\n",
      "4393 loss:  2.11024\n",
      "4394 loss:  2.11025\n",
      "4395 loss:  2.11024\n",
      "4396 loss:  2.11022\n",
      "4397 loss:  2.11019\n",
      "4398 loss:  2.11022\n",
      "4399 loss:  2.11026\n",
      "4400 loss:  2.11024\n",
      "4401 loss:  2.11023\n",
      "4402 loss:  2.11025\n",
      "4403 loss:  2.11019\n",
      "4404 loss:  2.11021\n",
      "4405 loss:  2.11017\n",
      "4406 loss:  2.11018\n",
      "4407 loss:  2.11017\n",
      "4408 loss:  2.11014\n",
      "4409 loss:  2.11015\n",
      "4410 loss:  2.11018\n",
      "4411 loss:  2.11017\n",
      "4412 loss:  2.11016\n",
      "4413 loss:  2.11021\n",
      "4414 loss:  2.11015\n",
      "4415 loss:  2.11015\n",
      "4416 loss:  2.11014\n",
      "4417 loss:  2.11012\n",
      "4418 loss:  2.11013\n",
      "4419 loss:  2.1102\n",
      "4420 loss:  2.11024\n",
      "4421 loss:  2.11024\n",
      "4422 loss:  2.11025\n",
      "4423 loss:  2.11027\n",
      "4424 loss:  2.11022\n",
      "4425 loss:  2.11021\n",
      "4426 loss:  2.11018\n",
      "4427 loss:  2.11019\n",
      "4428 loss:  2.11016\n",
      "4429 loss:  2.11015\n",
      "4430 loss:  2.1101\n",
      "4431 loss:  2.11013\n",
      "4432 loss:  2.11011\n",
      "4433 loss:  2.1101\n",
      "4434 loss:  2.11011\n",
      "4435 loss:  2.11004\n",
      "4436 loss:  2.11001\n",
      "4437 loss:  2.10999\n",
      "4438 loss:  2.10997\n",
      "4439 loss:  2.10999\n",
      "4440 loss:  2.10996\n",
      "4441 loss:  2.10995\n",
      "4442 loss:  2.10994\n",
      "4443 loss:  2.10992\n",
      "4444 loss:  2.10992\n",
      "4445 loss:  2.1099\n",
      "4446 loss:  2.1099\n",
      "4447 loss:  2.10988\n",
      "4448 loss:  2.10988\n",
      "4449 loss:  2.10988\n",
      "4450 loss:  2.10987\n",
      "4451 loss:  2.10986\n",
      "4452 loss:  2.10985\n",
      "4453 loss:  2.10985\n",
      "4454 loss:  2.10984\n",
      "4455 loss:  2.10984\n",
      "4456 loss:  2.10983\n",
      "4457 loss:  2.10982\n",
      "4458 loss:  2.10981\n",
      "4459 loss:  2.10981\n",
      "4460 loss:  2.10981\n",
      "4461 loss:  2.1098\n",
      "4462 loss:  2.1098\n",
      "4463 loss:  2.1098\n",
      "4464 loss:  2.10979\n",
      "4465 loss:  2.10979\n",
      "4466 loss:  2.10978\n",
      "4467 loss:  2.10978\n",
      "4468 loss:  2.10977\n",
      "4469 loss:  2.10977\n",
      "4470 loss:  2.10976\n",
      "4471 loss:  2.10976\n",
      "4472 loss:  2.10975\n",
      "4473 loss:  2.10973\n",
      "4474 loss:  2.10971\n",
      "4475 loss:  2.10971\n",
      "4476 loss:  2.10971\n",
      "4477 loss:  2.1097\n",
      "4478 loss:  2.1097\n",
      "4479 loss:  2.10969\n",
      "4480 loss:  2.10968\n",
      "4481 loss:  2.10967\n",
      "4482 loss:  2.10967\n",
      "4483 loss:  2.10966\n",
      "4484 loss:  2.10965\n",
      "4485 loss:  2.10965\n",
      "4486 loss:  2.10964\n",
      "4487 loss:  2.10964\n",
      "4488 loss:  2.10963\n",
      "4489 loss:  2.10963\n",
      "4490 loss:  2.10963\n",
      "4491 loss:  2.10962\n",
      "4492 loss:  2.10962\n",
      "4493 loss:  2.10962\n",
      "4494 loss:  2.10961\n",
      "4495 loss:  2.1096\n",
      "4496 loss:  2.1096\n",
      "4497 loss:  2.10959\n",
      "4498 loss:  2.10958\n",
      "4499 loss:  2.10956\n",
      "4500 loss:  2.10955\n",
      "4501 loss:  2.10954\n",
      "4502 loss:  2.10954\n",
      "4503 loss:  2.10953\n",
      "4504 loss:  2.10953\n",
      "4505 loss:  2.10953\n",
      "4506 loss:  2.10952\n",
      "4507 loss:  2.10952\n",
      "4508 loss:  2.10952\n",
      "4509 loss:  2.10952\n",
      "4510 loss:  2.10951\n",
      "4511 loss:  2.10951\n",
      "4512 loss:  2.10951\n",
      "4513 loss:  2.1095\n",
      "4514 loss:  2.1095\n",
      "4515 loss:  2.1095\n",
      "4516 loss:  2.1095\n",
      "4517 loss:  2.10949\n",
      "4518 loss:  2.10949\n",
      "4519 loss:  2.10948\n",
      "4520 loss:  2.10948\n",
      "4521 loss:  2.10948\n",
      "4522 loss:  2.10948\n",
      "4523 loss:  2.10948\n",
      "4524 loss:  2.10949\n",
      "4525 loss:  2.1095\n",
      "4526 loss:  2.10947\n",
      "4527 loss:  2.10945\n",
      "4528 loss:  2.10944\n",
      "4529 loss:  2.10945\n",
      "4530 loss:  2.10945\n",
      "4531 loss:  2.10944\n",
      "4532 loss:  2.10945\n",
      "4533 loss:  2.10944\n",
      "4534 loss:  2.10944\n",
      "4535 loss:  2.10944\n",
      "4536 loss:  2.10943\n",
      "4537 loss:  2.10943\n",
      "4538 loss:  2.10943\n",
      "4539 loss:  2.10942\n",
      "4540 loss:  2.10942\n",
      "4541 loss:  2.10943\n",
      "4542 loss:  2.10943\n",
      "4543 loss:  2.10943\n",
      "4544 loss:  2.10942\n",
      "4545 loss:  2.10942\n",
      "4546 loss:  2.10941\n",
      "4547 loss:  2.10941\n",
      "4548 loss:  2.10941\n",
      "4549 loss:  2.10941\n",
      "4550 loss:  2.10941\n",
      "4551 loss:  2.10941\n",
      "4552 loss:  2.10941\n",
      "4553 loss:  2.10941\n",
      "4554 loss:  2.10941\n",
      "4555 loss:  2.1094\n",
      "4556 loss:  2.1094\n",
      "4557 loss:  2.1094\n",
      "4558 loss:  2.1094\n",
      "4559 loss:  2.1094\n",
      "4560 loss:  2.1094\n",
      "4561 loss:  2.1094\n",
      "4562 loss:  2.1094\n",
      "4563 loss:  2.1094\n",
      "4564 loss:  2.10939\n",
      "4565 loss:  2.10939\n",
      "4566 loss:  2.10939\n",
      "4567 loss:  2.10939\n",
      "4568 loss:  2.10939\n",
      "4569 loss:  2.10939\n",
      "4570 loss:  2.10939\n",
      "4571 loss:  2.10939\n",
      "4572 loss:  2.10939\n",
      "4573 loss:  2.10939\n",
      "4574 loss:  2.10939\n",
      "4575 loss:  2.10939\n",
      "4576 loss:  2.10938\n",
      "4577 loss:  2.10938\n",
      "4578 loss:  2.10938\n",
      "4579 loss:  2.10938\n",
      "4580 loss:  2.10938\n",
      "4581 loss:  2.10938\n",
      "4582 loss:  2.10938\n",
      "4583 loss:  2.10938\n",
      "4584 loss:  2.10938\n",
      "4585 loss:  2.10938\n",
      "4586 loss:  2.10938\n",
      "4587 loss:  2.10937\n",
      "4588 loss:  2.10937\n",
      "4589 loss:  2.10937\n",
      "4590 loss:  2.10937\n",
      "4591 loss:  2.10937\n",
      "4592 loss:  2.10937\n",
      "4593 loss:  2.10937\n",
      "4594 loss:  2.10937\n",
      "4595 loss:  2.10937\n",
      "4596 loss:  2.10936\n",
      "4597 loss:  2.10936\n",
      "4598 loss:  2.10936\n",
      "4599 loss:  2.10936\n",
      "4600 loss:  2.10936\n",
      "4601 loss:  2.10935\n",
      "4602 loss:  2.10935\n",
      "4603 loss:  2.10935\n",
      "4604 loss:  2.10934\n",
      "4605 loss:  2.10934\n",
      "4606 loss:  2.10933\n",
      "4607 loss:  2.10933\n",
      "4608 loss:  2.10933\n",
      "4609 loss:  2.10932\n",
      "4610 loss:  2.10932\n",
      "4611 loss:  2.10932\n",
      "4612 loss:  2.10931\n",
      "4613 loss:  2.10931\n",
      "4614 loss:  2.1093\n",
      "4615 loss:  2.1093\n",
      "4616 loss:  2.1093\n",
      "4617 loss:  2.1093\n",
      "4618 loss:  2.10929\n",
      "4619 loss:  2.10929\n",
      "4620 loss:  2.10929\n",
      "4621 loss:  2.10928\n",
      "4622 loss:  2.10928\n",
      "4623 loss:  2.10927\n",
      "4624 loss:  2.10926\n",
      "4625 loss:  2.10924\n",
      "4626 loss:  2.10922\n",
      "4627 loss:  2.10919\n",
      "4628 loss:  2.10918\n",
      "4629 loss:  2.10918\n",
      "4630 loss:  2.10916\n",
      "4631 loss:  2.10915\n",
      "4632 loss:  2.10938\n",
      "4633 loss:  2.10915\n",
      "4634 loss:  2.10924\n",
      "4635 loss:  2.10961\n",
      "4636 loss:  2.10977\n",
      "4637 loss:  2.10974\n",
      "4638 loss:  2.10972\n",
      "4639 loss:  2.10973\n",
      "4640 loss:  2.10969\n",
      "4641 loss:  2.10957\n",
      "4642 loss:  2.10957\n",
      "4643 loss:  2.10964\n",
      "4644 loss:  2.10957\n",
      "4645 loss:  2.10981\n",
      "4646 loss:  2.1098\n",
      "4647 loss:  2.11008\n",
      "4648 loss:  2.10995\n",
      "4649 loss:  2.10976\n",
      "4650 loss:  2.10965\n",
      "4651 loss:  2.11007\n",
      "4652 loss:  2.10985\n",
      "4653 loss:  2.11003\n",
      "4654 loss:  2.11009\n",
      "4655 loss:  2.11013\n",
      "4656 loss:  2.11008\n",
      "4657 loss:  2.11011\n",
      "4658 loss:  2.11019\n",
      "4659 loss:  2.11004\n",
      "4660 loss:  2.10978\n",
      "4661 loss:  2.10977\n",
      "4662 loss:  2.1096\n",
      "4663 loss:  2.10957\n",
      "4664 loss:  2.10948\n",
      "4665 loss:  2.10944\n",
      "4666 loss:  2.10942\n",
      "4667 loss:  2.10934\n",
      "4668 loss:  2.10932\n",
      "4669 loss:  2.10929\n",
      "4670 loss:  2.10934\n",
      "4671 loss:  2.10934\n",
      "4672 loss:  2.10932\n",
      "4673 loss:  2.1093\n",
      "4674 loss:  2.10927\n",
      "4675 loss:  2.10926\n",
      "4676 loss:  2.10923\n",
      "4677 loss:  2.10918\n",
      "4678 loss:  2.10912\n",
      "4679 loss:  2.10906\n",
      "4680 loss:  2.10899\n",
      "4681 loss:  2.10894\n",
      "4682 loss:  2.10889\n",
      "4683 loss:  2.10885\n",
      "4684 loss:  2.1088\n",
      "4685 loss:  2.10879\n",
      "4686 loss:  2.10877\n",
      "4687 loss:  2.10876\n",
      "4688 loss:  2.10876\n",
      "4689 loss:  2.10875\n",
      "4690 loss:  2.10874\n",
      "4691 loss:  2.10872\n",
      "4692 loss:  2.1087\n",
      "4693 loss:  2.10869\n",
      "4694 loss:  2.1087\n",
      "4695 loss:  2.1087\n",
      "4696 loss:  2.10868\n",
      "4697 loss:  2.10867\n",
      "4698 loss:  2.1087\n",
      "4699 loss:  2.10872\n",
      "4700 loss:  2.10875\n",
      "4701 loss:  2.10882\n",
      "4702 loss:  2.10875\n",
      "4703 loss:  2.10871\n",
      "4704 loss:  2.1087\n",
      "4705 loss:  2.10868\n",
      "4706 loss:  2.10869\n",
      "4707 loss:  2.1086\n",
      "4708 loss:  2.10865\n",
      "4709 loss:  2.10862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4710 loss:  2.10859\n",
      "4711 loss:  2.10872\n",
      "4712 loss:  2.10885\n",
      "4713 loss:  2.10878\n",
      "4714 loss:  2.10881\n",
      "4715 loss:  2.1089\n",
      "4716 loss:  2.10882\n",
      "4717 loss:  2.10881\n",
      "4718 loss:  2.10873\n",
      "4719 loss:  2.10867\n",
      "4720 loss:  2.10875\n",
      "4721 loss:  2.10871\n",
      "4722 loss:  2.10877\n",
      "4723 loss:  2.10869\n",
      "4724 loss:  2.10871\n",
      "4725 loss:  2.10869\n",
      "4726 loss:  2.10864\n",
      "4727 loss:  2.10865\n",
      "4728 loss:  2.10861\n",
      "4729 loss:  2.10863\n",
      "4730 loss:  2.10858\n",
      "4731 loss:  2.1086\n",
      "4732 loss:  2.10856\n",
      "4733 loss:  2.10858\n",
      "4734 loss:  2.10856\n",
      "4735 loss:  2.10859\n",
      "4736 loss:  2.10855\n",
      "4737 loss:  2.10856\n",
      "4738 loss:  2.10854\n",
      "4739 loss:  2.10854\n",
      "4740 loss:  2.10853\n",
      "4741 loss:  2.10853\n",
      "4742 loss:  2.10852\n",
      "4743 loss:  2.10852\n",
      "4744 loss:  2.10852\n",
      "4745 loss:  2.10851\n",
      "4746 loss:  2.10851\n",
      "4747 loss:  2.1085\n",
      "4748 loss:  2.1085\n",
      "4749 loss:  2.10849\n",
      "4750 loss:  2.10849\n",
      "4751 loss:  2.10849\n",
      "4752 loss:  2.10848\n",
      "4753 loss:  2.10848\n",
      "4754 loss:  2.10847\n",
      "4755 loss:  2.10848\n",
      "4756 loss:  2.10847\n",
      "4757 loss:  2.10847\n",
      "4758 loss:  2.10846\n",
      "4759 loss:  2.10845\n",
      "4760 loss:  2.10845\n",
      "4761 loss:  2.10844\n",
      "4762 loss:  2.10844\n",
      "4763 loss:  2.10843\n",
      "4764 loss:  2.10843\n",
      "4765 loss:  2.10842\n",
      "4766 loss:  2.10841\n",
      "4767 loss:  2.10841\n",
      "4768 loss:  2.10841\n",
      "4769 loss:  2.10841\n",
      "4770 loss:  2.1084\n",
      "4771 loss:  2.1084\n",
      "4772 loss:  2.1084\n",
      "4773 loss:  2.1084\n",
      "4774 loss:  2.1084\n",
      "4775 loss:  2.1084\n",
      "4776 loss:  2.10839\n",
      "4777 loss:  2.10839\n",
      "4778 loss:  2.10839\n",
      "4779 loss:  2.10839\n",
      "4780 loss:  2.10838\n",
      "4781 loss:  2.10838\n",
      "4782 loss:  2.10837\n",
      "4783 loss:  2.10837\n",
      "4784 loss:  2.10836\n",
      "4785 loss:  2.10835\n",
      "4786 loss:  2.10834\n",
      "4787 loss:  2.10834\n",
      "4788 loss:  2.10833\n",
      "4789 loss:  2.10833\n",
      "4790 loss:  2.10833\n",
      "4791 loss:  2.10833\n",
      "4792 loss:  2.10832\n",
      "4793 loss:  2.10832\n",
      "4794 loss:  2.10832\n",
      "4795 loss:  2.10832\n",
      "4796 loss:  2.10831\n",
      "4797 loss:  2.10831\n",
      "4798 loss:  2.10831\n",
      "4799 loss:  2.10831\n",
      "4800 loss:  2.10831\n",
      "4801 loss:  2.10831\n",
      "4802 loss:  2.10831\n",
      "4803 loss:  2.1083\n",
      "4804 loss:  2.1083\n",
      "4805 loss:  2.1083\n",
      "4806 loss:  2.1083\n",
      "4807 loss:  2.1083\n",
      "4808 loss:  2.1083\n",
      "4809 loss:  2.1083\n",
      "4810 loss:  2.1083\n",
      "4811 loss:  2.1083\n",
      "4812 loss:  2.1083\n",
      "4813 loss:  2.1083\n",
      "4814 loss:  2.1083\n",
      "4815 loss:  2.10829\n",
      "4816 loss:  2.10829\n",
      "4817 loss:  2.10829\n",
      "4818 loss:  2.10829\n",
      "4819 loss:  2.10829\n",
      "4820 loss:  2.10829\n",
      "4821 loss:  2.10829\n",
      "4822 loss:  2.10829\n",
      "4823 loss:  2.10829\n",
      "4824 loss:  2.10829\n",
      "4825 loss:  2.10829\n",
      "4826 loss:  2.10829\n",
      "4827 loss:  2.10829\n",
      "4828 loss:  2.10829\n",
      "4829 loss:  2.10829\n",
      "4830 loss:  2.10828\n",
      "4831 loss:  2.10828\n",
      "4832 loss:  2.10828\n",
      "4833 loss:  2.10828\n",
      "4834 loss:  2.10828\n",
      "4835 loss:  2.10828\n",
      "4836 loss:  2.10828\n",
      "4837 loss:  2.10828\n",
      "4838 loss:  2.10828\n",
      "4839 loss:  2.10828\n",
      "4840 loss:  2.10828\n",
      "4841 loss:  2.10828\n",
      "4842 loss:  2.10828\n",
      "4843 loss:  2.10827\n",
      "4844 loss:  2.10827\n",
      "4845 loss:  2.10827\n",
      "4846 loss:  2.10827\n",
      "4847 loss:  2.10827\n",
      "4848 loss:  2.10827\n",
      "4849 loss:  2.10827\n",
      "4850 loss:  2.10827\n",
      "4851 loss:  2.10827\n",
      "4852 loss:  2.10826\n",
      "4853 loss:  2.10826\n",
      "4854 loss:  2.10826\n",
      "4855 loss:  2.10826\n",
      "4856 loss:  2.10826\n",
      "4857 loss:  2.10826\n",
      "4858 loss:  2.10826\n",
      "4859 loss:  2.10826\n",
      "4860 loss:  2.10826\n",
      "4861 loss:  2.10826\n",
      "4862 loss:  2.10826\n",
      "4863 loss:  2.10826\n",
      "4864 loss:  2.10826\n",
      "4865 loss:  2.10826\n",
      "4866 loss:  2.10826\n",
      "4867 loss:  2.10825\n",
      "4868 loss:  2.10825\n",
      "4869 loss:  2.10825\n",
      "4870 loss:  2.10825\n",
      "4871 loss:  2.10825\n",
      "4872 loss:  2.10825\n",
      "4873 loss:  2.10825\n",
      "4874 loss:  2.10825\n",
      "4875 loss:  2.10825\n",
      "4876 loss:  2.10825\n",
      "4877 loss:  2.10825\n",
      "4878 loss:  2.10825\n",
      "4879 loss:  2.10825\n",
      "4880 loss:  2.10824\n",
      "4881 loss:  2.10822\n",
      "4882 loss:  2.10822\n",
      "4883 loss:  2.10822\n",
      "4884 loss:  2.10823\n",
      "4885 loss:  2.10823\n",
      "4886 loss:  2.10823\n",
      "4887 loss:  2.10822\n",
      "4888 loss:  2.10822\n",
      "4889 loss:  2.10822\n",
      "4890 loss:  2.10822\n",
      "4891 loss:  2.10822\n",
      "4892 loss:  2.10822\n",
      "4893 loss:  2.10822\n",
      "4894 loss:  2.10822\n",
      "4895 loss:  2.10822\n",
      "4896 loss:  2.10822\n",
      "4897 loss:  2.10822\n",
      "4898 loss:  2.10822\n",
      "4899 loss:  2.10822\n",
      "4900 loss:  2.10822\n",
      "4901 loss:  2.10822\n",
      "4902 loss:  2.10822\n",
      "4903 loss:  2.10821\n",
      "4904 loss:  2.10821\n",
      "4905 loss:  2.10821\n",
      "4906 loss:  2.10821\n",
      "4907 loss:  2.10821\n",
      "4908 loss:  2.10821\n",
      "4909 loss:  2.10821\n",
      "4910 loss:  2.10821\n",
      "4911 loss:  2.10821\n",
      "4912 loss:  2.10821\n",
      "4913 loss:  2.10821\n",
      "4914 loss:  2.10821\n",
      "4915 loss:  2.10821\n",
      "4916 loss:  2.10821\n",
      "4917 loss:  2.10821\n",
      "4918 loss:  2.10821\n",
      "4919 loss:  2.10821\n",
      "4920 loss:  2.10821\n",
      "4921 loss:  2.10821\n",
      "4922 loss:  2.10821\n",
      "4923 loss:  2.10821\n",
      "4924 loss:  2.10821\n",
      "4925 loss:  2.10821\n",
      "4926 loss:  2.10821\n",
      "4927 loss:  2.10821\n",
      "4928 loss:  2.10821\n",
      "4929 loss:  2.1082\n",
      "4930 loss:  2.1082\n",
      "4931 loss:  2.1082\n",
      "4932 loss:  2.1082\n",
      "4933 loss:  2.1082\n",
      "4934 loss:  2.1082\n",
      "4935 loss:  2.1082\n",
      "4936 loss:  2.1082\n",
      "4937 loss:  2.1082\n",
      "4938 loss:  2.1082\n",
      "4939 loss:  2.1082\n",
      "4940 loss:  2.1082\n",
      "4941 loss:  2.1082\n",
      "4942 loss:  2.1082\n",
      "4943 loss:  2.1082\n",
      "4944 loss:  2.1082\n",
      "4945 loss:  2.1082\n",
      "4946 loss:  2.1082\n",
      "4947 loss:  2.1082\n",
      "4948 loss:  2.10819\n",
      "4949 loss:  2.10819\n",
      "4950 loss:  2.10819\n",
      "4951 loss:  2.10819\n",
      "4952 loss:  2.10819\n",
      "4953 loss:  2.10819\n",
      "4954 loss:  2.10819\n",
      "4955 loss:  2.10819\n",
      "4956 loss:  2.10819\n",
      "4957 loss:  2.10819\n",
      "4958 loss:  2.10819\n",
      "4959 loss:  2.10819\n",
      "4960 loss:  2.10818\n",
      "4961 loss:  2.10818\n",
      "4962 loss:  2.10818\n",
      "4963 loss:  2.10818\n",
      "4964 loss:  2.10818\n",
      "4965 loss:  2.10817\n",
      "4966 loss:  2.10817\n",
      "4967 loss:  2.10816\n",
      "4968 loss:  2.10815\n",
      "4969 loss:  2.10813\n",
      "4970 loss:  2.1081\n",
      "4971 loss:  2.10809\n",
      "4972 loss:  2.10809\n",
      "4973 loss:  2.10807\n",
      "4974 loss:  2.10805\n",
      "4975 loss:  2.10804\n",
      "4976 loss:  2.10803\n",
      "4977 loss:  2.10804\n",
      "4978 loss:  2.10804\n",
      "4979 loss:  2.10803\n",
      "4980 loss:  2.10803\n",
      "4981 loss:  2.10803\n",
      "4982 loss:  2.10801\n",
      "4983 loss:  2.10801\n",
      "4984 loss:  2.10801\n",
      "4985 loss:  2.108\n",
      "4986 loss:  2.10801\n",
      "4987 loss:  2.108\n",
      "4988 loss:  2.10813\n",
      "4989 loss:  2.10951\n",
      "4990 loss:  2.11789\n",
      "4991 loss:  2.11467\n",
      "4992 loss:  2.11603\n",
      "4993 loss:  2.11913\n",
      "4994 loss:  2.11887\n",
      "4995 loss:  2.12319\n",
      "4996 loss:  2.12228\n",
      "4997 loss:  2.12269\n",
      "4998 loss:  2.12153\n",
      "4999 loss:  2.12311\n",
      "Answer_full:  f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "Result_full:  t do   ant to toted d hhe   don't dodm e   eodoe to ether to todoett tood nnd don't d eign the  to e  dnd dor e dot rether to th the  to nond do  the nnd et  iodenett  o  the nea \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")\n",
    "char_set = list(set(sentence)) # 유니크한 문자열을 리스트로 넣는다.\n",
    "char_dic = {w: i for i, w in enumerate(char_set)} # 리스트 문자열을 index로 매칭되는 딕셔너리를 만든다.\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "data_dim = len(char_set)\n",
    "rnn_hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10 # Any value\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i+sequence_length]\n",
    "    y_str = sentence[i+1:i+sequence_length+1]\n",
    "    # print( '{0:03d} {1}->{2}'.format(i, x_str, y_str) )\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    x_data.append(x)\n",
    "    y_data.append(y)\n",
    "          \n",
    "\n",
    "batch_size = len(x_data)\n",
    "        \n",
    "# x_data = [sample_idx[:-1]] # X data sample (0 ~ n-1) hello:hell\n",
    "# y_data = [sample_idx[1:]]  # Y label sample ( 1~ n) hello: ello\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([cell]*2, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size,  tf.float32)\n",
    "outputs, _state = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "sess =  tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(500):\n",
    "    loss_, _ = sess.run([loss, train], feed_dict={X:x_data, Y:y_data})\n",
    "\n",
    "    print(i, \"loss: \", loss_)\n",
    "\n",
    "result = sess.run(prediction, feed_dict={X:x_data})\n",
    "\n",
    "answer_full = \"\"\n",
    "result_full = \"\"\n",
    "i = 0\n",
    "for (y, r) in zip(y_data, result):\n",
    "\n",
    "    # print(\"prediction: \", r, \"true Y: \", y)\n",
    "    # print char using dic\n",
    "    result_str = [char_set[c] for c in np.squeeze(r)]\n",
    "    # print(\"\\tPrediction str: \", ''.join(result_str))\n",
    "\n",
    "    answer_str = [char_set[c] for c in np.squeeze(y)]\n",
    "    # print(\"\\tAnswer str: \", ''.join(answer_str))\n",
    "    # print(\"\\tAnswer str2: \",  answer_str)\n",
    "\n",
    "    if i==0:\n",
    "        answer_full = \"{}{}\".format(answer_full, ''.join(answer_str))\n",
    "    else:\n",
    "        answer_full = \"{}{}\".format(answer_full, answer_str[-1])\n",
    "\n",
    "    if i==0:\n",
    "        result_full = \"{}{}\".format(result_full, ''.join(result_str))\n",
    "    else:\n",
    "        result_full = \"{}{}\".format(result_full, result_str[-1])\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "print(\"Answer_full: \", answer_full)\n",
    "print(\"Result_full: \", result_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source - SoftMax Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  3.3395\n",
      "1 loss:  3.01851\n",
      "2 loss:  3.12091\n",
      "3 loss:  2.85825\n",
      "4 loss:  2.76286\n",
      "5 loss:  2.70782\n",
      "6 loss:  2.62646\n",
      "7 loss:  2.49501\n",
      "8 loss:  2.33889\n",
      "9 loss:  2.17974\n",
      "10 loss:  2.04237\n",
      "11 loss:  1.88793\n",
      "12 loss:  1.74531\n",
      "13 loss:  1.61573\n",
      "14 loss:  1.49048\n",
      "15 loss:  1.37545\n",
      "16 loss:  1.26581\n",
      "17 loss:  1.17268\n",
      "18 loss:  1.09451\n",
      "19 loss:  1.00587\n",
      "20 loss:  0.920819\n",
      "21 loss:  0.850004\n",
      "22 loss:  0.777583\n",
      "23 loss:  0.716121\n",
      "24 loss:  0.654456\n",
      "25 loss:  0.6057\n",
      "26 loss:  0.558897\n",
      "27 loss:  0.518936\n",
      "28 loss:  0.487815\n",
      "29 loss:  0.457179\n",
      "30 loss:  0.43148\n",
      "31 loss:  0.410719\n",
      "32 loss:  0.391165\n",
      "33 loss:  0.375039\n",
      "34 loss:  0.359192\n",
      "35 loss:  0.346373\n",
      "36 loss:  0.335976\n",
      "37 loss:  0.325438\n",
      "38 loss:  0.316858\n",
      "39 loss:  0.308904\n",
      "40 loss:  0.301702\n",
      "41 loss:  0.294782\n",
      "42 loss:  0.289919\n",
      "43 loss:  0.284781\n",
      "44 loss:  0.280026\n",
      "45 loss:  0.275815\n",
      "46 loss:  0.27196\n",
      "47 loss:  0.268264\n",
      "48 loss:  0.265318\n",
      "49 loss:  0.262638\n",
      "Answer_full:  f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "Result_full:  t you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")\n",
    "char_set = list(set(sentence)) # 유니크한 문자열을 리스트로 넣는다.\n",
    "char_dic = {w: i for i, w in enumerate(char_set)} # 리스트 문자열을 index로 매칭되는 딕셔너리를 만든다.\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "data_dim = len(char_set)\n",
    "rnn_hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10 # Any value\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(sentence) - sequence_length):\n",
    "    x_str = sentence[i:i+sequence_length]\n",
    "    y_str = sentence[i+1:i+sequence_length+1]\n",
    "    # print( '{0:03d} {1}->{2}'.format(i, x_str, y_str) )\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "    \n",
    "    x_data.append(x)\n",
    "    y_data.append(y)\n",
    "          \n",
    "\n",
    "batch_size = len(x_data)\n",
    "        \n",
    "# x_data = [sample_idx[:-1]] # X data sample (0 ~ n-1) hello:hell\n",
    "# y_data = [sample_idx[1:]]  # Y label sample ( 1~ n) hello: ello\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size,  tf.float32)\n",
    "outputs, _state = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "x_for_softmax = tf.reshape(outputs, [-1, rnn_hidden_size])\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [rnn_hidden_size, num_classes])\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [1, num_classes])\n",
    "outputs = tf.matmul(x_for_softmax, softmax_w)+softmax_b\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "sess =  tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(50):\n",
    "    loss_, _ = sess.run([loss, train], feed_dict={X:x_data, Y:y_data})\n",
    "\n",
    "    print(i, \"loss: \", loss_)\n",
    "\n",
    "result = sess.run(prediction, feed_dict={X:x_data})\n",
    "\n",
    "answer_full = \"\"\n",
    "result_full = \"\"\n",
    "i = 0\n",
    "for (y, r) in zip(y_data, result):\n",
    "\n",
    "    # print(\"prediction: \", r, \"true Y: \", y)\n",
    "    # print char using dic\n",
    "    result_str = [char_set[c] for c in np.squeeze(r)]\n",
    "    # print(\"\\tPrediction str: \", ''.join(result_str))\n",
    "\n",
    "    answer_str = [char_set[c] for c in np.squeeze(y)]\n",
    "    # print(\"\\tAnswer str: \", ''.join(answer_str))\n",
    "    # print(\"\\tAnswer str2: \",  answer_str)\n",
    "\n",
    "    if i==0:\n",
    "        answer_full = \"{}{}\".format(answer_full, ''.join(answer_str))\n",
    "    else:\n",
    "        answer_full = \"{}{}\".format(answer_full, answer_str[-1])\n",
    "\n",
    "    if i==0:\n",
    "        result_full = \"{}{}\".format(result_full, ''.join(result_str))\n",
    "    else:\n",
    "        result_full = \"{}{}\".format(result_full, result_str[-1])\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "print(\"Answer_full: \", answer_full)\n",
    "print(\"Result_full: \", result_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source - Softmax + Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss:  3.19448\n",
      "1 loss:  3.08043\n",
      "2 loss:  3.01146\n",
      "3 loss:  2.88652\n",
      "4 loss:  2.86369\n",
      "5 loss:  2.82592\n",
      "6 loss:  2.79319\n",
      "7 loss:  2.76791\n",
      "8 loss:  2.71617\n",
      "9 loss:  2.66848\n",
      "10 loss:  2.61407\n",
      "11 loss:  2.52762\n",
      "12 loss:  2.47005\n",
      "13 loss:  2.40335\n",
      "14 loss:  2.28229\n",
      "15 loss:  2.18383\n",
      "16 loss:  2.0757\n",
      "17 loss:  1.94584\n",
      "18 loss:  1.83697\n",
      "19 loss:  1.69621\n",
      "20 loss:  1.57077\n",
      "21 loss:  1.45244\n",
      "22 loss:  1.31455\n",
      "23 loss:  1.19999\n",
      "24 loss:  1.09749\n",
      "25 loss:  0.989764\n",
      "26 loss:  0.891393\n",
      "27 loss:  0.815526\n",
      "28 loss:  0.734493\n",
      "29 loss:  0.67623\n",
      "30 loss:  0.613738\n",
      "31 loss:  0.569623\n",
      "32 loss:  0.526452\n",
      "33 loss:  0.491365\n",
      "34 loss:  0.454785\n",
      "35 loss:  0.431624\n",
      "36 loss:  0.410327\n",
      "37 loss:  0.393624\n",
      "38 loss:  0.381953\n",
      "39 loss:  0.364098\n",
      "40 loss:  0.349105\n",
      "41 loss:  0.337241\n",
      "42 loss:  0.32728\n",
      "43 loss:  0.314608\n",
      "44 loss:  0.305762\n",
      "45 loss:  0.296174\n",
      "46 loss:  0.290268\n",
      "47 loss:  0.284958\n",
      "48 loss:  0.279464\n",
      "49 loss:  0.275392\n",
      "Answer_full:  f you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n",
      "Result_full:  t you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sentence = (\"if you want to build a ship, don't drum up people together to \"\n",
    "            \"collect wood and don't assign them tasks and work, but rather \"\n",
    "            \"teach them to long for the endless immensity of the sea.\")\n",
    "char_set = list(set(sentence)) # 유니크한 문자열을 리스트로 넣는다.\n",
    "char_dic = {w: i for i, w in enumerate(char_set)} # 리스트 문자열을 index로 매칭되는 딕셔너리를 만든다.\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "data_dim = len(char_set)\n",
    "rnn_hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "sequence_length = 10 # Any value\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(0, len(sentence)- sequence_length):\n",
    "    x_str = sentence[i:i+sequence_length]\n",
    "    y_str = sentence[i+1:i+sequence_length+1]\n",
    "    # print(i, x_str, ' -> ', y_str)\n",
    "\n",
    "    x = [char_dic[c] for c in x_str]\n",
    "    y = [char_dic[c] for c in y_str]\n",
    "\n",
    "    x_data.append(x)\n",
    "    y_data.append(y)\n",
    "          \n",
    "\n",
    "batch_size = len(x_data)\n",
    "        \n",
    "# x_data = [sample_idx[:-1]] # X data sample (0 ~ n-1) hello:hell\n",
    "# y_data = [sample_idx[1:]]  # Y label sample ( 1~ n) hello: ello\n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length])\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes)\n",
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=rnn_hidden_size, state_is_tuple=True)\n",
    "cell = tf.contrib.rnn.MultiRNNCell([cell]*2, state_is_tuple=True)\n",
    "initial_state = cell.zero_state(batch_size,  tf.float32)\n",
    "outputs, _state = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "x_for_softmax = tf.reshape(outputs, [-1, rnn_hidden_size])\n",
    "softmax_w = tf.get_variable(\"softmax_w\", [rnn_hidden_size, num_classes])\n",
    "softmax_b = tf.get_variable(\"softmax_b\", [1, num_classes])\n",
    "outputs = tf.matmul(x_for_softmax, softmax_w)+softmax_b\n",
    "outputs = tf.reshape(outputs, [batch_size, sequence_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits=outputs, targets=Y, weights=weights)\n",
    "\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)\n",
    "\n",
    "sess =  tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10):\n",
    "    loss_, _ = sess.run([loss, train], feed_dict={X:x_data, Y:y_data})\n",
    "\n",
    "    print(i, \"loss: \", loss_)\n",
    "\n",
    "result = sess.run(prediction, feed_dict={X:x_data})\n",
    "\n",
    "answer_full = \"\"\n",
    "result_full = \"\"\n",
    "i = 0\n",
    "for (y, r) in zip(y_data, result):\n",
    "\n",
    "    # print(\"prediction: \", r, \"true Y: \", y)\n",
    "    # print char using dic\n",
    "    result_str = [char_set[c] for c in np.squeeze(r)]\n",
    "    # print(\"\\tPrediction str: \", ''.join(result_str))\n",
    "\n",
    "    answer_str = [char_set[c] for c in np.squeeze(y)]\n",
    "    # print(\"\\tAnswer str: \", ''.join(answer_str))\n",
    "    # print(\"\\tAnswer str2: \",  answer_str)\n",
    "\n",
    "    if i==0:\n",
    "        answer_full = \"{}{}\".format(answer_full, ''.join(answer_str))\n",
    "    else:\n",
    "        answer_full = \"{}{}\".format(answer_full, answer_str[-1])\n",
    "\n",
    "    if i==0:\n",
    "        result_full = \"{}{}\".format(result_full, ''.join(result_str))\n",
    "    else:\n",
    "        result_full = \"{}{}\".format(result_full, result_str[-1])\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "print(\"Answer_full: \", answer_full)\n",
    "print(\"Result_full: \", result_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc",
   "language": "python",
   "name": "tc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
