{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1702,
     "output_extras": [
      {
       "item_id": 54
      },
      {
       "item_id": 55
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 307125,
     "status": "error",
     "timestamp": 1522396224747,
     "user": {
      "displayName": "김민욱",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "108006258518439830382"
     },
     "user_tz": -540
    },
    "id": "AvYP9FLXu4A3",
    "outputId": "bb61db14-1142-454a-aac7-7acca8c5c235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "WARNING:tensorflow:From <ipython-input-1-92a5173a694c>:105: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Epoch: 0001 cost = 0.448497932\n",
      "Epoch: 0002 cost = 0.112512294\n",
      "Epoch: 0003 cost = 0.089538135\n",
      "Epoch: 0004 cost = 0.071975009\n",
      "Epoch: 0005 cost = 0.057651816\n",
      "Epoch: 0006 cost = 0.053585116\n",
      "Epoch: 0007 cost = 0.048262265\n",
      "Epoch: 0008 cost = 0.042739795\n",
      "Epoch: 0009 cost = 0.039808381\n",
      "Epoch: 0010 cost = 0.039720183\n",
      "Epoch: 0011 cost = 0.033897462\n",
      "Epoch: 0012 cost = 0.036678755\n",
      "Epoch: 0013 cost = 0.033453652\n",
      "Epoch: 0014 cost = 0.033176561\n",
      "Epoch: 0015 cost = 0.029673411\n",
      "Epoch: 0016 cost = 0.031965396\n",
      "Epoch: 0017 cost = 0.027027064\n",
      "Epoch: 0018 cost = 0.024619887\n",
      "Epoch: 0019 cost = 0.024855465\n",
      "Epoch: 0020 cost = 0.024299113\n",
      "Epoch: 0021 cost = 0.026166432\n",
      "Epoch: 0022 cost = 0.025793536\n",
      "Epoch: 0023 cost = 0.022749806\n",
      "Epoch: 0024 cost = 0.022777967\n",
      "Epoch: 0025 cost = 0.020522322\n",
      "Epoch: 0026 cost = 0.023228076\n",
      "Epoch: 0027 cost = 0.023551717\n",
      "Epoch: 0028 cost = 0.021406098\n",
      "Epoch: 0029 cost = 0.019535644\n",
      "Epoch: 0030 cost = 0.020730245\n",
      "Epoch: 0031 cost = 0.020173270\n",
      "Epoch: 0032 cost = 0.021303753\n",
      "Epoch: 0033 cost = 0.018787642\n",
      "Epoch: 0034 cost = 0.018396144\n",
      "Epoch: 0035 cost = 0.019691062\n",
      "Epoch: 0036 cost = 0.018790539\n",
      "Epoch: 0037 cost = 0.020064891\n",
      "Epoch: 0038 cost = 0.018471843\n",
      "Epoch: 0039 cost = 0.019180911\n",
      "Epoch: 0040 cost = 0.018456674\n",
      "Epoch: 0041 cost = 0.017777444\n",
      "Epoch: 0042 cost = 0.016966245\n",
      "Epoch: 0043 cost = 0.016605351\n",
      "Epoch: 0044 cost = 0.018398135\n",
      "Epoch: 0045 cost = 0.020216398\n",
      "Epoch: 0046 cost = 0.018005995\n",
      "Epoch: 0047 cost = 0.015157735\n",
      "Epoch: 0048 cost = 0.017848006\n",
      "Epoch: 0049 cost = 0.015446712\n",
      "Epoch: 0050 cost = 0.017848111\n",
      "Learning Time =  253.9549744129181\n",
      "Accuracy:  0.9920641\n",
      "[1 3 2 ... 7 6 9]\n",
      "[1 3 2 ... 7 6 9]\n"
     ]
    },
    {
     "ename": "MessageError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92a5173a694c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./predict.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m   })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     84\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m     85\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
     ]
    }
   ],
   "source": [
    "!pip install -U -q PyDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import files\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "\n",
    "class MNIST:\n",
    "        \n",
    "    def __init__(self):\n",
    "        print(\"init\")\n",
    "        \n",
    "    def one_hot(self, Y_int, max_num):\n",
    "        return np.eye(max_num)[Y_int]\n",
    "    \n",
    "    def load_test_data(self, csv_file_path):\n",
    "        x = np.loadtxt(csv_file_path, delimiter=',', dtype=np.int32)\n",
    "        self.TestX = x/255.0               # data : [None, 784]\n",
    "        \n",
    "        \n",
    "    def load_train_data(self, csv_file_path, divide_ratio, nb_classes):\n",
    "        \n",
    "        xy = np.loadtxt(csv_file_path, delimiter=',', dtype=np.int32)\n",
    "        \n",
    "        total_size = len(xy)\n",
    "        divide_num = int( total_size*divide_ratio );\n",
    "        \n",
    "        self.TrainX = xy[:divide_num, 1:]/255.0               # data : [None, 784]\n",
    "        self.TrainY_int = xy[:divide_num, [0]]                # label : [None, 1]\n",
    "        self.TrainY = self.one_hot(self.TrainY_int, nb_classes)       # one hot : [None, 1, 10]\n",
    "        self.TrainY = np.reshape(self.TrainY, [-1, nb_classes])     # one hot : [None, 10]\n",
    "        \n",
    "        # print(self.TestX.shape)\n",
    "        self.ValX = xy[divide_num:, 1:]/255.0                # data : [None, 784]\n",
    "        self.ValY_int = xy[divide_num:, [0]]                 # label : [None, 1]\n",
    "        self.ValY = self.one_hot(self.ValY_int, nb_classes)         # one hot : [None, 1, 10]\n",
    "        self.ValY = np.reshape(self.ValY, [-1, nb_classes])       # one hot : [None, 10]\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        # random int를 갯수만큼 수행하여 해당 index의 X와 Y를 리턴한다.\n",
    "        sample_indices = np.random.randint(0, len(self.TrainY), size=batch_size)\n",
    "        return self.TrainX[sample_indices, :], self.TrainY[sample_indices, :]\n",
    "       \n",
    "    def train(self, batch_size, traing_epoch):\n",
    "        # Data Initialize\n",
    "        X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "        X_img = tf.reshape(X, [-1, 28, 28, 1]) # img 28*28*1(BW Image)\n",
    "        Y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
    "        W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "        # Conv -> (?, 28, 28, 32)\n",
    "        L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        L1 = tf.nn.relu(L1)\n",
    "        # Pool -> (?, 14, 14, 32)\n",
    "        L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], \n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "        L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
    "        W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "        # Conv -> (?, 14, 14, 64)\n",
    "        L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        L2 = tf.nn.relu(L2)\n",
    "        # Pool -> (?, 7, 7, 64)\n",
    "        L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], \n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "        L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "        # L3 ImgIn shape=(?, 7, 7, 128)\n",
    "        W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "        # Conv -> (?, 7, 7, 128)\n",
    "        L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        L3 = tf.nn.relu(L3)\n",
    "        # Pool -> (?, 4, 4, 128)\n",
    "        L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], \n",
    "                            strides=[1, 2, 2, 1], padding='SAME')\n",
    "        L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "        # reshape = (?, 3136)\n",
    "        L3 = tf.reshape(L3, [-1, 4*4*128])\n",
    "\n",
    "        # L4 fully Connected Layer\n",
    "        W4 = tf.get_variable(\"W4\", shape=[4*4*128, 625], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b4 = tf.Variable(tf.random_normal([1, 625]))\n",
    "        L4 = tf.nn.relu(tf.matmul(L3, W4)+b4)\n",
    "        L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "        # L5 Final FC 625 input -> 10 output\n",
    "        W5 = tf.get_variable(\"W5\", shape=[625, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b5 = tf.Variable(tf.random_normal([1, 10]))\n",
    "\n",
    "        # define Hypothesis\n",
    "        logits = tf.matmul(L4, W5)+b5\n",
    "        hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "        # define cost\n",
    "        cost_i = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)\n",
    "        cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "        # define gradient\n",
    "        gradient = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "        # calc accuracy\n",
    "        prediction = tf.argmax(hypothesis, 1)\n",
    "        answer = tf.argmax(Y, 1)\n",
    "        accuracy = tf.reduce_mean( tf.cast( tf.equal(prediction, answer), dtype=tf.float32)) \n",
    "\n",
    "        # init network\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # go implement\n",
    "        total_recur = 0\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(traing_epoch):\n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(len(self.TrainY)/batch_size)\n",
    "\n",
    "            for batch in range(total_batch):\n",
    "                batch_X, batch_Y = self.next_batch(batch_size)\n",
    "                cost_, _ = sess.run([cost, gradient], feed_dict={X: batch_X, Y:batch_Y, keep_prob:0.7})\n",
    "                avg_cost += cost_/total_batch\n",
    "                total_recur = total_recur + 1\n",
    "\n",
    "            print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "        end_time = time.time()\n",
    "        print('Learning Time = ', end_time-start_time)\n",
    "        # implement accuracy\n",
    "        print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: self.ValX, Y:self.ValY, keep_prob:1.0} ) )\n",
    "        \n",
    "        print(sess.run(prediction, feed_dict={X: self.ValX, keep_prob:1.0}))\n",
    "        print(sess.run(answer, feed_dict={Y: self.ValY, keep_prob:1.0}))\n",
    "        \n",
    "        predict = sess.run(prediction, feed_dict={X: self.TestX, keep_prob:1.0})\n",
    "        np.savetxt(\"./predict.csv\", predict, delimiter=\",\")\n",
    "\n",
    "        \n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "#2. Get the file\n",
    "downloaded = drive.CreateFile({'id':'1J7BI4Gvu1-1-Zgqpw6VgDmjVdmP0QS5Z'}) # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('train.csv')\n",
    "\n",
    "# downloaded = drive.CreateFile({'id':'1NNPxbxX65me8LbQblenrGvyFcEqOm946'}) # replace the id with id of file you want to access\n",
    "# downloaded.GetContentFile('test_tiny.csv')\n",
    "\n",
    "downloaded = drive.CreateFile({'id':'1qd3idtK9SvfKubj7f2FRGmdUMjXtBQI-'}) # replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('test.csv')\n",
    "        \n",
    "test = MNIST()\n",
    "test.load_train_data('train.csv', 0.7, 10)\n",
    "test.load_test_data('test.csv')\n",
    "test.train(50, 50)\n",
    "\n",
    "files.download('./predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SYzsUL_GvTqQ"
   },
   "outputs": [],
   "source": [
    "files.download('./predict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "U39KH1Iz3PRO"
   },
   "source": [
    "![tensorboard](./김민욱_Score.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Untitled0.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
