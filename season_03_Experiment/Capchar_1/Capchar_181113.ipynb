{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capchar_181113.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "49dk4uoxxh9N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Test Data ##"
      ]
    },
    {
      "metadata": {
        "id": "OxVgZVllwkfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SO63NsvJxWt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2. Get the file\n",
        "downloaded = drive.CreateFile({'id':'1bKD8IT-I3JyMUzXfViVMfgYXAcXgJYRy'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('image_.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gN-4cH4Rx1V1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir checkpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MtEJzTgBeTTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# downloaded = drive.CreateFile({'id':'10PphrHSK-R4zZfN1tYKObb1DYUTtS5io'}) # replace the id with id of file you want to access\n",
        "# downloaded.GetContentFile('./checkpoint/ckpt.t7')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6OiglgrnyAD-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Zip Extraction ##"
      ]
    },
    {
      "metadata": {
        "id": "XfHLPq7wx8bd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os, os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFrupsZSyGU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ImagePath = './Image'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kJC8OKLgyIW9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "objZip = zipfile.ZipFile('./image_.zip')\n",
        "objZip.extractall(ImagePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2V_Ew-8IySy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1S6RTUPPyV6U",
        "colab_type": "code",
        "outputId": "ec3b01a6-cfd5-45d0-fbc6-309f56a79d0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "Image('./Image/train10/00356.jpeg')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "./Image/train10/00356.jpeg",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "Mk88O8J1yqzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install Pytorch 4.0 ##"
      ]
    },
    {
      "metadata": {
        "id": "-m_P2FPPye_G",
        "colab_type": "code",
        "outputId": "56a6741c-d6f6-468f-be3b-3843359fb85b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "# torch 0.4 install for torch.no_grad()\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "# !pip3 install torchvision"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5c69a000 @  0x7f2daa0742a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n",
            "0.4.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gtSRc1sIy6kt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Make pandas data ##"
      ]
    },
    {
      "metadata": {
        "id": "xqn6t3POe4K0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Data ###"
      ]
    },
    {
      "metadata": {
        "id": "Q63H280TyuDG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B4N7r2Mpy-FG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_DATA_PATH = \"./Image/train/\"\n",
        "VALID_DATA_PATH = \"./Image/validate/\"\n",
        "TEST_DATA_PATH  = \"./Image/test/\"\n",
        "\n",
        "TRAIN10_DATA_PATH  = \"./Image/train10/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aV5h8BXXzI-N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dirs = os.listdir(TRAIN_DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U-GfYKgGzOdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aKmqO8yDzPvV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_train_data = pd.DataFrame(train_dirs, columns=[\"filename\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vb4Y1KfCzSqF",
        "colab_type": "code",
        "outputId": "a7e78bd0-6a28-4c40-a45e-6ab9f054549b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "pd_train_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360566.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02550.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>446035.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34534.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30020.jpeg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename\n",
              "0  360566.jpeg\n",
              "1   02550.jpeg\n",
              "2  446035.jpeg\n",
              "3   34534.jpeg\n",
              "4   30020.jpeg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "uRvW7I3tzXrd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_train_data[\"output\"] = pd_train_data[\"filename\"].str.extract('([0-9]+)', expand=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Jgpc1l_zZUl",
        "colab_type": "code",
        "outputId": "6da1b9ee-da59-4b1e-d810-1b584b07a88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "pd_train_data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360566.jpeg</td>\n",
              "      <td>360566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02550.jpeg</td>\n",
              "      <td>02550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>446035.jpeg</td>\n",
              "      <td>446035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34534.jpeg</td>\n",
              "      <td>34534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30020.jpeg</td>\n",
              "      <td>30020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  output\n",
              "0  360566.jpeg  360566\n",
              "1   02550.jpeg   02550\n",
              "2  446035.jpeg  446035\n",
              "3   34534.jpeg   34534\n",
              "4   30020.jpeg   30020"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "raVhGN9CzahV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_train_data[\"output0\"] =  pd.to_numeric( pd_train_data[\"output\"].str[0], downcast='integer')\n",
        "pd_train_data[\"output1\"] =  pd.to_numeric( pd_train_data[\"output\"].str[1], downcast='integer')\n",
        "pd_train_data[\"output2\"] =  pd.to_numeric( pd_train_data[\"output\"].str[2], downcast='integer')\n",
        "pd_train_data[\"output3\"] =  pd.to_numeric( pd_train_data[\"output\"].str[3], downcast='integer')\n",
        "pd_train_data[\"output4\"] =  pd.to_numeric( pd_train_data[\"output\"].str[4], downcast='integer')\n",
        "pd_train_data[\"output5\"] =  pd.to_numeric( pd_train_data[\"output\"].str[5], downcast='integer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FiFXt4QJfcSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "cb8c1971-d8ba-4ca8-d71b-2136828899c0"
      },
      "cell_type": "code",
      "source": [
        "pd_train_data.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "      <th>output0</th>\n",
              "      <th>output1</th>\n",
              "      <th>output2</th>\n",
              "      <th>output3</th>\n",
              "      <th>output4</th>\n",
              "      <th>output5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360566.jpeg</td>\n",
              "      <td>360566</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02550.jpeg</td>\n",
              "      <td>02550</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>446035.jpeg</td>\n",
              "      <td>446035</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34534.jpeg</td>\n",
              "      <td>34534</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30020.jpeg</td>\n",
              "      <td>30020</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  output  output0  output1  output2  output3  output4  output5\n",
              "0  360566.jpeg  360566        3        6        0        5        6      6.0\n",
              "1   02550.jpeg   02550        0        2        5        5        0      NaN\n",
              "2  446035.jpeg  446035        4        4        6        0        3      5.0\n",
              "3   34534.jpeg   34534        3        4        5        3        4      NaN\n",
              "4   30020.jpeg   30020        3        0        0        2        0      NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "wiBJQZBAInfK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_train_data = pd_train_data.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDrxuO3wzpDV",
        "colab_type": "code",
        "outputId": "daf8a70b-3b35-4664-9745-950f79e93014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "cell_type": "code",
      "source": [
        "pd_train_data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "      <th>output0</th>\n",
              "      <th>output1</th>\n",
              "      <th>output2</th>\n",
              "      <th>output3</th>\n",
              "      <th>output4</th>\n",
              "      <th>output5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>360566.jpeg</td>\n",
              "      <td>360566</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02550.jpeg</td>\n",
              "      <td>02550</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>446035.jpeg</td>\n",
              "      <td>446035</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34534.jpeg</td>\n",
              "      <td>34534</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30020.jpeg</td>\n",
              "      <td>30020</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  output  output0  output1  output2  output3  output4  output5\n",
              "0  360566.jpeg  360566        3        6        0        5        6      6.0\n",
              "1   02550.jpeg   02550        0        2        5        5        0      0.0\n",
              "2  446035.jpeg  446035        4        4        6        0        3      5.0\n",
              "3   34534.jpeg   34534        3        4        5        3        4      0.0\n",
              "4   30020.jpeg   30020        3        0        0        2        0      0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "jrbFF827f1ay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Valid Data ###"
      ]
    },
    {
      "metadata": {
        "id": "iJRjkHlVf7LS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_dirs = os.listdir(VALID_DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aCCy2MF5gLxZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQMyXmxQgPrH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data = pd.DataFrame(valid_dirs, columns=[\"filename\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtErdB_7gPkZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e8aa9a76-a92b-4e2f-8fa8-b63826e7ce2d"
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99239.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43495.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>830364.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06959.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>942283.jpeg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename\n",
              "0   99239.jpeg\n",
              "1   43495.jpeg\n",
              "2  830364.jpeg\n",
              "3   06959.jpeg\n",
              "4  942283.jpeg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "PXUMIAa_gPek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data[\"output\"] = pd_valid_data[\"filename\"].str.extract('([0-9]+)', expand=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5IFcbW5bgPYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "56fb1dc5-f882-45d6-8400-633ac55eeb8c"
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99239.jpeg</td>\n",
              "      <td>99239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43495.jpeg</td>\n",
              "      <td>43495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>830364.jpeg</td>\n",
              "      <td>830364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06959.jpeg</td>\n",
              "      <td>06959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>942283.jpeg</td>\n",
              "      <td>942283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  output\n",
              "0   99239.jpeg   99239\n",
              "1   43495.jpeg   43495\n",
              "2  830364.jpeg  830364\n",
              "3   06959.jpeg   06959\n",
              "4  942283.jpeg  942283"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "xJtxPMLNgPS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data[\"output0\"] =  pd.to_numeric( pd_valid_data[\"output\"].str[0], downcast='integer')\n",
        "pd_valid_data[\"output1\"] =  pd.to_numeric( pd_valid_data[\"output\"].str[1], downcast='integer')\n",
        "pd_valid_data[\"output2\"] =  pd.to_numeric( pd_valid_data[\"output\"].str[2], downcast='integer')\n",
        "pd_valid_data[\"output3\"] =  pd.to_numeric( pd_valid_data[\"output\"].str[3], downcast='integer')\n",
        "pd_valid_data[\"output4\"] =  pd.to_numeric( pd_valid_data[\"output\"].str[4], downcast='integer')\n",
        "pd_valid_data[\"output5\"] =  pd.to_numeric( pd_valid_data[\"output\"].str[5], downcast='integer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkBl8syvgPL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "27425bd4-0c83-4f71-e609-5b904f4c0c52"
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "      <th>output0</th>\n",
              "      <th>output1</th>\n",
              "      <th>output2</th>\n",
              "      <th>output3</th>\n",
              "      <th>output4</th>\n",
              "      <th>output5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99239.jpeg</td>\n",
              "      <td>99239</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43495.jpeg</td>\n",
              "      <td>43495</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>830364.jpeg</td>\n",
              "      <td>830364</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06959.jpeg</td>\n",
              "      <td>06959</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>942283.jpeg</td>\n",
              "      <td>942283</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  output  output0  output1  output2  output3  output4  output5\n",
              "0   99239.jpeg   99239        9        9        2        3        9      NaN\n",
              "1   43495.jpeg   43495        4        3        4        9        5      NaN\n",
              "2  830364.jpeg  830364        8        3        0        3        6      4.0\n",
              "3   06959.jpeg   06959        0        6        9        5        9      NaN\n",
              "4  942283.jpeg  942283        9        4        2        2        8      3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "pP91j3fIgPDJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data = pd_valid_data.fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8Iso-wGgO5w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e9395f7c-5634-4749-febc-be0e51605b6b"
      },
      "cell_type": "code",
      "source": [
        "pd_valid_data.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "      <th>output0</th>\n",
              "      <th>output1</th>\n",
              "      <th>output2</th>\n",
              "      <th>output3</th>\n",
              "      <th>output4</th>\n",
              "      <th>output5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>99239.jpeg</td>\n",
              "      <td>99239</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43495.jpeg</td>\n",
              "      <td>43495</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>830364.jpeg</td>\n",
              "      <td>830364</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>06959.jpeg</td>\n",
              "      <td>06959</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>942283.jpeg</td>\n",
              "      <td>942283</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  output  output0  output1  output2  output3  output4  output5\n",
              "0   99239.jpeg   99239        9        9        2        3        9      0.0\n",
              "1   43495.jpeg   43495        4        3        4        9        5      0.0\n",
              "2  830364.jpeg  830364        8        3        0        3        6      4.0\n",
              "3   06959.jpeg   06959        0        6        9        5        9      0.0\n",
              "4  942283.jpeg  942283        9        4        2        2        8      3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "HcBzg9O-zt29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Image Load using PILOW ##"
      ]
    },
    {
      "metadata": {
        "id": "ardKaRS_zqm9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        # return img.convert('RGB') # RGB\n",
        "        return img.convert('L') # Gray\n",
        "        # return img.convert('1') # binary\n",
        "\n",
        "\n",
        "def accimage_loader(path):\n",
        "    import accimage\n",
        "    try:\n",
        "        return accimage.Image(path)\n",
        "    except IOError:\n",
        "        # Potentially a decoding problem, fall back to PIL.Image\n",
        "        return pil_loader(path)\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    from torchvision import get_image_backend\n",
        "    if get_image_backend() == 'accimage':\n",
        "        return accimage_loader(path)\n",
        "    else:\n",
        "        return pil_loader(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7NT9m9hzzLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = default_loader(\"./Image/train/00345.jpeg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMplsORhz2-G",
        "colab_type": "code",
        "outputId": "a3ae7d81-8222-403a-ef92-eb31b5a1ddd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "cell_type": "code",
      "source": [
        "image"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAAA8CAAAAADEAO7JAAAOVUlEQVR4nO2ZeZDV1ZXHv7/1/d7a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\nX9GJuIL+cqI9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=160x60 at 0x7FBD31368128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "oefTsiD70OX1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PreProcess Image Data ##"
      ]
    },
    {
      "metadata": {
        "id": "ov1S1RmQ0NAN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import collections\n",
        "\n",
        "try:\n",
        "    import accimage\n",
        "except ImportError:\n",
        "    accimage = None\n",
        "    \n",
        "def _is_pil_image(img):\n",
        "    if accimage is not None:\n",
        "        return isinstance(img, (Image.Image, accimage.Image))\n",
        "    else:\n",
        "        return isinstance(img, Image.Image)\n",
        "\n",
        "\n",
        "def _is_tensor_image(img):\n",
        "    return torch.is_tensor(img) and img.ndimension() == 3\n",
        "\n",
        "\n",
        "def _is_numpy_image(img):\n",
        "    return isinstance(img, np.ndarray) and (img.ndim in {2, 3})\n",
        "\n",
        "def to_tensor(pic):\n",
        "    \"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\n",
        "    See ``ToTensor`` for more details.\n",
        "    Args:\n",
        "        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\n",
        "    Returns:\n",
        "        Tensor: Converted image.\n",
        "    \"\"\"\n",
        "    if not(_is_pil_image(pic) or _is_numpy_image(pic)):\n",
        "        raise TypeError('pic should be PIL Image or ndarray. Got {}'.format(type(pic)))\n",
        "\n",
        "    if isinstance(pic, np.ndarray):\n",
        "        # handle numpy array\n",
        "        img = torch.from_numpy(pic.transpose((2, 0, 1)))\n",
        "        # backward compatibility\n",
        "        if isinstance(img, torch.ByteTensor):\n",
        "            return img.float().div(255)\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    if accimage is not None and isinstance(pic, accimage.Image):\n",
        "        nppic = np.zeros([pic.channels, pic.height, pic.width], dtype=np.float32)\n",
        "        pic.copyto(nppic)\n",
        "        return torch.from_numpy(nppic)\n",
        "\n",
        "    # handle PIL Image\n",
        "    if pic.mode == 'I':\n",
        "        img = torch.from_numpy(np.array(pic, np.int32, copy=False))\n",
        "    elif pic.mode == 'I;16':\n",
        "        img = torch.from_numpy(np.array(pic, np.int16, copy=False))\n",
        "    elif pic.mode == 'F':\n",
        "        img = torch.from_numpy(np.array(pic, np.float32, copy=False))\n",
        "    elif pic.mode == '1':\n",
        "        img = 255 * torch.from_numpy(np.array(pic, np.uint8, copy=False))\n",
        "    else:\n",
        "        img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
        "    # PIL image mode: L, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
        "    if pic.mode == 'YCbCr':\n",
        "        nchannel = 3\n",
        "    elif pic.mode == 'I;16':\n",
        "        nchannel = 1\n",
        "    else:\n",
        "        nchannel = len(pic.mode)\n",
        "    img = img.view(pic.size[1], pic.size[0], nchannel)\n",
        "    # put it from HWC to CHW format\n",
        "    # yikes, this transpose takes 80% of the loading time/CPU\n",
        "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
        "    if isinstance(img, torch.ByteTensor):\n",
        "        return img.float().div(255)\n",
        "    else:\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5QhZz9F0TCf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_tensor = to_tensor(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pA9rCyVI0Ux1",
        "colab_type": "code",
        "outputId": "a8534df5-ea16-4a28-e565-439e44a8267d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "image_tensor.type()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "FvcLJ-0q0VtG",
        "colab_type": "code",
        "outputId": "d20a8454-cfc7-4e37-aa08-e24beb0e31af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "image_tensor.size()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 60, 160])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "hqiOzjKf0Yu9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Design Dataset ##"
      ]
    },
    {
      "metadata": {
        "id": "Xa0ZY66b0XCW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9MoqX98u0cKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CapCharDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.input_data = []\n",
        "        self.target_data = []\n",
        "        \n",
        "        # Load All Data\n",
        "        print(\"image data loading...\")\n",
        "        for index, row in data.iterrows():\n",
        "            filename = data_root + row['filename']\n",
        "            image = default_loader(filename)\n",
        "            image_tensor = to_tensor(image)\n",
        "            self.input_data.append(image_tensor)\n",
        "             \n",
        "            target_tensor = torch.tensor([[ int(row['output0']), int(row['output1']), int(row['output2']),  \n",
        "                                            int(row['output3']), int(row['output4']), int(row['output5']) ]])             \n",
        "            self.target_data.append(target_tensor)\n",
        "        \n",
        "        print(\"[{}] data is loaded!\".format(len(self.input_data)))\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.input_data[index], self.target_data[index]\n",
        "                                          \n",
        "    def __len__(self):\n",
        "        return len(self.input_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JvY8H3WX0dfX",
        "colab_type": "code",
        "outputId": "0559bad5-c368-46b0-97fc-ffc2a2f999c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "data_root = TRAIN_DATA_PATH\n",
        "train_dataset = CapCharDataSet(pd_train_data)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=20, shuffle=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image data loading...\n",
            "[10000] data is loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XXxdbMyThTz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "96e14d42-bb3e-4b76-904d-270f64cc0834"
      },
      "cell_type": "code",
      "source": [
        "data_root = VALID_DATA_PATH\n",
        "valid_dataset = CapCharDataSet(pd_valid_data)\n",
        "valid_loader = DataLoader(dataset=valid_dataset, batch_size=20, shuffle=False)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image data loading...\n",
            "[4356] data is loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXvosomU0lvl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Design Model ##"
      ]
    },
    {
      "metadata": {
        "id": "1O7cPEz70iIm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        \n",
        "        ## input 1*60*160\n",
        "        self.conv1 = torch.nn.Conv2d( 1, 48, kernel_size=5)\n",
        "        self.mp1 = torch.nn.MaxPool2d((2,2), stride=(2, 2))\n",
        "        \n",
        "        self.conv2 = torch.nn.Conv2d(48, 64, kernel_size=5)        \n",
        "        self.mp2 = torch.nn.MaxPool2d((2,1), stride=(2, 1))\n",
        "        \n",
        "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3)        \n",
        "        self.mp3 = torch.nn.MaxPool2d((2,2), stride=(2, 2))\n",
        "        \n",
        "        self.conv4 = torch.nn.Conv2d(128, 256, kernel_size=4)        \n",
        "        self.mp4 = torch.nn.MaxPool2d((2,2), stride=(2, 2))\n",
        "        \n",
        "        self.fc1 = torch.nn.Linear(4096, 3072)\n",
        "        self.fc2 = torch.nn.Linear(3072, 3072)\n",
        "        \n",
        "        self.fcO1 = torch.nn.Linear(3072, 10)\n",
        "        self.fcO2 = torch.nn.Linear(3072, 10)\n",
        "        self.fcO3 = torch.nn.Linear(3072, 10)\n",
        "        self.fcO4 = torch.nn.Linear(3072, 10)\n",
        "        self.fcO5 = torch.nn.Linear(3072, 10)\n",
        "        self.fcO6 = torch.nn.Linear(3072, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "        \n",
        "        x = F.relu(self.mp1(self.conv1(x)))\n",
        "        x = F.relu(self.mp2(self.conv2(x)))\n",
        "        x = F.relu(self.mp3(self.conv3(x)))\n",
        "        x = F.relu(self.mp4(self.conv4(x)))\n",
        "        \n",
        "        x = x.view(in_size, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "      \n",
        "        x1 = F.log_softmax(self.fcO1(x))\n",
        "        x2 = F.log_softmax(self.fcO2(x))\n",
        "        x3 = F.log_softmax(self.fcO3(x))\n",
        "        x4 = F.log_softmax(self.fcO4(x))\n",
        "        x5 = F.log_softmax(self.fcO5(x))\n",
        "        x6 = F.log_softmax(self.fcO6(x))\n",
        "        \n",
        "        return x1, x2, x3, x4, x5, x6\n",
        "        # return output # F.log_softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6rBz78ig0o92",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_cuda else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45CzGB6Y0qSm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dLSQyKpQdclT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os, os.path\n",
        "\n",
        "#@title Resume 여부\n",
        "resume = False #@param {type:\"boolean\"}\n",
        "\n",
        "# 그래프를 위하여 pandas에 accuracy와 loss를 저장한다.\n",
        "train_acc_collect = []\n",
        "valid_acc_collect = []\n",
        "\n",
        "train_loss_collect = []\n",
        "valid_loss_collect = []\n",
        "\n",
        "if resume:\n",
        "    # Load checkpoint.\n",
        "    print('==> Resuming from checkpoint..')\n",
        "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
        "    checkpoint = torch.load('./checkpoint/ckpt.t7')\n",
        "    model.load_state_dict(checkpoint['net'])\n",
        "    best_acc = checkpoint['acc']\n",
        "    start_epoch = checkpoint['epoch']\n",
        "    best_epoch = start_epoch\n",
        "    print('==> best_epoch : ', best_epoch)\n",
        "    print('==> best_acc : ', best_acc)\n",
        "    \n",
        "    ## Load Train Stat\n",
        "    # train_stat = pd.read_csv(\"./checkpoint/test_stat.csv\")\n",
        "    # train_acc_collect = train_stat['TrainAccRate'].tolist()\n",
        "    # valid_acc_collect = train_stat['ValidAccRate'].tolist()\n",
        "    # train_loss_collect = train_stat['TrainLoss'].tolist()\n",
        "    # valid_loss_collect = train_stat['ValidLoss'].tolist()\n",
        "    \n",
        "    print('==> Done..')\n",
        "else:\n",
        "    # train_stat = pd.DataFrame()\n",
        "    start_epoch = 0\n",
        "    best_acc = 0\n",
        "    best_epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dUjcHHF_09Ze",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define criterion & optimizer ##"
      ]
    },
    {
      "metadata": {
        "id": "DKwnjlRu0rXG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00003, weight_decay=1e-5 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qCgLVUp1SCo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train ##"
      ]
    },
    {
      "metadata": {
        "id": "iBYQ3jySvZIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calc_correct(pred_all, answer): \n",
        "  \n",
        "  equality = pred_all.eq(answer)\n",
        "  \n",
        "  sum_correct = ( equality.sum(1) == len(answer[0]) ).sum()\n",
        "    \n",
        "  return sum_correct\n",
        "\n",
        "# calc_correct(a, b, 10.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLOyy3LH1OCv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    \n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in  enumerate(train_loader):\n",
        "    \n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # init optimizer\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Go Forward\n",
        "        # target_pred = model(data)\n",
        "        out1, out2, out3, out4, out5, out6 = model(data)\n",
        "\n",
        "        # Calc loss\n",
        "        target = target.view(-1, 6)\n",
        "                \n",
        "        loss1 = F.nll_loss(out1, target[:,0], size_average=False)\n",
        "        loss2 = F.nll_loss(out2, target[:,1], size_average=False)\n",
        "        loss3 = F.nll_loss(out3, target[:,2], size_average=False)\n",
        "        loss4 = F.nll_loss(out4, target[:,3], size_average=False)\n",
        "        loss5 = F.nll_loss(out5, target[:,4], size_average=False)\n",
        "        loss6 = F.nll_loss(out6, target[:,5], size_average=False)\n",
        "        # print(\"loss1 : \", loss1)\n",
        "        # print(\"loss2 : \", loss2)\n",
        "        # print(\"loss3 : \", loss3)\n",
        "        # print(\"loss4 : \", loss4)\n",
        "        # print(\"loss5 : \", loss5)\n",
        "        # print(\"loss6 : \", loss6)\n",
        "        \n",
        "        loss = loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
        "\n",
        "        pred_1 = out1.data.max(1, keepdim=True)[1]\n",
        "        pred_2 = out2.data.max(1, keepdim=True)[1]\n",
        "        pred_3 = out3.data.max(1, keepdim=True)[1]\n",
        "        pred_4 = out4.data.max(1, keepdim=True)[1]\n",
        "        pred_5 = out5.data.max(1, keepdim=True)[1]\n",
        "        pred_6 = out6.data.max(1, keepdim=True)[1]\n",
        "                \n",
        "        pred_all = torch.cat([pred_1,pred_2, pred_3, pred_4, pred_5, pred_6],1)\n",
        "        # print(\"pred_all\", pred_all)\n",
        "        # print(\"target\", target)\n",
        "        \n",
        "        # Calc Acc (loss < 10.0)      \n",
        "        correct += calc_correct(pred_all, target)\n",
        "        # correct += ((abs(target_pred - target)<3.0).sum(1)==8.0).sum()\n",
        "        # correct += (abs(target_pred - target).sum(1)<10.0).sum()\n",
        "        # correct = (float)(correct.item())\n",
        "        total  += len(target)\n",
        "          \n",
        "        # loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # update weight\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} ({:.0f}/{:.0f})'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item(), correct, total))\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "    print(\"\")\n",
        "    print(epoch, total_loss)\n",
        "    print(\"\")\n",
        "    \n",
        "    # Save checkpoint.\n",
        "    acc = 100.0*(correct)/(total)\n",
        "    print(\"acc = \", acc)\n",
        "      \n",
        "    # Save Train Statistics\n",
        "    epoch_acc = correct/total\n",
        "    epoch_loss = total_loss/(batch_idx+1)\n",
        "    train_acc_collect.append(epoch_acc)\n",
        "    train_loss_collect.append(epoch_loss)\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sC1z6iXycez7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "    \n",
        "    global best_acc\n",
        "    global best_epoch\n",
        "    \n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "      model.eval()\n",
        "\n",
        "      total_loss = 0.0\n",
        "      for batch_idx, (data, target) in  enumerate(valid_loader):\n",
        "\n",
        "          data, target = data.to(device), target.to(device)\n",
        "        \n",
        "          # init optimizer\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Go Forward\n",
        "          # target_pred = model(data)\n",
        "          out1, out2, out3, out4, out5, out6 = model(data)\n",
        "\n",
        "          # Calc loss\n",
        "          target = target.view(-1, 6)\n",
        "\n",
        "          loss1 = F.nll_loss(out1, target[:,0], size_average=False)\n",
        "          loss2 = F.nll_loss(out2, target[:,1], size_average=False)\n",
        "          loss3 = F.nll_loss(out3, target[:,2], size_average=False)\n",
        "          loss4 = F.nll_loss(out4, target[:,3], size_average=False)\n",
        "          loss5 = F.nll_loss(out5, target[:,4], size_average=False)\n",
        "          loss6 = F.nll_loss(out6, target[:,5], size_average=False)\n",
        "          # print(\"loss1 : \", loss1)\n",
        "          # print(\"loss2 : \", loss2)\n",
        "          # print(\"loss3 : \", loss3)\n",
        "          # print(\"loss4 : \", loss4)\n",
        "          # print(\"loss5 : \", loss5)\n",
        "          # print(\"loss6 : \", loss6)\n",
        "\n",
        "          loss = loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
        "\n",
        "          pred_1 = out1.data.max(1, keepdim=True)[1]\n",
        "          pred_2 = out2.data.max(1, keepdim=True)[1]\n",
        "          pred_3 = out3.data.max(1, keepdim=True)[1]\n",
        "          pred_4 = out4.data.max(1, keepdim=True)[1]\n",
        "          pred_5 = out5.data.max(1, keepdim=True)[1]\n",
        "          pred_6 = out6.data.max(1, keepdim=True)[1]\n",
        "\n",
        "          pred_all = torch.cat([pred_1,pred_2, pred_3, pred_4, pred_5, pred_6],1)\n",
        "          # print(\"pred_all\", pred_all)\n",
        "          # print(\"target\", target)\n",
        "\n",
        "          # Calc Acc (loss < 10.0)      \n",
        "          correct += (float)(calc_correct(pred_all, target))\n",
        "          # correct += ((abs(target_pred - target)<3.0).sum(1)==8.0).sum()\n",
        "          # correct += (abs(target_pred - target).sum(1)<10.0).sum()\n",
        "          # correct = (float)(correct.item())\n",
        "          total  += len(target)\n",
        "\n",
        "          if batch_idx % 10 == 0:\n",
        "              print('Test Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} ({:.0f}/{:.0f})'.format(\n",
        "                  epoch, batch_idx * len(data), len(valid_loader.dataset),\n",
        "                  100. * batch_idx / len(valid_loader), loss.item(), correct, total))\n",
        "\n",
        "          total_loss += loss.item()\n",
        "      print(\"\")\n",
        "      print(epoch, total_loss)\n",
        "      print(\"\")\n",
        "      \n",
        "    \n",
        "      # Save checkpoint.\n",
        "      acc = 100.0*(correct)/(total)\n",
        "      print(\"acc = \", acc)\n",
        "      if acc > best_acc:\n",
        "          print('\\nSaving.. = [%d, %.3f]\\n'% (epoch, acc))\n",
        "          state = {\n",
        "              'net': model.state_dict(),\n",
        "              'acc': acc,\n",
        "              'epoch': epoch,\n",
        "          }\n",
        "          if not os.path.isdir('checkpoint'):\n",
        "              os.mkdir('checkpoint')\n",
        "          torch.save(state, './checkpoint/ckpt.t7')\n",
        "          best_acc = acc\n",
        "          best_epoch = epoch\n",
        "      \n",
        "      \n",
        "      # Save Eval Statistics\n",
        "      epoch_acc = correct/total\n",
        "      epoch_loss = total_loss/(batch_idx+1)\n",
        "      valid_acc_collect.append(epoch_acc)\n",
        "      valid_loss_collect.append(epoch_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tKFO7H2C1d-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 28282
        },
        "outputId": "b6d3dd11-498a-4a17-aa10-a5d057dc650e"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(start_epoch, start_epoch+20):\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    start_epoch = epoch"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 71 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 71 [200/10000 (2%)]\tLoss: 0.000000 (220/220)\n",
            "Train Epoch: 71 [400/10000 (4%)]\tLoss: 0.000003 (420/420)\n",
            "Train Epoch: 71 [600/10000 (6%)]\tLoss: 0.000000 (620/620)\n",
            "Train Epoch: 71 [800/10000 (8%)]\tLoss: 0.000003 (820/820)\n",
            "Train Epoch: 71 [1000/10000 (10%)]\tLoss: 0.000027 (1020/1020)\n",
            "Train Epoch: 71 [1200/10000 (12%)]\tLoss: 0.000006 (1220/1220)\n",
            "Train Epoch: 71 [1400/10000 (14%)]\tLoss: 0.000002 (1420/1420)\n",
            "Train Epoch: 71 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 71 [1800/10000 (18%)]\tLoss: 0.000008 (1820/1820)\n",
            "Train Epoch: 71 [2000/10000 (20%)]\tLoss: 0.000005 (2020/2020)\n",
            "Train Epoch: 71 [2200/10000 (22%)]\tLoss: 0.000000 (2220/2220)\n",
            "Train Epoch: 71 [2400/10000 (24%)]\tLoss: 0.000002 (2420/2420)\n",
            "Train Epoch: 71 [2600/10000 (26%)]\tLoss: 0.000002 (2620/2620)\n",
            "Train Epoch: 71 [2800/10000 (28%)]\tLoss: 0.000002 (2820/2820)\n",
            "Train Epoch: 71 [3000/10000 (30%)]\tLoss: 0.000002 (3020/3020)\n",
            "Train Epoch: 71 [3200/10000 (32%)]\tLoss: 0.000008 (3220/3220)\n",
            "Train Epoch: 71 [3400/10000 (34%)]\tLoss: 0.000005 (3420/3420)\n",
            "Train Epoch: 71 [3600/10000 (36%)]\tLoss: 0.000002 (3620/3620)\n",
            "Train Epoch: 71 [3800/10000 (38%)]\tLoss: 0.000002 (3820/3820)\n",
            "Train Epoch: 71 [4000/10000 (40%)]\tLoss: 0.000010 (4020/4020)\n",
            "Train Epoch: 71 [4200/10000 (42%)]\tLoss: 0.000005 (4220/4220)\n",
            "Train Epoch: 71 [4400/10000 (44%)]\tLoss: 0.000010 (4420/4420)\n",
            "Train Epoch: 71 [4600/10000 (46%)]\tLoss: 0.000000 (4620/4620)\n",
            "Train Epoch: 71 [4800/10000 (48%)]\tLoss: 0.000025 (4820/4820)\n",
            "Train Epoch: 71 [5000/10000 (50%)]\tLoss: 0.000000 (5020/5020)\n",
            "Train Epoch: 71 [5200/10000 (52%)]\tLoss: 0.000007 (5220/5220)\n",
            "Train Epoch: 71 [5400/10000 (54%)]\tLoss: 0.000009 (5420/5420)\n",
            "Train Epoch: 71 [5600/10000 (56%)]\tLoss: 0.000005 (5620/5620)\n",
            "Train Epoch: 71 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 71 [6000/10000 (60%)]\tLoss: 0.000005 (6020/6020)\n",
            "Train Epoch: 71 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 71 [6400/10000 (64%)]\tLoss: 0.000003 (6420/6420)\n",
            "Train Epoch: 71 [6600/10000 (66%)]\tLoss: 0.000005 (6620/6620)\n",
            "Train Epoch: 71 [6800/10000 (68%)]\tLoss: 0.000003 (6820/6820)\n",
            "Train Epoch: 71 [7000/10000 (70%)]\tLoss: 0.000000 (7020/7020)\n",
            "Train Epoch: 71 [7200/10000 (72%)]\tLoss: 0.000000 (7220/7220)\n",
            "Train Epoch: 71 [7400/10000 (74%)]\tLoss: 0.000003 (7420/7420)\n",
            "Train Epoch: 71 [7600/10000 (76%)]\tLoss: 0.000002 (7620/7620)\n",
            "Train Epoch: 71 [7800/10000 (78%)]\tLoss: 0.000005 (7820/7820)\n",
            "Train Epoch: 71 [8000/10000 (80%)]\tLoss: 0.000005 (8020/8020)\n",
            "Train Epoch: 71 [8200/10000 (82%)]\tLoss: 0.000000 (8220/8220)\n",
            "Train Epoch: 71 [8400/10000 (84%)]\tLoss: 0.000004 (8420/8420)\n",
            "Train Epoch: 71 [8600/10000 (86%)]\tLoss: 0.000000 (8620/8620)\n",
            "Train Epoch: 71 [8800/10000 (88%)]\tLoss: 0.000002 (8820/8820)\n",
            "Train Epoch: 71 [9000/10000 (90%)]\tLoss: 0.000002 (9020/9020)\n",
            "Train Epoch: 71 [9200/10000 (92%)]\tLoss: 0.000001 (9220/9220)\n",
            "Train Epoch: 71 [9400/10000 (94%)]\tLoss: 0.000009 (9420/9420)\n",
            "Train Epoch: 71 [9600/10000 (96%)]\tLoss: 0.000012 (9620/9620)\n",
            "Train Epoch: 71 [9800/10000 (98%)]\tLoss: 0.000004 (9820/9820)\n",
            "\n",
            "71 0.0025873184204101562\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 71 [0/4356 (0%)]\tLoss: 2.165022 (19/20)\n",
            "Test Epoch: 71 [200/4356 (5%)]\tLoss: 39.612640 (197/220)\n",
            "Test Epoch: 71 [400/4356 (9%)]\tLoss: 1.845990 (378/420)\n",
            "Test Epoch: 71 [600/4356 (14%)]\tLoss: 24.529011 (560/620)\n",
            "Test Epoch: 71 [800/4356 (18%)]\tLoss: 9.300869 (746/820)\n",
            "Test Epoch: 71 [1000/4356 (23%)]\tLoss: 0.518667 (936/1020)\n",
            "Test Epoch: 71 [1200/4356 (28%)]\tLoss: 0.000486 (1122/1220)\n",
            "Test Epoch: 71 [1400/4356 (32%)]\tLoss: 23.141113 (1300/1420)\n",
            "Test Epoch: 71 [1600/4356 (37%)]\tLoss: 38.731926 (1476/1620)\n",
            "Test Epoch: 71 [1800/4356 (41%)]\tLoss: 22.093277 (1664/1820)\n",
            "Test Epoch: 71 [2000/4356 (46%)]\tLoss: 0.295578 (1851/2020)\n",
            "Test Epoch: 71 [2200/4356 (50%)]\tLoss: 4.978736 (2041/2220)\n",
            "Test Epoch: 71 [2400/4356 (55%)]\tLoss: 72.794800 (2227/2420)\n",
            "Test Epoch: 71 [2600/4356 (60%)]\tLoss: 29.989304 (2413/2620)\n",
            "Test Epoch: 71 [2800/4356 (64%)]\tLoss: 15.576377 (2602/2820)\n",
            "Test Epoch: 71 [3000/4356 (69%)]\tLoss: 22.026451 (2782/3020)\n",
            "Test Epoch: 71 [3200/4356 (73%)]\tLoss: 12.704683 (2961/3220)\n",
            "Test Epoch: 71 [3400/4356 (78%)]\tLoss: 47.753056 (3146/3420)\n",
            "Test Epoch: 71 [3600/4356 (83%)]\tLoss: 9.253573 (3325/3620)\n",
            "Test Epoch: 71 [3800/4356 (87%)]\tLoss: 4.355389 (3510/3820)\n",
            "Test Epoch: 71 [4000/4356 (92%)]\tLoss: 0.331566 (3693/4020)\n",
            "Test Epoch: 71 [4200/4356 (96%)]\tLoss: 0.095120 (3877/4220)\n",
            "\n",
            "71 5164.293880701065\n",
            "\n",
            "acc =  91.8732782369146\n",
            "Train Epoch: 72 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 72 [200/10000 (2%)]\tLoss: 0.000000 (220/220)\n",
            "Train Epoch: 72 [400/10000 (4%)]\tLoss: 0.000006 (420/420)\n",
            "Train Epoch: 72 [600/10000 (6%)]\tLoss: 0.000000 (620/620)\n",
            "Train Epoch: 72 [800/10000 (8%)]\tLoss: 0.000003 (820/820)\n",
            "Train Epoch: 72 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 72 [1200/10000 (12%)]\tLoss: 0.000002 (1220/1220)\n",
            "Train Epoch: 72 [1400/10000 (14%)]\tLoss: 0.000008 (1420/1420)\n",
            "Train Epoch: 72 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 72 [1800/10000 (18%)]\tLoss: 0.000000 (1820/1820)\n",
            "Train Epoch: 72 [2000/10000 (20%)]\tLoss: 0.000000 (2020/2020)\n",
            "Train Epoch: 72 [2200/10000 (22%)]\tLoss: 0.000000 (2220/2220)\n",
            "Train Epoch: 72 [2400/10000 (24%)]\tLoss: 0.000006 (2420/2420)\n",
            "Train Epoch: 72 [2600/10000 (26%)]\tLoss: 0.000001 (2620/2620)\n",
            "Train Epoch: 72 [2800/10000 (28%)]\tLoss: 0.000000 (2820/2820)\n",
            "Train Epoch: 72 [3000/10000 (30%)]\tLoss: 0.000001 (3020/3020)\n",
            "Train Epoch: 72 [3200/10000 (32%)]\tLoss: 0.000055 (3220/3220)\n",
            "Train Epoch: 72 [3400/10000 (34%)]\tLoss: 0.000005 (3420/3420)\n",
            "Train Epoch: 72 [3600/10000 (36%)]\tLoss: 0.000008 (3620/3620)\n",
            "Train Epoch: 72 [3800/10000 (38%)]\tLoss: 0.000004 (3820/3820)\n",
            "Train Epoch: 72 [4000/10000 (40%)]\tLoss: 0.000002 (4020/4020)\n",
            "Train Epoch: 72 [4200/10000 (42%)]\tLoss: 0.000019 (4220/4220)\n",
            "Train Epoch: 72 [4400/10000 (44%)]\tLoss: 0.000004 (4420/4420)\n",
            "Train Epoch: 72 [4600/10000 (46%)]\tLoss: 0.000000 (4620/4620)\n",
            "Train Epoch: 72 [4800/10000 (48%)]\tLoss: 0.000000 (4820/4820)\n",
            "Train Epoch: 72 [5000/10000 (50%)]\tLoss: 0.000000 (5020/5020)\n",
            "Train Epoch: 72 [5200/10000 (52%)]\tLoss: 0.000000 (5220/5220)\n",
            "Train Epoch: 72 [5400/10000 (54%)]\tLoss: 0.000001 (5420/5420)\n",
            "Train Epoch: 72 [5600/10000 (56%)]\tLoss: 0.000002 (5620/5620)\n",
            "Train Epoch: 72 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 72 [6000/10000 (60%)]\tLoss: 0.000004 (6020/6020)\n",
            "Train Epoch: 72 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 72 [6400/10000 (64%)]\tLoss: 0.000003 (6420/6420)\n",
            "Train Epoch: 72 [6600/10000 (66%)]\tLoss: 0.000001 (6620/6620)\n",
            "Train Epoch: 72 [6800/10000 (68%)]\tLoss: 0.000000 (6820/6820)\n",
            "Train Epoch: 72 [7000/10000 (70%)]\tLoss: 0.000005 (7020/7020)\n",
            "Train Epoch: 72 [7200/10000 (72%)]\tLoss: 0.000004 (7220/7220)\n",
            "Train Epoch: 72 [7400/10000 (74%)]\tLoss: 0.000001 (7420/7420)\n",
            "Train Epoch: 72 [7600/10000 (76%)]\tLoss: 0.000003 (7620/7620)\n",
            "Train Epoch: 72 [7800/10000 (78%)]\tLoss: 0.000001 (7820/7820)\n",
            "Train Epoch: 72 [8000/10000 (80%)]\tLoss: 0.000439 (8020/8020)\n",
            "Train Epoch: 72 [8200/10000 (82%)]\tLoss: 0.000008 (8220/8220)\n",
            "Train Epoch: 72 [8400/10000 (84%)]\tLoss: 0.000001 (8420/8420)\n",
            "Train Epoch: 72 [8600/10000 (86%)]\tLoss: 0.000000 (8620/8620)\n",
            "Train Epoch: 72 [8800/10000 (88%)]\tLoss: 0.000000 (8820/8820)\n",
            "Train Epoch: 72 [9000/10000 (90%)]\tLoss: 0.000000 (9020/9020)\n",
            "Train Epoch: 72 [9200/10000 (92%)]\tLoss: 0.000004 (9220/9220)\n",
            "Train Epoch: 72 [9400/10000 (94%)]\tLoss: 0.000000 (9420/9420)\n",
            "Train Epoch: 72 [9600/10000 (96%)]\tLoss: 0.000000 (9620/9620)\n",
            "Train Epoch: 72 [9800/10000 (98%)]\tLoss: 0.000009 (9820/9820)\n",
            "\n",
            "72 0.0033713579177856445\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 72 [0/4356 (0%)]\tLoss: 4.912570 (19/20)\n",
            "Test Epoch: 72 [200/4356 (5%)]\tLoss: 40.806591 (197/220)\n",
            "Test Epoch: 72 [400/4356 (9%)]\tLoss: 2.051904 (377/420)\n",
            "Test Epoch: 72 [600/4356 (14%)]\tLoss: 22.274929 (557/620)\n",
            "Test Epoch: 72 [800/4356 (18%)]\tLoss: 8.990794 (742/820)\n",
            "Test Epoch: 72 [1000/4356 (23%)]\tLoss: 0.098904 (930/1020)\n",
            "Test Epoch: 72 [1200/4356 (28%)]\tLoss: 0.000073 (1114/1220)\n",
            "Test Epoch: 72 [1400/4356 (32%)]\tLoss: 20.743221 (1292/1420)\n",
            "Test Epoch: 72 [1600/4356 (37%)]\tLoss: 40.876896 (1471/1620)\n",
            "Test Epoch: 72 [1800/4356 (41%)]\tLoss: 24.884205 (1658/1820)\n",
            "Test Epoch: 72 [2000/4356 (46%)]\tLoss: 0.345812 (1845/2020)\n",
            "Test Epoch: 72 [2200/4356 (50%)]\tLoss: 6.407931 (2035/2220)\n",
            "Test Epoch: 72 [2400/4356 (55%)]\tLoss: 72.615860 (2220/2420)\n",
            "Test Epoch: 72 [2600/4356 (60%)]\tLoss: 28.618290 (2405/2620)\n",
            "Test Epoch: 72 [2800/4356 (64%)]\tLoss: 13.831639 (2592/2820)\n",
            "Test Epoch: 72 [3000/4356 (69%)]\tLoss: 25.448870 (2772/3020)\n",
            "Test Epoch: 72 [3200/4356 (73%)]\tLoss: 12.009210 (2953/3220)\n",
            "Test Epoch: 72 [3400/4356 (78%)]\tLoss: 41.392166 (3138/3420)\n",
            "Test Epoch: 72 [3600/4356 (83%)]\tLoss: 8.725370 (3317/3620)\n",
            "Test Epoch: 72 [3800/4356 (87%)]\tLoss: 5.848172 (3503/3820)\n",
            "Test Epoch: 72 [4000/4356 (92%)]\tLoss: 1.139509 (3685/4020)\n",
            "Test Epoch: 72 [4200/4356 (96%)]\tLoss: 0.055769 (3869/4220)\n",
            "\n",
            "72 5206.560094833374\n",
            "\n",
            "acc =  91.71258034894399\n",
            "Train Epoch: 73 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 73 [200/10000 (2%)]\tLoss: 0.000010 (220/220)\n",
            "Train Epoch: 73 [400/10000 (4%)]\tLoss: 0.000104 (420/420)\n",
            "Train Epoch: 73 [600/10000 (6%)]\tLoss: 0.000010 (620/620)\n",
            "Train Epoch: 73 [800/10000 (8%)]\tLoss: 0.000000 (820/820)\n",
            "Train Epoch: 73 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 73 [1200/10000 (12%)]\tLoss: 0.000042 (1220/1220)\n",
            "Train Epoch: 73 [1400/10000 (14%)]\tLoss: 0.000000 (1420/1420)\n",
            "Train Epoch: 73 [1600/10000 (16%)]\tLoss: 0.000004 (1620/1620)\n",
            "Train Epoch: 73 [1800/10000 (18%)]\tLoss: 0.000006 (1820/1820)\n",
            "Train Epoch: 73 [2000/10000 (20%)]\tLoss: 0.000002 (2020/2020)\n",
            "Train Epoch: 73 [2200/10000 (22%)]\tLoss: 0.000000 (2220/2220)\n",
            "Train Epoch: 73 [2400/10000 (24%)]\tLoss: 0.000001 (2420/2420)\n",
            "Train Epoch: 73 [2600/10000 (26%)]\tLoss: 0.000005 (2620/2620)\n",
            "Train Epoch: 73 [2800/10000 (28%)]\tLoss: 0.000012 (2820/2820)\n",
            "Train Epoch: 73 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 73 [3200/10000 (32%)]\tLoss: 0.000000 (3220/3220)\n",
            "Train Epoch: 73 [3400/10000 (34%)]\tLoss: 0.000004 (3420/3420)\n",
            "Train Epoch: 73 [3600/10000 (36%)]\tLoss: 0.000000 (3620/3620)\n",
            "Train Epoch: 73 [3800/10000 (38%)]\tLoss: 0.000000 (3820/3820)\n",
            "Train Epoch: 73 [4000/10000 (40%)]\tLoss: 0.000004 (4020/4020)\n",
            "Train Epoch: 73 [4200/10000 (42%)]\tLoss: 0.000002 (4220/4220)\n",
            "Train Epoch: 73 [4400/10000 (44%)]\tLoss: 0.000004 (4420/4420)\n",
            "Train Epoch: 73 [4600/10000 (46%)]\tLoss: 0.000000 (4620/4620)\n",
            "Train Epoch: 73 [4800/10000 (48%)]\tLoss: 0.000000 (4820/4820)\n",
            "Train Epoch: 73 [5000/10000 (50%)]\tLoss: 0.000002 (5020/5020)\n",
            "Train Epoch: 73 [5200/10000 (52%)]\tLoss: 0.000000 (5220/5220)\n",
            "Train Epoch: 73 [5400/10000 (54%)]\tLoss: 0.000000 (5420/5420)\n",
            "Train Epoch: 73 [5600/10000 (56%)]\tLoss: 0.000002 (5620/5620)\n",
            "Train Epoch: 73 [5800/10000 (58%)]\tLoss: 0.000001 (5820/5820)\n",
            "Train Epoch: 73 [6000/10000 (60%)]\tLoss: 0.000001 (6020/6020)\n",
            "Train Epoch: 73 [6200/10000 (62%)]\tLoss: 0.000008 (6220/6220)\n",
            "Train Epoch: 73 [6400/10000 (64%)]\tLoss: 0.000004 (6420/6420)\n",
            "Train Epoch: 73 [6600/10000 (66%)]\tLoss: 0.000000 (6620/6620)\n",
            "Train Epoch: 73 [6800/10000 (68%)]\tLoss: 0.000005 (6820/6820)\n",
            "Train Epoch: 73 [7000/10000 (70%)]\tLoss: 0.000002 (7020/7020)\n",
            "Train Epoch: 73 [7200/10000 (72%)]\tLoss: 0.000000 (7220/7220)\n",
            "Train Epoch: 73 [7400/10000 (74%)]\tLoss: 0.000180 (7420/7420)\n",
            "Train Epoch: 73 [7600/10000 (76%)]\tLoss: 0.000008 (7620/7620)\n",
            "Train Epoch: 73 [7800/10000 (78%)]\tLoss: 0.000002 (7820/7820)\n",
            "Train Epoch: 73 [8000/10000 (80%)]\tLoss: 0.000013 (8020/8020)\n",
            "Train Epoch: 73 [8200/10000 (82%)]\tLoss: 0.000004 (8220/8220)\n",
            "Train Epoch: 73 [8400/10000 (84%)]\tLoss: 0.000002 (8420/8420)\n",
            "Train Epoch: 73 [8600/10000 (86%)]\tLoss: 0.000001 (8620/8620)\n",
            "Train Epoch: 73 [8800/10000 (88%)]\tLoss: 0.000010 (8820/8820)\n",
            "Train Epoch: 73 [9000/10000 (90%)]\tLoss: 0.000010 (9020/9020)\n",
            "Train Epoch: 73 [9200/10000 (92%)]\tLoss: 0.000006 (9220/9220)\n",
            "Train Epoch: 73 [9400/10000 (94%)]\tLoss: 0.000003 (9420/9420)\n",
            "Train Epoch: 73 [9600/10000 (96%)]\tLoss: 0.000015 (9620/9620)\n",
            "Train Epoch: 73 [9800/10000 (98%)]\tLoss: 0.000002 (9820/9820)\n",
            "\n",
            "73 0.004645705223083496\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 73 [0/4356 (0%)]\tLoss: 1.097462 (19/20)\n",
            "Test Epoch: 73 [200/4356 (5%)]\tLoss: 41.668427 (195/220)\n",
            "Test Epoch: 73 [400/4356 (9%)]\tLoss: 3.485071 (375/420)\n",
            "Test Epoch: 73 [600/4356 (14%)]\tLoss: 24.485235 (557/620)\n",
            "Test Epoch: 73 [800/4356 (18%)]\tLoss: 6.312489 (743/820)\n",
            "Test Epoch: 73 [1000/4356 (23%)]\tLoss: 0.092467 (930/1020)\n",
            "Test Epoch: 73 [1200/4356 (28%)]\tLoss: 0.000051 (1116/1220)\n",
            "Test Epoch: 73 [1400/4356 (32%)]\tLoss: 24.497879 (1293/1420)\n",
            "Test Epoch: 73 [1600/4356 (37%)]\tLoss: 33.531963 (1471/1620)\n",
            "Test Epoch: 73 [1800/4356 (41%)]\tLoss: 22.599709 (1660/1820)\n",
            "Test Epoch: 73 [2000/4356 (46%)]\tLoss: 0.824928 (1846/2020)\n",
            "Test Epoch: 73 [2200/4356 (50%)]\tLoss: 5.339291 (2036/2220)\n",
            "Test Epoch: 73 [2400/4356 (55%)]\tLoss: 77.471237 (2223/2420)\n",
            "Test Epoch: 73 [2600/4356 (60%)]\tLoss: 30.680851 (2408/2620)\n",
            "Test Epoch: 73 [2800/4356 (64%)]\tLoss: 18.738750 (2594/2820)\n",
            "Test Epoch: 73 [3000/4356 (69%)]\tLoss: 28.250017 (2772/3020)\n",
            "Test Epoch: 73 [3200/4356 (73%)]\tLoss: 9.890154 (2954/3220)\n",
            "Test Epoch: 73 [3400/4356 (78%)]\tLoss: 53.158348 (3140/3420)\n",
            "Test Epoch: 73 [3600/4356 (83%)]\tLoss: 10.380341 (3319/3620)\n",
            "Test Epoch: 73 [3800/4356 (87%)]\tLoss: 5.228303 (3505/3820)\n",
            "Test Epoch: 73 [4000/4356 (92%)]\tLoss: 0.051125 (3688/4020)\n",
            "Test Epoch: 73 [4200/4356 (96%)]\tLoss: 0.091007 (3872/4220)\n",
            "\n",
            "73 5370.622452259064\n",
            "\n",
            "acc =  91.80440771349862\n",
            "Train Epoch: 74 [0/10000 (0%)]\tLoss: 0.000010 (20/20)\n",
            "Train Epoch: 74 [200/10000 (2%)]\tLoss: 0.000012 (220/220)\n",
            "Train Epoch: 74 [400/10000 (4%)]\tLoss: 0.000000 (420/420)\n",
            "Train Epoch: 74 [600/10000 (6%)]\tLoss: 0.000001 (620/620)\n",
            "Train Epoch: 74 [800/10000 (8%)]\tLoss: 0.000003 (820/820)\n",
            "Train Epoch: 74 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 74 [1200/10000 (12%)]\tLoss: 0.000004 (1220/1220)\n",
            "Train Epoch: 74 [1400/10000 (14%)]\tLoss: 0.000003 (1420/1420)\n",
            "Train Epoch: 74 [1600/10000 (16%)]\tLoss: 0.000002 (1620/1620)\n",
            "Train Epoch: 74 [1800/10000 (18%)]\tLoss: 0.000000 (1820/1820)\n",
            "Train Epoch: 74 [2000/10000 (20%)]\tLoss: 0.000011 (2020/2020)\n",
            "Train Epoch: 74 [2200/10000 (22%)]\tLoss: 0.000020 (2220/2220)\n",
            "Train Epoch: 74 [2400/10000 (24%)]\tLoss: 0.000000 (2420/2420)\n",
            "Train Epoch: 74 [2600/10000 (26%)]\tLoss: 0.000002 (2620/2620)\n",
            "Train Epoch: 74 [2800/10000 (28%)]\tLoss: 0.000008 (2820/2820)\n",
            "Train Epoch: 74 [3000/10000 (30%)]\tLoss: 0.000015 (3020/3020)\n",
            "Train Epoch: 74 [3200/10000 (32%)]\tLoss: 0.000002 (3220/3220)\n",
            "Train Epoch: 74 [3400/10000 (34%)]\tLoss: 0.000003 (3420/3420)\n",
            "Train Epoch: 74 [3600/10000 (36%)]\tLoss: 0.000001 (3620/3620)\n",
            "Train Epoch: 74 [3800/10000 (38%)]\tLoss: 0.000002 (3820/3820)\n",
            "Train Epoch: 74 [4000/10000 (40%)]\tLoss: 0.000002 (4020/4020)\n",
            "Train Epoch: 74 [4200/10000 (42%)]\tLoss: 0.000000 (4220/4220)\n",
            "Train Epoch: 74 [4400/10000 (44%)]\tLoss: 0.000000 (4420/4420)\n",
            "Train Epoch: 74 [4600/10000 (46%)]\tLoss: 0.000002 (4620/4620)\n",
            "Train Epoch: 74 [4800/10000 (48%)]\tLoss: 0.000010 (4820/4820)\n",
            "Train Epoch: 74 [5000/10000 (50%)]\tLoss: 0.000001 (5020/5020)\n",
            "Train Epoch: 74 [5200/10000 (52%)]\tLoss: 0.000002 (5220/5220)\n",
            "Train Epoch: 74 [5400/10000 (54%)]\tLoss: 0.000021 (5420/5420)\n",
            "Train Epoch: 74 [5600/10000 (56%)]\tLoss: 0.000000 (5620/5620)\n",
            "Train Epoch: 74 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 74 [6000/10000 (60%)]\tLoss: 0.000002 (6020/6020)\n",
            "Train Epoch: 74 [6200/10000 (62%)]\tLoss: 0.000002 (6220/6220)\n",
            "Train Epoch: 74 [6400/10000 (64%)]\tLoss: 0.000000 (6420/6420)\n",
            "Train Epoch: 74 [6600/10000 (66%)]\tLoss: 0.000000 (6620/6620)\n",
            "Train Epoch: 74 [6800/10000 (68%)]\tLoss: 0.000000 (6820/6820)\n",
            "Train Epoch: 74 [7000/10000 (70%)]\tLoss: 0.000000 (7020/7020)\n",
            "Train Epoch: 74 [7200/10000 (72%)]\tLoss: 0.000032 (7220/7220)\n",
            "Train Epoch: 74 [7400/10000 (74%)]\tLoss: 0.000013 (7420/7420)\n",
            "Train Epoch: 74 [7600/10000 (76%)]\tLoss: 0.000001 (7620/7620)\n",
            "Train Epoch: 74 [7800/10000 (78%)]\tLoss: 0.000000 (7820/7820)\n",
            "Train Epoch: 74 [8000/10000 (80%)]\tLoss: 0.000001 (8020/8020)\n",
            "Train Epoch: 74 [8200/10000 (82%)]\tLoss: 0.000058 (8220/8220)\n",
            "Train Epoch: 74 [8400/10000 (84%)]\tLoss: 0.000003 (8420/8420)\n",
            "Train Epoch: 74 [8600/10000 (86%)]\tLoss: 0.000002 (8620/8620)\n",
            "Train Epoch: 74 [8800/10000 (88%)]\tLoss: 0.000008 (8820/8820)\n",
            "Train Epoch: 74 [9000/10000 (90%)]\tLoss: 0.000000 (9020/9020)\n",
            "Train Epoch: 74 [9200/10000 (92%)]\tLoss: 0.000034 (9220/9220)\n",
            "Train Epoch: 74 [9400/10000 (94%)]\tLoss: 0.000007 (9420/9420)\n",
            "Train Epoch: 74 [9600/10000 (96%)]\tLoss: 0.000000 (9620/9620)\n",
            "Train Epoch: 74 [9800/10000 (98%)]\tLoss: 0.000032 (9820/9820)\n",
            "\n",
            "74 0.0029217004776000977\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 74 [0/4356 (0%)]\tLoss: 0.966761 (19/20)\n",
            "Test Epoch: 74 [200/4356 (5%)]\tLoss: 41.048706 (195/220)\n",
            "Test Epoch: 74 [400/4356 (9%)]\tLoss: 3.185922 (373/420)\n",
            "Test Epoch: 74 [600/4356 (14%)]\tLoss: 25.058659 (554/620)\n",
            "Test Epoch: 74 [800/4356 (18%)]\tLoss: 8.574335 (741/820)\n",
            "Test Epoch: 74 [1000/4356 (23%)]\tLoss: 0.481968 (931/1020)\n",
            "Test Epoch: 74 [1200/4356 (28%)]\tLoss: 0.000237 (1117/1220)\n",
            "Test Epoch: 74 [1400/4356 (32%)]\tLoss: 24.383022 (1294/1420)\n",
            "Test Epoch: 74 [1600/4356 (37%)]\tLoss: 38.242157 (1472/1620)\n",
            "Test Epoch: 74 [1800/4356 (41%)]\tLoss: 21.970240 (1659/1820)\n",
            "Test Epoch: 74 [2000/4356 (46%)]\tLoss: 0.424415 (1845/2020)\n",
            "Test Epoch: 74 [2200/4356 (50%)]\tLoss: 4.264304 (2035/2220)\n",
            "Test Epoch: 74 [2400/4356 (55%)]\tLoss: 75.553993 (2220/2420)\n",
            "Test Epoch: 74 [2600/4356 (60%)]\tLoss: 26.318932 (2405/2620)\n",
            "Test Epoch: 74 [2800/4356 (64%)]\tLoss: 15.881921 (2594/2820)\n",
            "Test Epoch: 74 [3000/4356 (69%)]\tLoss: 27.683796 (2774/3020)\n",
            "Test Epoch: 74 [3200/4356 (73%)]\tLoss: 10.643190 (2954/3220)\n",
            "Test Epoch: 74 [3400/4356 (78%)]\tLoss: 55.841537 (3140/3420)\n",
            "Test Epoch: 74 [3600/4356 (83%)]\tLoss: 10.264888 (3319/3620)\n",
            "Test Epoch: 74 [3800/4356 (87%)]\tLoss: 4.198411 (3506/3820)\n",
            "Test Epoch: 74 [4000/4356 (92%)]\tLoss: 0.053383 (3689/4020)\n",
            "Test Epoch: 74 [4200/4356 (96%)]\tLoss: 0.098512 (3874/4220)\n",
            "\n",
            "74 5353.647878050804\n",
            "\n",
            "acc =  91.82736455463728\n",
            "Train Epoch: 75 [0/10000 (0%)]\tLoss: 0.000009 (20/20)\n",
            "Train Epoch: 75 [200/10000 (2%)]\tLoss: 0.000000 (220/220)\n",
            "Train Epoch: 75 [400/10000 (4%)]\tLoss: 0.000000 (420/420)\n",
            "Train Epoch: 75 [600/10000 (6%)]\tLoss: 0.000000 (620/620)\n",
            "Train Epoch: 75 [800/10000 (8%)]\tLoss: 0.000000 (820/820)\n",
            "Train Epoch: 75 [1000/10000 (10%)]\tLoss: 0.000003 (1020/1020)\n",
            "Train Epoch: 75 [1200/10000 (12%)]\tLoss: 0.000001 (1220/1220)\n",
            "Train Epoch: 75 [1400/10000 (14%)]\tLoss: 0.000000 (1420/1420)\n",
            "Train Epoch: 75 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 75 [1800/10000 (18%)]\tLoss: 0.000019 (1820/1820)\n",
            "Train Epoch: 75 [2000/10000 (20%)]\tLoss: 0.000000 (2020/2020)\n",
            "Train Epoch: 75 [2200/10000 (22%)]\tLoss: 0.000020 (2220/2220)\n",
            "Train Epoch: 75 [2400/10000 (24%)]\tLoss: 0.000000 (2420/2420)\n",
            "Train Epoch: 75 [2600/10000 (26%)]\tLoss: 0.000008 (2620/2620)\n",
            "Train Epoch: 75 [2800/10000 (28%)]\tLoss: 0.000001 (2820/2820)\n",
            "Train Epoch: 75 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 75 [3200/10000 (32%)]\tLoss: 0.000004 (3220/3220)\n",
            "Train Epoch: 75 [3400/10000 (34%)]\tLoss: 0.000000 (3420/3420)\n",
            "Train Epoch: 75 [3600/10000 (36%)]\tLoss: 0.000002 (3620/3620)\n",
            "Train Epoch: 75 [3800/10000 (38%)]\tLoss: 0.000000 (3820/3820)\n",
            "Train Epoch: 75 [4000/10000 (40%)]\tLoss: 0.000002 (4020/4020)\n",
            "Train Epoch: 75 [4200/10000 (42%)]\tLoss: 0.000009 (4220/4220)\n",
            "Train Epoch: 75 [4400/10000 (44%)]\tLoss: 0.000006 (4420/4420)\n",
            "Train Epoch: 75 [4600/10000 (46%)]\tLoss: 0.000001 (4620/4620)\n",
            "Train Epoch: 75 [4800/10000 (48%)]\tLoss: 0.000001 (4820/4820)\n",
            "Train Epoch: 75 [5000/10000 (50%)]\tLoss: 0.000008 (5020/5020)\n",
            "Train Epoch: 75 [5200/10000 (52%)]\tLoss: 0.000002 (5220/5220)\n",
            "Train Epoch: 75 [5400/10000 (54%)]\tLoss: 0.000002 (5420/5420)\n",
            "Train Epoch: 75 [5600/10000 (56%)]\tLoss: 0.000000 (5620/5620)\n",
            "Train Epoch: 75 [5800/10000 (58%)]\tLoss: 0.000001 (5820/5820)\n",
            "Train Epoch: 75 [6000/10000 (60%)]\tLoss: 0.000000 (6020/6020)\n",
            "Train Epoch: 75 [6200/10000 (62%)]\tLoss: 0.000002 (6220/6220)\n",
            "Train Epoch: 75 [6400/10000 (64%)]\tLoss: 0.000000 (6420/6420)\n",
            "Train Epoch: 75 [6600/10000 (66%)]\tLoss: 0.000002 (6620/6620)\n",
            "Train Epoch: 75 [6800/10000 (68%)]\tLoss: 0.000000 (6820/6820)\n",
            "Train Epoch: 75 [7000/10000 (70%)]\tLoss: 0.000019 (7020/7020)\n",
            "Train Epoch: 75 [7200/10000 (72%)]\tLoss: 0.000001 (7220/7220)\n",
            "Train Epoch: 75 [7400/10000 (74%)]\tLoss: 0.000003 (7420/7420)\n",
            "Train Epoch: 75 [7600/10000 (76%)]\tLoss: 0.000008 (7620/7620)\n",
            "Train Epoch: 75 [7800/10000 (78%)]\tLoss: 0.000000 (7820/7820)\n",
            "Train Epoch: 75 [8000/10000 (80%)]\tLoss: 0.000000 (8020/8020)\n",
            "Train Epoch: 75 [8200/10000 (82%)]\tLoss: 0.000044 (8220/8220)\n",
            "Train Epoch: 75 [8400/10000 (84%)]\tLoss: 0.000006 (8420/8420)\n",
            "Train Epoch: 75 [8600/10000 (86%)]\tLoss: 0.000002 (8620/8620)\n",
            "Train Epoch: 75 [8800/10000 (88%)]\tLoss: 0.000001 (8820/8820)\n",
            "Train Epoch: 75 [9000/10000 (90%)]\tLoss: 0.000000 (9020/9020)\n",
            "Train Epoch: 75 [9200/10000 (92%)]\tLoss: 0.000000 (9220/9220)\n",
            "Train Epoch: 75 [9400/10000 (94%)]\tLoss: 0.000000 (9420/9420)\n",
            "Train Epoch: 75 [9600/10000 (96%)]\tLoss: 0.000004 (9620/9620)\n",
            "Train Epoch: 75 [9800/10000 (98%)]\tLoss: 0.000008 (9820/9820)\n",
            "\n",
            "75 0.002046346664428711\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 75 [0/4356 (0%)]\tLoss: 1.869129 (19/20)\n",
            "Test Epoch: 75 [200/4356 (5%)]\tLoss: 41.244144 (195/220)\n",
            "Test Epoch: 75 [400/4356 (9%)]\tLoss: 4.626966 (375/420)\n",
            "Test Epoch: 75 [600/4356 (14%)]\tLoss: 24.360191 (557/620)\n",
            "Test Epoch: 75 [800/4356 (18%)]\tLoss: 8.421993 (743/820)\n",
            "Test Epoch: 75 [1000/4356 (23%)]\tLoss: 0.431151 (933/1020)\n",
            "Test Epoch: 75 [1200/4356 (28%)]\tLoss: 0.000127 (1117/1220)\n",
            "Test Epoch: 75 [1400/4356 (32%)]\tLoss: 24.271385 (1293/1420)\n",
            "Test Epoch: 75 [1600/4356 (37%)]\tLoss: 37.003468 (1470/1620)\n",
            "Test Epoch: 75 [1800/4356 (41%)]\tLoss: 23.390308 (1658/1820)\n",
            "Test Epoch: 75 [2000/4356 (46%)]\tLoss: 0.426531 (1844/2020)\n",
            "Test Epoch: 75 [2200/4356 (50%)]\tLoss: 5.245723 (2034/2220)\n",
            "Test Epoch: 75 [2400/4356 (55%)]\tLoss: 78.491936 (2221/2420)\n",
            "Test Epoch: 75 [2600/4356 (60%)]\tLoss: 28.847397 (2404/2620)\n",
            "Test Epoch: 75 [2800/4356 (64%)]\tLoss: 18.317337 (2591/2820)\n",
            "Test Epoch: 75 [3000/4356 (69%)]\tLoss: 27.312372 (2771/3020)\n",
            "Test Epoch: 75 [3200/4356 (73%)]\tLoss: 10.401314 (2951/3220)\n",
            "Test Epoch: 75 [3400/4356 (78%)]\tLoss: 54.314632 (3138/3420)\n",
            "Test Epoch: 75 [3600/4356 (83%)]\tLoss: 12.350674 (3318/3620)\n",
            "Test Epoch: 75 [3800/4356 (87%)]\tLoss: 5.410475 (3504/3820)\n",
            "Test Epoch: 75 [4000/4356 (92%)]\tLoss: 0.167037 (3687/4020)\n",
            "Test Epoch: 75 [4200/4356 (96%)]\tLoss: 0.243302 (3871/4220)\n",
            "\n",
            "75 5363.993008852005\n",
            "\n",
            "acc =  91.7584940312213\n",
            "Train Epoch: 76 [0/10000 (0%)]\tLoss: 0.000002 (20/20)\n",
            "Train Epoch: 76 [200/10000 (2%)]\tLoss: 0.000014 (220/220)\n",
            "Train Epoch: 76 [400/10000 (4%)]\tLoss: 0.000006 (420/420)\n",
            "Train Epoch: 76 [600/10000 (6%)]\tLoss: 0.000013 (620/620)\n",
            "Train Epoch: 76 [800/10000 (8%)]\tLoss: 0.000008 (820/820)\n",
            "Train Epoch: 76 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 76 [1200/10000 (12%)]\tLoss: 0.000002 (1220/1220)\n",
            "Train Epoch: 76 [1400/10000 (14%)]\tLoss: 0.000002 (1420/1420)\n",
            "Train Epoch: 76 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 76 [1800/10000 (18%)]\tLoss: 0.000004 (1820/1820)\n",
            "Train Epoch: 76 [2000/10000 (20%)]\tLoss: 0.000000 (2020/2020)\n",
            "Train Epoch: 76 [2200/10000 (22%)]\tLoss: 0.000004 (2220/2220)\n",
            "Train Epoch: 76 [2400/10000 (24%)]\tLoss: 0.000006 (2420/2420)\n",
            "Train Epoch: 76 [2600/10000 (26%)]\tLoss: 0.000008 (2620/2620)\n",
            "Train Epoch: 76 [2800/10000 (28%)]\tLoss: 0.000000 (2820/2820)\n",
            "Train Epoch: 76 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 76 [3200/10000 (32%)]\tLoss: 0.000000 (3220/3220)\n",
            "Train Epoch: 76 [3400/10000 (34%)]\tLoss: 0.000005 (3420/3420)\n",
            "Train Epoch: 76 [3600/10000 (36%)]\tLoss: 0.000006 (3620/3620)\n",
            "Train Epoch: 76 [3800/10000 (38%)]\tLoss: 0.000004 (3820/3820)\n",
            "Train Epoch: 76 [4000/10000 (40%)]\tLoss: 0.000000 (4020/4020)\n",
            "Train Epoch: 76 [4200/10000 (42%)]\tLoss: 0.000005 (4220/4220)\n",
            "Train Epoch: 76 [4400/10000 (44%)]\tLoss: 0.000014 (4420/4420)\n",
            "Train Epoch: 76 [4600/10000 (46%)]\tLoss: 0.000001 (4620/4620)\n",
            "Train Epoch: 76 [4800/10000 (48%)]\tLoss: 0.000000 (4820/4820)\n",
            "Train Epoch: 76 [5000/10000 (50%)]\tLoss: 0.000019 (5020/5020)\n",
            "Train Epoch: 76 [5200/10000 (52%)]\tLoss: 0.012012 (5220/5220)\n",
            "Train Epoch: 76 [5400/10000 (54%)]\tLoss: 0.000007 (5420/5420)\n",
            "Train Epoch: 76 [5600/10000 (56%)]\tLoss: 0.000236 (5620/5620)\n",
            "Train Epoch: 76 [5800/10000 (58%)]\tLoss: 0.000057 (5820/5820)\n",
            "Train Epoch: 76 [6000/10000 (60%)]\tLoss: 0.000002 (6020/6020)\n",
            "Train Epoch: 76 [6200/10000 (62%)]\tLoss: 0.000054 (6220/6220)\n",
            "Train Epoch: 76 [6400/10000 (64%)]\tLoss: 0.000019 (6420/6420)\n",
            "Train Epoch: 76 [6600/10000 (66%)]\tLoss: 0.000000 (6620/6620)\n",
            "Train Epoch: 76 [6800/10000 (68%)]\tLoss: 0.000046 (6820/6820)\n",
            "Train Epoch: 76 [7000/10000 (70%)]\tLoss: 0.000013 (7020/7020)\n",
            "Train Epoch: 76 [7200/10000 (72%)]\tLoss: 0.000021 (7220/7220)\n",
            "Train Epoch: 76 [7400/10000 (74%)]\tLoss: 0.000007 (7420/7420)\n",
            "Train Epoch: 76 [7600/10000 (76%)]\tLoss: 0.000000 (7620/7620)\n",
            "Train Epoch: 76 [7800/10000 (78%)]\tLoss: 0.000000 (7820/7820)\n",
            "Train Epoch: 76 [8000/10000 (80%)]\tLoss: 0.000044 (8020/8020)\n",
            "Train Epoch: 76 [8200/10000 (82%)]\tLoss: 0.000120 (8220/8220)\n",
            "Train Epoch: 76 [8400/10000 (84%)]\tLoss: 0.000027 (8420/8420)\n",
            "Train Epoch: 76 [8600/10000 (86%)]\tLoss: 0.000001 (8620/8620)\n",
            "Train Epoch: 76 [8800/10000 (88%)]\tLoss: 0.000010 (8820/8820)\n",
            "Train Epoch: 76 [9000/10000 (90%)]\tLoss: 0.000001 (9020/9020)\n",
            "Train Epoch: 76 [9200/10000 (92%)]\tLoss: 0.000010 (9220/9220)\n",
            "Train Epoch: 76 [9400/10000 (94%)]\tLoss: 0.000000 (9420/9420)\n",
            "Train Epoch: 76 [9600/10000 (96%)]\tLoss: 0.000000 (9620/9620)\n",
            "Train Epoch: 76 [9800/10000 (98%)]\tLoss: 0.000006 (9820/9820)\n",
            "\n",
            "76 0.144065260887146\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 76 [0/4356 (0%)]\tLoss: 3.821992 (19/20)\n",
            "Test Epoch: 76 [200/4356 (5%)]\tLoss: 38.869076 (198/220)\n",
            "Test Epoch: 76 [400/4356 (9%)]\tLoss: 0.785186 (378/420)\n",
            "Test Epoch: 76 [600/4356 (14%)]\tLoss: 21.833317 (557/620)\n",
            "Test Epoch: 76 [800/4356 (18%)]\tLoss: 8.875282 (742/820)\n",
            "Test Epoch: 76 [1000/4356 (23%)]\tLoss: 6.059405 (932/1020)\n",
            "Test Epoch: 76 [1200/4356 (28%)]\tLoss: 0.016800 (1116/1220)\n",
            "Test Epoch: 76 [1400/4356 (32%)]\tLoss: 21.993891 (1293/1420)\n",
            "Test Epoch: 76 [1600/4356 (37%)]\tLoss: 34.313274 (1470/1620)\n",
            "Test Epoch: 76 [1800/4356 (41%)]\tLoss: 25.386089 (1656/1820)\n",
            "Test Epoch: 76 [2000/4356 (46%)]\tLoss: 1.131729 (1842/2020)\n",
            "Test Epoch: 76 [2200/4356 (50%)]\tLoss: 5.589075 (2032/2220)\n",
            "Test Epoch: 76 [2400/4356 (55%)]\tLoss: 82.367165 (2216/2420)\n",
            "Test Epoch: 76 [2600/4356 (60%)]\tLoss: 18.796722 (2400/2620)\n",
            "Test Epoch: 76 [2800/4356 (64%)]\tLoss: 17.110100 (2586/2820)\n",
            "Test Epoch: 76 [3000/4356 (69%)]\tLoss: 27.146341 (2767/3020)\n",
            "Test Epoch: 76 [3200/4356 (73%)]\tLoss: 12.791300 (2946/3220)\n",
            "Test Epoch: 76 [3400/4356 (78%)]\tLoss: 59.050388 (3130/3420)\n",
            "Test Epoch: 76 [3600/4356 (83%)]\tLoss: 13.814589 (3308/3620)\n",
            "Test Epoch: 76 [3800/4356 (87%)]\tLoss: 5.008802 (3496/3820)\n",
            "Test Epoch: 76 [4000/4356 (92%)]\tLoss: 0.200754 (3679/4020)\n",
            "Test Epoch: 76 [4200/4356 (96%)]\tLoss: 0.215736 (3861/4220)\n",
            "\n",
            "76 5206.493511199951\n",
            "\n",
            "acc =  91.4830119375574\n",
            "Train Epoch: 77 [0/10000 (0%)]\tLoss: 0.000007 (20/20)\n",
            "Train Epoch: 77 [200/10000 (2%)]\tLoss: 0.000010 (220/220)\n",
            "Train Epoch: 77 [400/10000 (4%)]\tLoss: 0.000725 (420/420)\n",
            "Train Epoch: 77 [600/10000 (6%)]\tLoss: 0.000014 (620/620)\n",
            "Train Epoch: 77 [800/10000 (8%)]\tLoss: 0.000054 (820/820)\n",
            "Train Epoch: 77 [1000/10000 (10%)]\tLoss: 0.000007 (1020/1020)\n",
            "Train Epoch: 77 [1200/10000 (12%)]\tLoss: 0.000006 (1220/1220)\n",
            "Train Epoch: 77 [1400/10000 (14%)]\tLoss: 0.000001 (1420/1420)\n",
            "Train Epoch: 77 [1600/10000 (16%)]\tLoss: 0.000002 (1620/1620)\n",
            "Train Epoch: 77 [1800/10000 (18%)]\tLoss: 0.000000 (1820/1820)\n",
            "Train Epoch: 77 [2000/10000 (20%)]\tLoss: 0.000000 (2020/2020)\n",
            "Train Epoch: 77 [2200/10000 (22%)]\tLoss: 0.000021 (2220/2220)\n",
            "Train Epoch: 77 [2400/10000 (24%)]\tLoss: 0.000010 (2420/2420)\n",
            "Train Epoch: 77 [2600/10000 (26%)]\tLoss: 0.000002 (2620/2620)\n",
            "Train Epoch: 77 [2800/10000 (28%)]\tLoss: 0.000003 (2820/2820)\n",
            "Train Epoch: 77 [3000/10000 (30%)]\tLoss: 0.000031 (3020/3020)\n",
            "Train Epoch: 77 [3200/10000 (32%)]\tLoss: 0.000064 (3220/3220)\n",
            "Train Epoch: 77 [3400/10000 (34%)]\tLoss: 0.000006 (3420/3420)\n",
            "Train Epoch: 77 [3600/10000 (36%)]\tLoss: 0.000020 (3620/3620)\n",
            "Train Epoch: 77 [3800/10000 (38%)]\tLoss: 0.000071 (3820/3820)\n",
            "Train Epoch: 77 [4000/10000 (40%)]\tLoss: 0.000012 (4020/4020)\n",
            "Train Epoch: 77 [4200/10000 (42%)]\tLoss: 0.000007 (4220/4220)\n",
            "Train Epoch: 77 [4400/10000 (44%)]\tLoss: 0.000000 (4420/4420)\n",
            "Train Epoch: 77 [4600/10000 (46%)]\tLoss: 0.000011 (4620/4620)\n",
            "Train Epoch: 77 [4800/10000 (48%)]\tLoss: 0.000000 (4820/4820)\n",
            "Train Epoch: 77 [5000/10000 (50%)]\tLoss: 0.000003 (5020/5020)\n",
            "Train Epoch: 77 [5200/10000 (52%)]\tLoss: 0.000004 (5220/5220)\n",
            "Train Epoch: 77 [5400/10000 (54%)]\tLoss: 0.000000 (5420/5420)\n",
            "Train Epoch: 77 [5600/10000 (56%)]\tLoss: 0.000071 (5620/5620)\n",
            "Train Epoch: 77 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 77 [6000/10000 (60%)]\tLoss: 0.000002 (6020/6020)\n",
            "Train Epoch: 77 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 77 [6400/10000 (64%)]\tLoss: 0.000002 (6420/6420)\n",
            "Train Epoch: 77 [6600/10000 (66%)]\tLoss: 0.000049 (6620/6620)\n",
            "Train Epoch: 77 [6800/10000 (68%)]\tLoss: 0.000002 (6820/6820)\n",
            "Train Epoch: 77 [7000/10000 (70%)]\tLoss: 0.000012 (7020/7020)\n",
            "Train Epoch: 77 [7200/10000 (72%)]\tLoss: 0.000128 (7220/7220)\n",
            "Train Epoch: 77 [7400/10000 (74%)]\tLoss: 0.000006 (7420/7420)\n",
            "Train Epoch: 77 [7600/10000 (76%)]\tLoss: 0.000004 (7620/7620)\n",
            "Train Epoch: 77 [7800/10000 (78%)]\tLoss: 0.000013 (7820/7820)\n",
            "Train Epoch: 77 [8000/10000 (80%)]\tLoss: 0.000031 (8020/8020)\n",
            "Train Epoch: 77 [8200/10000 (82%)]\tLoss: 0.000014 (8220/8220)\n",
            "Train Epoch: 77 [8400/10000 (84%)]\tLoss: 0.000001 (8420/8420)\n",
            "Train Epoch: 77 [8600/10000 (86%)]\tLoss: 0.000007 (8620/8620)\n",
            "Train Epoch: 77 [8800/10000 (88%)]\tLoss: 0.000007 (8820/8820)\n",
            "Train Epoch: 77 [9000/10000 (90%)]\tLoss: 0.000005 (9020/9020)\n",
            "Train Epoch: 77 [9200/10000 (92%)]\tLoss: 0.000002 (9220/9220)\n",
            "Train Epoch: 77 [9400/10000 (94%)]\tLoss: 0.000000 (9420/9420)\n",
            "Train Epoch: 77 [9600/10000 (96%)]\tLoss: 0.000047 (9620/9620)\n",
            "Train Epoch: 77 [9800/10000 (98%)]\tLoss: 0.000024 (9820/9820)\n",
            "\n",
            "77 0.02365744113922119\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 77 [0/4356 (0%)]\tLoss: 4.852554 (19/20)\n",
            "Test Epoch: 77 [200/4356 (5%)]\tLoss: 37.290939 (197/220)\n",
            "Test Epoch: 77 [400/4356 (9%)]\tLoss: 4.188658 (375/420)\n",
            "Test Epoch: 77 [600/4356 (14%)]\tLoss: 22.744974 (557/620)\n",
            "Test Epoch: 77 [800/4356 (18%)]\tLoss: 8.950576 (741/820)\n",
            "Test Epoch: 77 [1000/4356 (23%)]\tLoss: 2.003599 (928/1020)\n",
            "Test Epoch: 77 [1200/4356 (28%)]\tLoss: 0.000589 (1112/1220)\n",
            "Test Epoch: 77 [1400/4356 (32%)]\tLoss: 21.280312 (1289/1420)\n",
            "Test Epoch: 77 [1600/4356 (37%)]\tLoss: 37.615646 (1466/1620)\n",
            "Test Epoch: 77 [1800/4356 (41%)]\tLoss: 27.203125 (1652/1820)\n",
            "Test Epoch: 77 [2000/4356 (46%)]\tLoss: 1.572260 (1838/2020)\n",
            "Test Epoch: 77 [2200/4356 (50%)]\tLoss: 5.519840 (2027/2220)\n",
            "Test Epoch: 77 [2400/4356 (55%)]\tLoss: 74.539230 (2215/2420)\n",
            "Test Epoch: 77 [2600/4356 (60%)]\tLoss: 21.737751 (2399/2620)\n",
            "Test Epoch: 77 [2800/4356 (64%)]\tLoss: 16.700600 (2587/2820)\n",
            "Test Epoch: 77 [3000/4356 (69%)]\tLoss: 29.287357 (2765/3020)\n",
            "Test Epoch: 77 [3200/4356 (73%)]\tLoss: 10.841044 (2944/3220)\n",
            "Test Epoch: 77 [3400/4356 (78%)]\tLoss: 48.024944 (3127/3420)\n",
            "Test Epoch: 77 [3600/4356 (83%)]\tLoss: 9.366196 (3304/3620)\n",
            "Test Epoch: 77 [3800/4356 (87%)]\tLoss: 5.266819 (3491/3820)\n",
            "Test Epoch: 77 [4000/4356 (92%)]\tLoss: 0.065166 (3674/4020)\n",
            "Test Epoch: 77 [4200/4356 (96%)]\tLoss: 0.573779 (3857/4220)\n",
            "\n",
            "77 5133.690925836563\n",
            "\n",
            "acc =  91.39118457300276\n",
            "Train Epoch: 78 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 78 [200/10000 (2%)]\tLoss: 0.000010 (220/220)\n",
            "Train Epoch: 78 [400/10000 (4%)]\tLoss: 0.000012 (420/420)\n",
            "Train Epoch: 78 [600/10000 (6%)]\tLoss: 0.000002 (620/620)\n",
            "Train Epoch: 78 [800/10000 (8%)]\tLoss: 0.000004 (820/820)\n",
            "Train Epoch: 78 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 78 [1200/10000 (12%)]\tLoss: 0.000020 (1220/1220)\n",
            "Train Epoch: 78 [1400/10000 (14%)]\tLoss: 0.000013 (1420/1420)\n",
            "Train Epoch: 78 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 78 [1800/10000 (18%)]\tLoss: 0.000007 (1820/1820)\n",
            "Train Epoch: 78 [2000/10000 (20%)]\tLoss: 0.000000 (2020/2020)\n",
            "Train Epoch: 78 [2200/10000 (22%)]\tLoss: 0.000027 (2220/2220)\n",
            "Train Epoch: 78 [2400/10000 (24%)]\tLoss: 0.000008 (2420/2420)\n",
            "Train Epoch: 78 [2600/10000 (26%)]\tLoss: 0.000063 (2620/2620)\n",
            "Train Epoch: 78 [2800/10000 (28%)]\tLoss: 0.000000 (2820/2820)\n",
            "Train Epoch: 78 [3000/10000 (30%)]\tLoss: 0.000006 (3020/3020)\n",
            "Train Epoch: 78 [3200/10000 (32%)]\tLoss: 0.000027 (3220/3220)\n",
            "Train Epoch: 78 [3400/10000 (34%)]\tLoss: 0.000000 (3420/3420)\n",
            "Train Epoch: 78 [3600/10000 (36%)]\tLoss: 0.000005 (3620/3620)\n",
            "Train Epoch: 78 [3800/10000 (38%)]\tLoss: 0.000037 (3820/3820)\n",
            "Train Epoch: 78 [4000/10000 (40%)]\tLoss: 0.000008 (4020/4020)\n",
            "Train Epoch: 78 [4200/10000 (42%)]\tLoss: 0.000000 (4220/4220)\n",
            "Train Epoch: 78 [4400/10000 (44%)]\tLoss: 0.000000 (4420/4420)\n",
            "Train Epoch: 78 [4600/10000 (46%)]\tLoss: 0.000000 (4620/4620)\n",
            "Train Epoch: 78 [4800/10000 (48%)]\tLoss: 0.000031 (4820/4820)\n",
            "Train Epoch: 78 [5000/10000 (50%)]\tLoss: 0.000000 (5020/5020)\n",
            "Train Epoch: 78 [5200/10000 (52%)]\tLoss: 0.000007 (5220/5220)\n",
            "Train Epoch: 78 [5400/10000 (54%)]\tLoss: 0.000051 (5420/5420)\n",
            "Train Epoch: 78 [5600/10000 (56%)]\tLoss: 0.000010 (5620/5620)\n",
            "Train Epoch: 78 [5800/10000 (58%)]\tLoss: 0.000031 (5820/5820)\n",
            "Train Epoch: 78 [6000/10000 (60%)]\tLoss: 0.000009 (6020/6020)\n",
            "Train Epoch: 78 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 78 [6400/10000 (64%)]\tLoss: 0.000000 (6420/6420)\n",
            "Train Epoch: 78 [6600/10000 (66%)]\tLoss: 0.000027 (6620/6620)\n",
            "Train Epoch: 78 [6800/10000 (68%)]\tLoss: 0.000012 (6820/6820)\n",
            "Train Epoch: 78 [7000/10000 (70%)]\tLoss: 0.000000 (7020/7020)\n",
            "Train Epoch: 78 [7200/10000 (72%)]\tLoss: 0.000001 (7220/7220)\n",
            "Train Epoch: 78 [7400/10000 (74%)]\tLoss: 0.000000 (7420/7420)\n",
            "Train Epoch: 78 [7600/10000 (76%)]\tLoss: 0.000002 (7620/7620)\n",
            "Train Epoch: 78 [7800/10000 (78%)]\tLoss: 0.000002 (7820/7820)\n",
            "Train Epoch: 78 [8000/10000 (80%)]\tLoss: 0.000043 (8020/8020)\n",
            "Train Epoch: 78 [8200/10000 (82%)]\tLoss: 0.000015 (8220/8220)\n",
            "Train Epoch: 78 [8400/10000 (84%)]\tLoss: 0.000027 (8420/8420)\n",
            "Train Epoch: 78 [8600/10000 (86%)]\tLoss: 0.000010 (8620/8620)\n",
            "Train Epoch: 78 [8800/10000 (88%)]\tLoss: 0.000000 (8820/8820)\n",
            "Train Epoch: 78 [9000/10000 (90%)]\tLoss: 0.000004 (9020/9020)\n",
            "Train Epoch: 78 [9200/10000 (92%)]\tLoss: 0.000012 (9220/9220)\n",
            "Train Epoch: 78 [9400/10000 (94%)]\tLoss: 0.000005 (9420/9420)\n",
            "Train Epoch: 78 [9600/10000 (96%)]\tLoss: 0.000015 (9620/9620)\n",
            "Train Epoch: 78 [9800/10000 (98%)]\tLoss: 0.000000 (9820/9820)\n",
            "\n",
            "78 0.011644840240478516\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 78 [0/4356 (0%)]\tLoss: 4.613027 (19/20)\n",
            "Test Epoch: 78 [200/4356 (5%)]\tLoss: 38.891769 (199/220)\n",
            "Test Epoch: 78 [400/4356 (9%)]\tLoss: 3.360562 (379/420)\n",
            "Test Epoch: 78 [600/4356 (14%)]\tLoss: 19.282234 (560/620)\n",
            "Test Epoch: 78 [800/4356 (18%)]\tLoss: 8.749307 (746/820)\n",
            "Test Epoch: 78 [1000/4356 (23%)]\tLoss: 3.180994 (933/1020)\n",
            "Test Epoch: 78 [1200/4356 (28%)]\tLoss: 0.004281 (1118/1220)\n",
            "Test Epoch: 78 [1400/4356 (32%)]\tLoss: 22.785105 (1295/1420)\n",
            "Test Epoch: 78 [1600/4356 (37%)]\tLoss: 37.275234 (1472/1620)\n",
            "Test Epoch: 78 [1800/4356 (41%)]\tLoss: 26.903027 (1658/1820)\n",
            "Test Epoch: 78 [2000/4356 (46%)]\tLoss: 1.712551 (1844/2020)\n",
            "Test Epoch: 78 [2200/4356 (50%)]\tLoss: 3.659436 (2034/2220)\n",
            "Test Epoch: 78 [2400/4356 (55%)]\tLoss: 77.929863 (2222/2420)\n",
            "Test Epoch: 78 [2600/4356 (60%)]\tLoss: 21.251442 (2406/2620)\n",
            "Test Epoch: 78 [2800/4356 (64%)]\tLoss: 17.511509 (2592/2820)\n",
            "Test Epoch: 78 [3000/4356 (69%)]\tLoss: 27.707109 (2774/3020)\n",
            "Test Epoch: 78 [3200/4356 (73%)]\tLoss: 11.371954 (2954/3220)\n",
            "Test Epoch: 78 [3400/4356 (78%)]\tLoss: 54.804237 (3138/3420)\n",
            "Test Epoch: 78 [3600/4356 (83%)]\tLoss: 8.921404 (3316/3620)\n",
            "Test Epoch: 78 [3800/4356 (87%)]\tLoss: 4.993437 (3503/3820)\n",
            "Test Epoch: 78 [4000/4356 (92%)]\tLoss: 0.182639 (3686/4020)\n",
            "Test Epoch: 78 [4200/4356 (96%)]\tLoss: 0.355822 (3869/4220)\n",
            "\n",
            "78 5231.33380317688\n",
            "\n",
            "acc =  91.66666666666667\n",
            "Train Epoch: 79 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 79 [200/10000 (2%)]\tLoss: 0.000026 (220/220)\n",
            "Train Epoch: 79 [400/10000 (4%)]\tLoss: 0.000006 (420/420)\n",
            "Train Epoch: 79 [600/10000 (6%)]\tLoss: 0.000026 (620/620)\n",
            "Train Epoch: 79 [800/10000 (8%)]\tLoss: 0.000006 (820/820)\n",
            "Train Epoch: 79 [1000/10000 (10%)]\tLoss: 0.000007 (1020/1020)\n",
            "Train Epoch: 79 [1200/10000 (12%)]\tLoss: 0.000000 (1220/1220)\n",
            "Train Epoch: 79 [1400/10000 (14%)]\tLoss: 0.000004 (1420/1420)\n",
            "Train Epoch: 79 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 79 [1800/10000 (18%)]\tLoss: 0.000004 (1820/1820)\n",
            "Train Epoch: 79 [2000/10000 (20%)]\tLoss: 0.000002 (2020/2020)\n",
            "Train Epoch: 79 [2200/10000 (22%)]\tLoss: 0.000000 (2220/2220)\n",
            "Train Epoch: 79 [2400/10000 (24%)]\tLoss: 0.000000 (2420/2420)\n",
            "Train Epoch: 79 [2600/10000 (26%)]\tLoss: 0.000001 (2620/2620)\n",
            "Train Epoch: 79 [2800/10000 (28%)]\tLoss: 0.000000 (2820/2820)\n",
            "Train Epoch: 79 [3000/10000 (30%)]\tLoss: 0.000006 (3020/3020)\n",
            "Train Epoch: 79 [3200/10000 (32%)]\tLoss: 0.000007 (3220/3220)\n",
            "Train Epoch: 79 [3400/10000 (34%)]\tLoss: 0.000000 (3420/3420)\n",
            "Train Epoch: 79 [3600/10000 (36%)]\tLoss: 0.000000 (3620/3620)\n",
            "Train Epoch: 79 [3800/10000 (38%)]\tLoss: 0.000000 (3820/3820)\n",
            "Train Epoch: 79 [4000/10000 (40%)]\tLoss: 0.000012 (4020/4020)\n",
            "Train Epoch: 79 [4200/10000 (42%)]\tLoss: 0.000000 (4220/4220)\n",
            "Train Epoch: 79 [4400/10000 (44%)]\tLoss: 0.000007 (4420/4420)\n",
            "Train Epoch: 79 [4600/10000 (46%)]\tLoss: 0.000004 (4620/4620)\n",
            "Train Epoch: 79 [4800/10000 (48%)]\tLoss: 0.000000 (4820/4820)\n",
            "Train Epoch: 79 [5000/10000 (50%)]\tLoss: 0.000000 (5020/5020)\n",
            "Train Epoch: 79 [5200/10000 (52%)]\tLoss: 0.000003 (5220/5220)\n",
            "Train Epoch: 79 [5400/10000 (54%)]\tLoss: 0.000007 (5420/5420)\n",
            "Train Epoch: 79 [5600/10000 (56%)]\tLoss: 0.000000 (5620/5620)\n",
            "Train Epoch: 79 [5800/10000 (58%)]\tLoss: 0.000001 (5820/5820)\n",
            "Train Epoch: 79 [6000/10000 (60%)]\tLoss: 0.000000 (6020/6020)\n",
            "Train Epoch: 79 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 79 [6400/10000 (64%)]\tLoss: 0.000010 (6420/6420)\n",
            "Train Epoch: 79 [6600/10000 (66%)]\tLoss: 0.000000 (6620/6620)\n",
            "Train Epoch: 79 [6800/10000 (68%)]\tLoss: 0.000005 (6820/6820)\n",
            "Train Epoch: 79 [7000/10000 (70%)]\tLoss: 0.000000 (7020/7020)\n",
            "Train Epoch: 79 [7200/10000 (72%)]\tLoss: 0.000000 (7220/7220)\n",
            "Train Epoch: 79 [7400/10000 (74%)]\tLoss: 0.000024 (7420/7420)\n",
            "Train Epoch: 79 [7600/10000 (76%)]\tLoss: 0.000000 (7620/7620)\n",
            "Train Epoch: 79 [7800/10000 (78%)]\tLoss: 0.000010 (7820/7820)\n",
            "Train Epoch: 79 [8000/10000 (80%)]\tLoss: 0.000010 (8020/8020)\n",
            "Train Epoch: 79 [8200/10000 (82%)]\tLoss: 0.000000 (8220/8220)\n",
            "Train Epoch: 79 [8400/10000 (84%)]\tLoss: 0.000005 (8420/8420)\n",
            "Train Epoch: 79 [8600/10000 (86%)]\tLoss: 0.000037 (8620/8620)\n",
            "Train Epoch: 79 [8800/10000 (88%)]\tLoss: 0.000000 (8820/8820)\n",
            "Train Epoch: 79 [9000/10000 (90%)]\tLoss: 0.000000 (9020/9020)\n",
            "Train Epoch: 79 [9200/10000 (92%)]\tLoss: 0.000002 (9220/9220)\n",
            "Train Epoch: 79 [9400/10000 (94%)]\tLoss: 0.000006 (9420/9420)\n",
            "Train Epoch: 79 [9600/10000 (96%)]\tLoss: 0.000011 (9620/9620)\n",
            "Train Epoch: 79 [9800/10000 (98%)]\tLoss: 0.000005 (9820/9820)\n",
            "\n",
            "79 0.003968000411987305\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 79 [0/4356 (0%)]\tLoss: 4.449886 (19/20)\n",
            "Test Epoch: 79 [200/4356 (5%)]\tLoss: 39.622292 (199/220)\n",
            "Test Epoch: 79 [400/4356 (9%)]\tLoss: 3.264502 (379/420)\n",
            "Test Epoch: 79 [600/4356 (14%)]\tLoss: 21.106762 (560/620)\n",
            "Test Epoch: 79 [800/4356 (18%)]\tLoss: 8.283921 (745/820)\n",
            "Test Epoch: 79 [1000/4356 (23%)]\tLoss: 3.431250 (931/1020)\n",
            "Test Epoch: 79 [1200/4356 (28%)]\tLoss: 0.001805 (1116/1220)\n",
            "Test Epoch: 79 [1400/4356 (32%)]\tLoss: 22.694347 (1292/1420)\n",
            "Test Epoch: 79 [1600/4356 (37%)]\tLoss: 37.782040 (1470/1620)\n",
            "Test Epoch: 79 [1800/4356 (41%)]\tLoss: 25.821762 (1656/1820)\n",
            "Test Epoch: 79 [2000/4356 (46%)]\tLoss: 1.921690 (1842/2020)\n",
            "Test Epoch: 79 [2200/4356 (50%)]\tLoss: 4.292963 (2032/2220)\n",
            "Test Epoch: 79 [2400/4356 (55%)]\tLoss: 78.940659 (2220/2420)\n",
            "Test Epoch: 79 [2600/4356 (60%)]\tLoss: 21.964584 (2404/2620)\n",
            "Test Epoch: 79 [2800/4356 (64%)]\tLoss: 18.005566 (2590/2820)\n",
            "Test Epoch: 79 [3000/4356 (69%)]\tLoss: 26.946501 (2772/3020)\n",
            "Test Epoch: 79 [3200/4356 (73%)]\tLoss: 11.195541 (2951/3220)\n",
            "Test Epoch: 79 [3400/4356 (78%)]\tLoss: 52.878124 (3135/3420)\n",
            "Test Epoch: 79 [3600/4356 (83%)]\tLoss: 10.686899 (3313/3620)\n",
            "Test Epoch: 79 [3800/4356 (87%)]\tLoss: 4.305264 (3500/3820)\n",
            "Test Epoch: 79 [4000/4356 (92%)]\tLoss: 0.271311 (3683/4020)\n",
            "Test Epoch: 79 [4200/4356 (96%)]\tLoss: 0.480182 (3866/4220)\n",
            "\n",
            "79 5242.210416257381\n",
            "\n",
            "acc =  91.59779614325069\n",
            "Train Epoch: 80 [0/10000 (0%)]\tLoss: 0.000010 (20/20)\n",
            "Train Epoch: 80 [200/10000 (2%)]\tLoss: 0.000002 (220/220)\n",
            "Train Epoch: 80 [400/10000 (4%)]\tLoss: 0.000005 (420/420)\n",
            "Train Epoch: 80 [600/10000 (6%)]\tLoss: 0.000006 (620/620)\n",
            "Train Epoch: 80 [800/10000 (8%)]\tLoss: 0.000012 (820/820)\n",
            "Train Epoch: 80 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 80 [1200/10000 (12%)]\tLoss: 0.000006 (1220/1220)\n",
            "Train Epoch: 80 [1400/10000 (14%)]\tLoss: 0.000008 (1420/1420)\n",
            "Train Epoch: 80 [1600/10000 (16%)]\tLoss: 0.000019 (1620/1620)\n",
            "Train Epoch: 80 [1800/10000 (18%)]\tLoss: 0.000027 (1820/1820)\n",
            "Train Epoch: 80 [2000/10000 (20%)]\tLoss: 0.000006 (2020/2020)\n",
            "Train Epoch: 80 [2200/10000 (22%)]\tLoss: 0.000007 (2220/2220)\n",
            "Train Epoch: 80 [2400/10000 (24%)]\tLoss: 0.000008 (2420/2420)\n",
            "Train Epoch: 80 [2600/10000 (26%)]\tLoss: 0.000001 (2620/2620)\n",
            "Train Epoch: 80 [2800/10000 (28%)]\tLoss: 0.000000 (2820/2820)\n",
            "Train Epoch: 80 [3000/10000 (30%)]\tLoss: 0.000023 (3020/3020)\n",
            "Train Epoch: 80 [3200/10000 (32%)]\tLoss: 0.000015 (3220/3220)\n",
            "Train Epoch: 80 [3400/10000 (34%)]\tLoss: 0.000006 (3420/3420)\n",
            "Train Epoch: 80 [3600/10000 (36%)]\tLoss: 0.000003 (3620/3620)\n",
            "Train Epoch: 80 [3800/10000 (38%)]\tLoss: 0.000016 (3820/3820)\n",
            "Train Epoch: 80 [4000/10000 (40%)]\tLoss: 0.000003 (4020/4020)\n",
            "Train Epoch: 80 [4200/10000 (42%)]\tLoss: 0.000002 (4220/4220)\n",
            "Train Epoch: 80 [4400/10000 (44%)]\tLoss: 0.000000 (4420/4420)\n",
            "Train Epoch: 80 [4600/10000 (46%)]\tLoss: 0.000000 (4620/4620)\n",
            "Train Epoch: 80 [4800/10000 (48%)]\tLoss: 0.000027 (4820/4820)\n",
            "Train Epoch: 80 [5000/10000 (50%)]\tLoss: 0.000002 (5020/5020)\n",
            "Train Epoch: 80 [5200/10000 (52%)]\tLoss: 0.000000 (5220/5220)\n",
            "Train Epoch: 80 [5400/10000 (54%)]\tLoss: 0.000005 (5420/5420)\n",
            "Train Epoch: 80 [5600/10000 (56%)]\tLoss: 0.000006 (5620/5620)\n",
            "Train Epoch: 80 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 80 [6000/10000 (60%)]\tLoss: 0.000011 (6020/6020)\n",
            "Train Epoch: 80 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 80 [6400/10000 (64%)]\tLoss: 0.000004 (6420/6420)\n",
            "Train Epoch: 80 [6600/10000 (66%)]\tLoss: 0.000003 (6620/6620)\n",
            "Train Epoch: 80 [6800/10000 (68%)]\tLoss: 0.000002 (6820/6820)\n",
            "Train Epoch: 80 [7000/10000 (70%)]\tLoss: 0.000000 (7020/7020)\n",
            "Train Epoch: 80 [7200/10000 (72%)]\tLoss: 0.000000 (7220/7220)\n",
            "Train Epoch: 80 [7400/10000 (74%)]\tLoss: 0.000002 (7420/7420)\n",
            "Train Epoch: 80 [7600/10000 (76%)]\tLoss: 0.000000 (7620/7620)\n",
            "Train Epoch: 80 [7800/10000 (78%)]\tLoss: 0.000002 (7820/7820)\n",
            "Train Epoch: 80 [8000/10000 (80%)]\tLoss: 0.000002 (8020/8020)\n",
            "Train Epoch: 80 [8200/10000 (82%)]\tLoss: 0.000008 (8220/8220)\n",
            "Train Epoch: 80 [8400/10000 (84%)]\tLoss: 0.000021 (8420/8420)\n",
            "Train Epoch: 80 [8600/10000 (86%)]\tLoss: 0.000011 (8620/8620)\n",
            "Train Epoch: 80 [8800/10000 (88%)]\tLoss: 0.000004 (8820/8820)\n",
            "Train Epoch: 80 [9000/10000 (90%)]\tLoss: 0.000011 (9020/9020)\n",
            "Train Epoch: 80 [9200/10000 (92%)]\tLoss: 0.000003 (9220/9220)\n",
            "Train Epoch: 80 [9400/10000 (94%)]\tLoss: 0.000002 (9420/9420)\n",
            "Train Epoch: 80 [9600/10000 (96%)]\tLoss: 0.000011 (9620/9620)\n",
            "Train Epoch: 80 [9800/10000 (98%)]\tLoss: 0.000004 (9820/9820)\n",
            "\n",
            "80 0.0035064220428466797\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 80 [0/4356 (0%)]\tLoss: 4.169085 (19/20)\n",
            "Test Epoch: 80 [200/4356 (5%)]\tLoss: 39.879013 (198/220)\n",
            "Test Epoch: 80 [400/4356 (9%)]\tLoss: 3.212990 (378/420)\n",
            "Test Epoch: 80 [600/4356 (14%)]\tLoss: 21.191872 (559/620)\n",
            "Test Epoch: 80 [800/4356 (18%)]\tLoss: 7.926546 (744/820)\n",
            "Test Epoch: 80 [1000/4356 (23%)]\tLoss: 3.658035 (931/1020)\n",
            "Test Epoch: 80 [1200/4356 (28%)]\tLoss: 0.001437 (1116/1220)\n",
            "Test Epoch: 80 [1400/4356 (32%)]\tLoss: 23.295578 (1292/1420)\n",
            "Test Epoch: 80 [1600/4356 (37%)]\tLoss: 37.916435 (1470/1620)\n",
            "Test Epoch: 80 [1800/4356 (41%)]\tLoss: 25.130358 (1656/1820)\n",
            "Test Epoch: 80 [2000/4356 (46%)]\tLoss: 2.029027 (1841/2020)\n",
            "Test Epoch: 80 [2200/4356 (50%)]\tLoss: 4.465794 (2030/2220)\n",
            "Test Epoch: 80 [2400/4356 (55%)]\tLoss: 79.396042 (2217/2420)\n",
            "Test Epoch: 80 [2600/4356 (60%)]\tLoss: 22.348776 (2400/2620)\n",
            "Test Epoch: 80 [2800/4356 (64%)]\tLoss: 18.361656 (2586/2820)\n",
            "Test Epoch: 80 [3000/4356 (69%)]\tLoss: 26.730791 (2768/3020)\n",
            "Test Epoch: 80 [3200/4356 (73%)]\tLoss: 10.785382 (2947/3220)\n",
            "Test Epoch: 80 [3400/4356 (78%)]\tLoss: 53.548641 (3131/3420)\n",
            "Test Epoch: 80 [3600/4356 (83%)]\tLoss: 11.561253 (3308/3620)\n",
            "Test Epoch: 80 [3800/4356 (87%)]\tLoss: 3.760545 (3494/3820)\n",
            "Test Epoch: 80 [4000/4356 (92%)]\tLoss: 0.225726 (3677/4020)\n",
            "Test Epoch: 80 [4200/4356 (96%)]\tLoss: 0.644215 (3860/4220)\n",
            "\n",
            "80 5278.076998233795\n",
            "\n",
            "acc =  91.46005509641873\n",
            "Train Epoch: 81 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 81 [200/10000 (2%)]\tLoss: 0.000003 (220/220)\n",
            "Train Epoch: 81 [400/10000 (4%)]\tLoss: 0.000000 (420/420)\n",
            "Train Epoch: 81 [600/10000 (6%)]\tLoss: 0.000004 (620/620)\n",
            "Train Epoch: 81 [800/10000 (8%)]\tLoss: 0.000000 (820/820)\n",
            "Train Epoch: 81 [1000/10000 (10%)]\tLoss: 0.000006 (1020/1020)\n",
            "Train Epoch: 81 [1200/10000 (12%)]\tLoss: 0.000004 (1220/1220)\n",
            "Train Epoch: 81 [1400/10000 (14%)]\tLoss: 0.000000 (1420/1420)\n",
            "Train Epoch: 81 [1600/10000 (16%)]\tLoss: 0.000023 (1620/1620)\n",
            "Train Epoch: 81 [1800/10000 (18%)]\tLoss: 0.000010 (1820/1820)\n",
            "Train Epoch: 81 [2000/10000 (20%)]\tLoss: 0.000004 (2020/2020)\n",
            "Train Epoch: 81 [2200/10000 (22%)]\tLoss: 0.000001 (2220/2220)\n",
            "Train Epoch: 81 [2400/10000 (24%)]\tLoss: 0.000002 (2420/2420)\n",
            "Train Epoch: 81 [2600/10000 (26%)]\tLoss: 0.000002 (2620/2620)\n",
            "Train Epoch: 81 [2800/10000 (28%)]\tLoss: 0.000006 (2820/2820)\n",
            "Train Epoch: 81 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 81 [3200/10000 (32%)]\tLoss: 0.000002 (3220/3220)\n",
            "Train Epoch: 81 [3400/10000 (34%)]\tLoss: 0.000000 (3420/3420)\n",
            "Train Epoch: 81 [3600/10000 (36%)]\tLoss: 0.000000 (3620/3620)\n",
            "Train Epoch: 81 [3800/10000 (38%)]\tLoss: 0.000007 (3820/3820)\n",
            "Train Epoch: 81 [4000/10000 (40%)]\tLoss: 0.000003 (4020/4020)\n",
            "Train Epoch: 81 [4200/10000 (42%)]\tLoss: 0.000007 (4220/4220)\n",
            "Train Epoch: 81 [4400/10000 (44%)]\tLoss: 0.000000 (4420/4420)\n",
            "Train Epoch: 81 [4600/10000 (46%)]\tLoss: 0.000008 (4620/4620)\n",
            "Train Epoch: 81 [4800/10000 (48%)]\tLoss: 0.000001 (4820/4820)\n",
            "Train Epoch: 81 [5000/10000 (50%)]\tLoss: 0.000013 (5020/5020)\n",
            "Train Epoch: 81 [5200/10000 (52%)]\tLoss: 0.000011 (5220/5220)\n",
            "Train Epoch: 81 [5400/10000 (54%)]\tLoss: 0.000010 (5420/5420)\n",
            "Train Epoch: 81 [5600/10000 (56%)]\tLoss: 0.000006 (5620/5620)\n",
            "Train Epoch: 81 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 81 [6000/10000 (60%)]\tLoss: 0.000020 (6020/6020)\n",
            "Train Epoch: 81 [6200/10000 (62%)]\tLoss: 0.000006 (6220/6220)\n",
            "Train Epoch: 81 [6400/10000 (64%)]\tLoss: 0.000007 (6420/6420)\n",
            "Train Epoch: 81 [6600/10000 (66%)]\tLoss: 0.000006 (6620/6620)\n",
            "Train Epoch: 81 [6800/10000 (68%)]\tLoss: 0.000006 (6820/6820)\n",
            "Train Epoch: 81 [7000/10000 (70%)]\tLoss: 0.000003 (7020/7020)\n",
            "Train Epoch: 81 [7200/10000 (72%)]\tLoss: 0.000002 (7220/7220)\n",
            "Train Epoch: 81 [7400/10000 (74%)]\tLoss: 0.000002 (7420/7420)\n",
            "Train Epoch: 81 [7600/10000 (76%)]\tLoss: 0.000006 (7620/7620)\n",
            "Train Epoch: 81 [7800/10000 (78%)]\tLoss: 0.000000 (7820/7820)\n",
            "Train Epoch: 81 [8000/10000 (80%)]\tLoss: 0.000005 (8020/8020)\n",
            "Train Epoch: 81 [8200/10000 (82%)]\tLoss: 0.000002 (8220/8220)\n",
            "Train Epoch: 81 [8400/10000 (84%)]\tLoss: 0.000002 (8420/8420)\n",
            "Train Epoch: 81 [8600/10000 (86%)]\tLoss: 0.000061 (8620/8620)\n",
            "Train Epoch: 81 [8800/10000 (88%)]\tLoss: 0.000000 (8820/8820)\n",
            "Train Epoch: 81 [9000/10000 (90%)]\tLoss: 0.000059 (9020/9020)\n",
            "Train Epoch: 81 [9200/10000 (92%)]\tLoss: 0.000001 (9220/9220)\n",
            "Train Epoch: 81 [9400/10000 (94%)]\tLoss: 0.000002 (9420/9420)\n",
            "Train Epoch: 81 [9600/10000 (96%)]\tLoss: 0.000002 (9620/9620)\n",
            "Train Epoch: 81 [9800/10000 (98%)]\tLoss: 0.000005 (9820/9820)\n",
            "\n",
            "81 0.00366818904876709\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 81 [0/4356 (0%)]\tLoss: 3.933015 (19/20)\n",
            "Test Epoch: 81 [200/4356 (5%)]\tLoss: 41.119415 (197/220)\n",
            "Test Epoch: 81 [400/4356 (9%)]\tLoss: 3.030701 (377/420)\n",
            "Test Epoch: 81 [600/4356 (14%)]\tLoss: 21.295979 (559/620)\n",
            "Test Epoch: 81 [800/4356 (18%)]\tLoss: 7.187141 (744/820)\n",
            "Test Epoch: 81 [1000/4356 (23%)]\tLoss: 3.812392 (932/1020)\n",
            "Test Epoch: 81 [1200/4356 (28%)]\tLoss: 0.001187 (1116/1220)\n",
            "Test Epoch: 81 [1400/4356 (32%)]\tLoss: 23.872602 (1294/1420)\n",
            "Test Epoch: 81 [1600/4356 (37%)]\tLoss: 37.736443 (1472/1620)\n",
            "Test Epoch: 81 [1800/4356 (41%)]\tLoss: 24.319288 (1659/1820)\n",
            "Test Epoch: 81 [2000/4356 (46%)]\tLoss: 2.056141 (1844/2020)\n",
            "Test Epoch: 81 [2200/4356 (50%)]\tLoss: 5.160636 (2033/2220)\n",
            "Test Epoch: 81 [2400/4356 (55%)]\tLoss: 80.465088 (2219/2420)\n",
            "Test Epoch: 81 [2600/4356 (60%)]\tLoss: 22.387066 (2402/2620)\n",
            "Test Epoch: 81 [2800/4356 (64%)]\tLoss: 18.972176 (2587/2820)\n",
            "Test Epoch: 81 [3000/4356 (69%)]\tLoss: 25.924948 (2768/3020)\n",
            "Test Epoch: 81 [3200/4356 (73%)]\tLoss: 10.857306 (2946/3220)\n",
            "Test Epoch: 81 [3400/4356 (78%)]\tLoss: 55.185528 (3129/3420)\n",
            "Test Epoch: 81 [3600/4356 (83%)]\tLoss: 12.179430 (3306/3620)\n",
            "Test Epoch: 81 [3800/4356 (87%)]\tLoss: 3.328537 (3492/3820)\n",
            "Test Epoch: 81 [4000/4356 (92%)]\tLoss: 0.179577 (3675/4020)\n",
            "Test Epoch: 81 [4200/4356 (96%)]\tLoss: 0.979469 (3857/4220)\n",
            "\n",
            "81 5308.167755007744\n",
            "\n",
            "acc =  91.3682277318641\n",
            "Train Epoch: 82 [0/10000 (0%)]\tLoss: 0.000003 (20/20)\n",
            "Train Epoch: 82 [200/10000 (2%)]\tLoss: 0.000001 (220/220)\n",
            "Train Epoch: 82 [400/10000 (4%)]\tLoss: 0.000004 (420/420)\n",
            "Train Epoch: 82 [600/10000 (6%)]\tLoss: 0.000010 (620/620)\n",
            "Train Epoch: 82 [800/10000 (8%)]\tLoss: 0.000001 (820/820)\n",
            "Train Epoch: 82 [1000/10000 (10%)]\tLoss: 0.000002 (1020/1020)\n",
            "Train Epoch: 82 [1200/10000 (12%)]\tLoss: 0.000001 (1220/1220)\n",
            "Train Epoch: 82 [1400/10000 (14%)]\tLoss: 0.000020 (1420/1420)\n",
            "Train Epoch: 82 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 82 [1800/10000 (18%)]\tLoss: 0.000000 (1820/1820)\n",
            "Train Epoch: 82 [2000/10000 (20%)]\tLoss: 0.000002 (2020/2020)\n",
            "Train Epoch: 82 [2200/10000 (22%)]\tLoss: 0.000010 (2220/2220)\n",
            "Train Epoch: 82 [2400/10000 (24%)]\tLoss: 0.000004 (2420/2420)\n",
            "Train Epoch: 82 [2600/10000 (26%)]\tLoss: 0.000010 (2620/2620)\n",
            "Train Epoch: 82 [2800/10000 (28%)]\tLoss: 0.000034 (2820/2820)\n",
            "Train Epoch: 82 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 82 [3200/10000 (32%)]\tLoss: 0.000006 (3220/3220)\n",
            "Train Epoch: 82 [3400/10000 (34%)]\tLoss: 0.000003 (3420/3420)\n",
            "Train Epoch: 82 [3600/10000 (36%)]\tLoss: 0.000008 (3620/3620)\n",
            "Train Epoch: 82 [3800/10000 (38%)]\tLoss: 0.000010 (3820/3820)\n",
            "Train Epoch: 82 [4000/10000 (40%)]\tLoss: 0.000000 (4020/4020)\n",
            "Train Epoch: 82 [4200/10000 (42%)]\tLoss: 0.000001 (4220/4220)\n",
            "Train Epoch: 82 [4400/10000 (44%)]\tLoss: 0.000008 (4420/4420)\n",
            "Train Epoch: 82 [4600/10000 (46%)]\tLoss: 0.000005 (4620/4620)\n",
            "Train Epoch: 82 [4800/10000 (48%)]\tLoss: 0.000003 (4820/4820)\n",
            "Train Epoch: 82 [5000/10000 (50%)]\tLoss: 0.000001 (5020/5020)\n",
            "Train Epoch: 82 [5200/10000 (52%)]\tLoss: 0.000011 (5220/5220)\n",
            "Train Epoch: 82 [5400/10000 (54%)]\tLoss: 0.000009 (5420/5420)\n",
            "Train Epoch: 82 [5600/10000 (56%)]\tLoss: 0.000006 (5620/5620)\n",
            "Train Epoch: 82 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 82 [6000/10000 (60%)]\tLoss: 0.000016 (6020/6020)\n",
            "Train Epoch: 82 [6200/10000 (62%)]\tLoss: 0.000023 (6220/6220)\n",
            "Train Epoch: 82 [6400/10000 (64%)]\tLoss: 0.000004 (6420/6420)\n",
            "Train Epoch: 82 [6600/10000 (66%)]\tLoss: 0.000002 (6620/6620)\n",
            "Train Epoch: 82 [6800/10000 (68%)]\tLoss: 0.000016 (6820/6820)\n",
            "Train Epoch: 82 [7000/10000 (70%)]\tLoss: 0.000002 (7020/7020)\n",
            "Train Epoch: 82 [7200/10000 (72%)]\tLoss: 0.000003 (7220/7220)\n",
            "Train Epoch: 82 [7400/10000 (74%)]\tLoss: 0.000047 (7420/7420)\n",
            "Train Epoch: 82 [7600/10000 (76%)]\tLoss: 0.000013 (7620/7620)\n",
            "Train Epoch: 82 [7800/10000 (78%)]\tLoss: 0.000017 (7820/7820)\n",
            "Train Epoch: 82 [8000/10000 (80%)]\tLoss: 0.000012 (8020/8020)\n",
            "Train Epoch: 82 [8200/10000 (82%)]\tLoss: 0.000004 (8220/8220)\n",
            "Train Epoch: 82 [8400/10000 (84%)]\tLoss: 0.000016 (8420/8420)\n",
            "Train Epoch: 82 [8600/10000 (86%)]\tLoss: 0.000009 (8620/8620)\n",
            "Train Epoch: 82 [8800/10000 (88%)]\tLoss: 0.000002 (8820/8820)\n",
            "Train Epoch: 82 [9000/10000 (90%)]\tLoss: 0.000002 (9020/9020)\n",
            "Train Epoch: 82 [9200/10000 (92%)]\tLoss: 0.000004 (9220/9220)\n",
            "Train Epoch: 82 [9400/10000 (94%)]\tLoss: 0.000010 (9420/9420)\n",
            "Train Epoch: 82 [9600/10000 (96%)]\tLoss: 0.000000 (9620/9620)\n",
            "Train Epoch: 82 [9800/10000 (98%)]\tLoss: 0.000004 (9820/9820)\n",
            "\n",
            "82 0.0038661956787109375\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 82 [0/4356 (0%)]\tLoss: 3.550147 (19/20)\n",
            "Test Epoch: 82 [200/4356 (5%)]\tLoss: 41.491394 (197/220)\n",
            "Test Epoch: 82 [400/4356 (9%)]\tLoss: 3.025869 (377/420)\n",
            "Test Epoch: 82 [600/4356 (14%)]\tLoss: 21.894920 (559/620)\n",
            "Test Epoch: 82 [800/4356 (18%)]\tLoss: 6.589932 (743/820)\n",
            "Test Epoch: 82 [1000/4356 (23%)]\tLoss: 3.884251 (932/1020)\n",
            "Test Epoch: 82 [1200/4356 (28%)]\tLoss: 0.000951 (1116/1220)\n",
            "Test Epoch: 82 [1400/4356 (32%)]\tLoss: 24.069105 (1293/1420)\n",
            "Test Epoch: 82 [1600/4356 (37%)]\tLoss: 39.050503 (1471/1620)\n",
            "Test Epoch: 82 [1800/4356 (41%)]\tLoss: 24.360825 (1657/1820)\n",
            "Test Epoch: 82 [2000/4356 (46%)]\tLoss: 2.132198 (1841/2020)\n",
            "Test Epoch: 82 [2200/4356 (50%)]\tLoss: 4.940255 (2029/2220)\n",
            "Test Epoch: 82 [2400/4356 (55%)]\tLoss: 80.399010 (2215/2420)\n",
            "Test Epoch: 82 [2600/4356 (60%)]\tLoss: 22.563320 (2398/2620)\n",
            "Test Epoch: 82 [2800/4356 (64%)]\tLoss: 19.446047 (2582/2820)\n",
            "Test Epoch: 82 [3000/4356 (69%)]\tLoss: 25.993641 (2763/3020)\n",
            "Test Epoch: 82 [3200/4356 (73%)]\tLoss: 10.793055 (2941/3220)\n",
            "Test Epoch: 82 [3400/4356 (78%)]\tLoss: 55.701382 (3124/3420)\n",
            "Test Epoch: 82 [3600/4356 (83%)]\tLoss: 12.538462 (3301/3620)\n",
            "Test Epoch: 82 [3800/4356 (87%)]\tLoss: 2.725163 (3487/3820)\n",
            "Test Epoch: 82 [4000/4356 (92%)]\tLoss: 0.154799 (3670/4020)\n",
            "Test Epoch: 82 [4200/4356 (96%)]\tLoss: 1.072843 (3853/4220)\n",
            "\n",
            "82 5349.378942668438\n",
            "\n",
            "acc =  91.34527089072543\n",
            "Train Epoch: 83 [0/10000 (0%)]\tLoss: 0.000016 (20/20)\n",
            "Train Epoch: 83 [200/10000 (2%)]\tLoss: 0.000000 (220/220)\n",
            "Train Epoch: 83 [400/10000 (4%)]\tLoss: 0.000000 (420/420)\n",
            "Train Epoch: 83 [600/10000 (6%)]\tLoss: 0.000009 (620/620)\n",
            "Train Epoch: 83 [800/10000 (8%)]\tLoss: 0.000005 (820/820)\n",
            "Train Epoch: 83 [1000/10000 (10%)]\tLoss: 0.000002 (1020/1020)\n",
            "Train Epoch: 83 [1200/10000 (12%)]\tLoss: 0.000004 (1220/1220)\n",
            "Train Epoch: 83 [1400/10000 (14%)]\tLoss: 0.000006 (1420/1420)\n",
            "Train Epoch: 83 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 83 [1800/10000 (18%)]\tLoss: 0.000008 (1820/1820)\n",
            "Train Epoch: 83 [2000/10000 (20%)]\tLoss: 0.000000 (2020/2020)\n",
            "Train Epoch: 83 [2200/10000 (22%)]\tLoss: 0.000000 (2220/2220)\n",
            "Train Epoch: 83 [2400/10000 (24%)]\tLoss: 0.000028 (2420/2420)\n",
            "Train Epoch: 83 [2600/10000 (26%)]\tLoss: 0.000008 (2620/2620)\n",
            "Train Epoch: 83 [2800/10000 (28%)]\tLoss: 0.000008 (2820/2820)\n",
            "Train Epoch: 83 [3000/10000 (30%)]\tLoss: 0.000006 (3020/3020)\n",
            "Train Epoch: 83 [3200/10000 (32%)]\tLoss: 0.000014 (3220/3220)\n",
            "Train Epoch: 83 [3400/10000 (34%)]\tLoss: 0.000002 (3420/3420)\n",
            "Train Epoch: 83 [3600/10000 (36%)]\tLoss: 0.000002 (3620/3620)\n",
            "Train Epoch: 83 [3800/10000 (38%)]\tLoss: 0.000001 (3820/3820)\n",
            "Train Epoch: 83 [4000/10000 (40%)]\tLoss: 0.000000 (4020/4020)\n",
            "Train Epoch: 83 [4200/10000 (42%)]\tLoss: 0.000004 (4220/4220)\n",
            "Train Epoch: 83 [4400/10000 (44%)]\tLoss: 0.000000 (4420/4420)\n",
            "Train Epoch: 83 [4600/10000 (46%)]\tLoss: 0.000062 (4620/4620)\n",
            "Train Epoch: 83 [4800/10000 (48%)]\tLoss: 0.000004 (4820/4820)\n",
            "Train Epoch: 83 [5000/10000 (50%)]\tLoss: 0.000004 (5020/5020)\n",
            "Train Epoch: 83 [5200/10000 (52%)]\tLoss: 0.000003 (5220/5220)\n",
            "Train Epoch: 83 [5400/10000 (54%)]\tLoss: 0.000000 (5420/5420)\n",
            "Train Epoch: 83 [5600/10000 (56%)]\tLoss: 0.000070 (5620/5620)\n",
            "Train Epoch: 83 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 83 [6000/10000 (60%)]\tLoss: 0.000006 (6020/6020)\n",
            "Train Epoch: 83 [6200/10000 (62%)]\tLoss: 0.000002 (6220/6220)\n",
            "Train Epoch: 83 [6400/10000 (64%)]\tLoss: 0.000000 (6420/6420)\n",
            "Train Epoch: 83 [6600/10000 (66%)]\tLoss: 0.000024 (6620/6620)\n",
            "Train Epoch: 83 [6800/10000 (68%)]\tLoss: 0.000002 (6820/6820)\n",
            "Train Epoch: 83 [7000/10000 (70%)]\tLoss: 0.000003 (7020/7020)\n",
            "Train Epoch: 83 [7200/10000 (72%)]\tLoss: 0.000000 (7220/7220)\n",
            "Train Epoch: 83 [7400/10000 (74%)]\tLoss: 0.000000 (7420/7420)\n",
            "Train Epoch: 83 [7600/10000 (76%)]\tLoss: 0.000004 (7620/7620)\n",
            "Train Epoch: 83 [7800/10000 (78%)]\tLoss: 0.000001 (7820/7820)\n",
            "Train Epoch: 83 [8000/10000 (80%)]\tLoss: 0.000002 (8020/8020)\n",
            "Train Epoch: 83 [8200/10000 (82%)]\tLoss: 0.000013 (8220/8220)\n",
            "Train Epoch: 83 [8400/10000 (84%)]\tLoss: 0.000033 (8420/8420)\n",
            "Train Epoch: 83 [8600/10000 (86%)]\tLoss: 0.000001 (8620/8620)\n",
            "Train Epoch: 83 [8800/10000 (88%)]\tLoss: 0.000002 (8820/8820)\n",
            "Train Epoch: 83 [9000/10000 (90%)]\tLoss: 0.000012 (9020/9020)\n",
            "Train Epoch: 83 [9200/10000 (92%)]\tLoss: 0.000016 (9220/9220)\n",
            "Train Epoch: 83 [9400/10000 (94%)]\tLoss: 0.000006 (9420/9420)\n",
            "Train Epoch: 83 [9600/10000 (96%)]\tLoss: 0.000003 (9620/9620)\n",
            "Train Epoch: 83 [9800/10000 (98%)]\tLoss: 0.000000 (9820/9820)\n",
            "\n",
            "83 0.004371285438537598\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 83 [0/4356 (0%)]\tLoss: 4.881064 (19/20)\n",
            "Test Epoch: 83 [200/4356 (5%)]\tLoss: 42.077656 (197/220)\n",
            "Test Epoch: 83 [400/4356 (9%)]\tLoss: 3.221254 (377/420)\n",
            "Test Epoch: 83 [600/4356 (14%)]\tLoss: 22.792164 (559/620)\n",
            "Test Epoch: 83 [800/4356 (18%)]\tLoss: 5.671065 (743/820)\n",
            "Test Epoch: 83 [1000/4356 (23%)]\tLoss: 4.221723 (932/1020)\n",
            "Test Epoch: 83 [1200/4356 (28%)]\tLoss: 0.000825 (1116/1220)\n",
            "Test Epoch: 83 [1400/4356 (32%)]\tLoss: 25.068943 (1294/1420)\n",
            "Test Epoch: 83 [1600/4356 (37%)]\tLoss: 38.471321 (1472/1620)\n",
            "Test Epoch: 83 [1800/4356 (41%)]\tLoss: 24.299440 (1657/1820)\n",
            "Test Epoch: 83 [2000/4356 (46%)]\tLoss: 2.411253 (1841/2020)\n",
            "Test Epoch: 83 [2200/4356 (50%)]\tLoss: 5.635019 (2029/2220)\n",
            "Test Epoch: 83 [2400/4356 (55%)]\tLoss: 80.796432 (2216/2420)\n",
            "Test Epoch: 83 [2600/4356 (60%)]\tLoss: 22.058798 (2399/2620)\n",
            "Test Epoch: 83 [2800/4356 (64%)]\tLoss: 20.296635 (2583/2820)\n",
            "Test Epoch: 83 [3000/4356 (69%)]\tLoss: 26.150881 (2766/3020)\n",
            "Test Epoch: 83 [3200/4356 (73%)]\tLoss: 10.689549 (2944/3220)\n",
            "Test Epoch: 83 [3400/4356 (78%)]\tLoss: 57.671722 (3128/3420)\n",
            "Test Epoch: 83 [3600/4356 (83%)]\tLoss: 13.074922 (3304/3620)\n",
            "Test Epoch: 83 [3800/4356 (87%)]\tLoss: 1.980932 (3491/3820)\n",
            "Test Epoch: 83 [4000/4356 (92%)]\tLoss: 0.150362 (3674/4020)\n",
            "Test Epoch: 83 [4200/4356 (96%)]\tLoss: 1.609351 (3856/4220)\n",
            "\n",
            "83 5375.621214479208\n",
            "\n",
            "acc =  91.41414141414141\n",
            "Train Epoch: 84 [0/10000 (0%)]\tLoss: 0.000002 (20/20)\n",
            "Train Epoch: 84 [200/10000 (2%)]\tLoss: 0.000000 (220/220)\n",
            "Train Epoch: 84 [400/10000 (4%)]\tLoss: 0.000000 (420/420)\n",
            "Train Epoch: 84 [600/10000 (6%)]\tLoss: 0.000004 (620/620)\n",
            "Train Epoch: 84 [800/10000 (8%)]\tLoss: 0.000006 (820/820)\n",
            "Train Epoch: 84 [1000/10000 (10%)]\tLoss: 0.000037 (1020/1020)\n",
            "Train Epoch: 84 [1200/10000 (12%)]\tLoss: 0.000004 (1220/1220)\n",
            "Train Epoch: 84 [1400/10000 (14%)]\tLoss: 0.000001 (1420/1420)\n",
            "Train Epoch: 84 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 84 [1800/10000 (18%)]\tLoss: 0.000011 (1820/1820)\n",
            "Train Epoch: 84 [2000/10000 (20%)]\tLoss: 0.000007 (2020/2020)\n",
            "Train Epoch: 84 [2200/10000 (22%)]\tLoss: 0.000015 (2220/2220)\n",
            "Train Epoch: 84 [2400/10000 (24%)]\tLoss: 0.000001 (2420/2420)\n",
            "Train Epoch: 84 [2600/10000 (26%)]\tLoss: 0.000010 (2620/2620)\n",
            "Train Epoch: 84 [2800/10000 (28%)]\tLoss: 0.000002 (2820/2820)\n",
            "Train Epoch: 84 [3000/10000 (30%)]\tLoss: 0.000022 (3020/3020)\n",
            "Train Epoch: 84 [3200/10000 (32%)]\tLoss: 0.000003 (3220/3220)\n",
            "Train Epoch: 84 [3400/10000 (34%)]\tLoss: 0.000011 (3420/3420)\n",
            "Train Epoch: 84 [3600/10000 (36%)]\tLoss: 0.000002 (3620/3620)\n",
            "Train Epoch: 84 [3800/10000 (38%)]\tLoss: 0.000007 (3820/3820)\n",
            "Train Epoch: 84 [4000/10000 (40%)]\tLoss: 0.000008 (4020/4020)\n",
            "Train Epoch: 84 [4200/10000 (42%)]\tLoss: 0.000000 (4220/4220)\n",
            "Train Epoch: 84 [4400/10000 (44%)]\tLoss: 0.000004 (4420/4420)\n",
            "Train Epoch: 84 [4600/10000 (46%)]\tLoss: 0.000001 (4620/4620)\n",
            "Train Epoch: 84 [4800/10000 (48%)]\tLoss: 0.000082 (4820/4820)\n",
            "Train Epoch: 84 [5000/10000 (50%)]\tLoss: 0.000046 (5020/5020)\n",
            "Train Epoch: 84 [5200/10000 (52%)]\tLoss: 0.000000 (5220/5220)\n",
            "Train Epoch: 84 [5400/10000 (54%)]\tLoss: 0.000014 (5420/5420)\n",
            "Train Epoch: 84 [5600/10000 (56%)]\tLoss: 0.000015 (5620/5620)\n",
            "Train Epoch: 84 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 84 [6000/10000 (60%)]\tLoss: 0.000020 (6020/6020)\n",
            "Train Epoch: 84 [6200/10000 (62%)]\tLoss: 0.000002 (6220/6220)\n",
            "Train Epoch: 84 [6400/10000 (64%)]\tLoss: 0.000021 (6420/6420)\n",
            "Train Epoch: 84 [6600/10000 (66%)]\tLoss: 0.000000 (6620/6620)\n",
            "Train Epoch: 84 [6800/10000 (68%)]\tLoss: 0.000008 (6820/6820)\n",
            "Train Epoch: 84 [7000/10000 (70%)]\tLoss: 0.000003 (7020/7020)\n",
            "Train Epoch: 84 [7200/10000 (72%)]\tLoss: 0.000040 (7220/7220)\n",
            "Train Epoch: 84 [7400/10000 (74%)]\tLoss: 0.000005 (7420/7420)\n",
            "Train Epoch: 84 [7600/10000 (76%)]\tLoss: 0.000005 (7620/7620)\n",
            "Train Epoch: 84 [7800/10000 (78%)]\tLoss: 0.000000 (7820/7820)\n",
            "Train Epoch: 84 [8000/10000 (80%)]\tLoss: 0.000000 (8020/8020)\n",
            "Train Epoch: 84 [8200/10000 (82%)]\tLoss: 0.000023 (8220/8220)\n",
            "Train Epoch: 84 [8400/10000 (84%)]\tLoss: 0.000038 (8420/8420)\n",
            "Train Epoch: 84 [8600/10000 (86%)]\tLoss: 0.000009 (8620/8620)\n",
            "Train Epoch: 84 [8800/10000 (88%)]\tLoss: 0.000004 (8820/8820)\n",
            "Train Epoch: 84 [9000/10000 (90%)]\tLoss: 0.000032 (9020/9020)\n",
            "Train Epoch: 84 [9200/10000 (92%)]\tLoss: 0.000021 (9220/9220)\n",
            "Train Epoch: 84 [9400/10000 (94%)]\tLoss: 0.000010 (9420/9420)\n",
            "Train Epoch: 84 [9600/10000 (96%)]\tLoss: 0.000008 (9620/9620)\n",
            "Train Epoch: 84 [9800/10000 (98%)]\tLoss: 0.000017 (9820/9820)\n",
            "\n",
            "84 0.004640817642211914\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 84 [0/4356 (0%)]\tLoss: 3.917946 (19/20)\n",
            "Test Epoch: 84 [200/4356 (5%)]\tLoss: 44.062599 (198/220)\n",
            "Test Epoch: 84 [400/4356 (9%)]\tLoss: 2.795120 (378/420)\n",
            "Test Epoch: 84 [600/4356 (14%)]\tLoss: 23.619598 (560/620)\n",
            "Test Epoch: 84 [800/4356 (18%)]\tLoss: 4.134272 (744/820)\n",
            "Test Epoch: 84 [1000/4356 (23%)]\tLoss: 3.649820 (931/1020)\n",
            "Test Epoch: 84 [1200/4356 (28%)]\tLoss: 0.000281 (1116/1220)\n",
            "Test Epoch: 84 [1400/4356 (32%)]\tLoss: 23.656843 (1293/1420)\n",
            "Test Epoch: 84 [1600/4356 (37%)]\tLoss: 40.116535 (1469/1620)\n",
            "Test Epoch: 84 [1800/4356 (41%)]\tLoss: 23.714598 (1655/1820)\n",
            "Test Epoch: 84 [2000/4356 (46%)]\tLoss: 2.750254 (1839/2020)\n",
            "Test Epoch: 84 [2200/4356 (50%)]\tLoss: 6.889047 (2028/2220)\n",
            "Test Epoch: 84 [2400/4356 (55%)]\tLoss: 82.034927 (2215/2420)\n",
            "Test Epoch: 84 [2600/4356 (60%)]\tLoss: 22.563545 (2398/2620)\n",
            "Test Epoch: 84 [2800/4356 (64%)]\tLoss: 21.754263 (2584/2820)\n",
            "Test Epoch: 84 [3000/4356 (69%)]\tLoss: 25.099699 (2768/3020)\n",
            "Test Epoch: 84 [3200/4356 (73%)]\tLoss: 10.672247 (2946/3220)\n",
            "Test Epoch: 84 [3400/4356 (78%)]\tLoss: 54.863941 (3129/3420)\n",
            "Test Epoch: 84 [3600/4356 (83%)]\tLoss: 15.374579 (3305/3620)\n",
            "Test Epoch: 84 [3800/4356 (87%)]\tLoss: 1.622835 (3492/3820)\n",
            "Test Epoch: 84 [4000/4356 (92%)]\tLoss: 0.171781 (3675/4020)\n",
            "Test Epoch: 84 [4200/4356 (96%)]\tLoss: 2.781524 (3856/4220)\n",
            "\n",
            "84 5374.083609163761\n",
            "\n",
            "acc =  91.41414141414141\n",
            "Train Epoch: 85 [0/10000 (0%)]\tLoss: 0.000013 (20/20)\n",
            "Train Epoch: 85 [200/10000 (2%)]\tLoss: 0.000013 (220/220)\n",
            "Train Epoch: 85 [400/10000 (4%)]\tLoss: 0.000003 (420/420)\n",
            "Train Epoch: 85 [600/10000 (6%)]\tLoss: 0.000010 (620/620)\n",
            "Train Epoch: 85 [800/10000 (8%)]\tLoss: 0.000008 (820/820)\n",
            "Train Epoch: 85 [1000/10000 (10%)]\tLoss: 0.000005 (1020/1020)\n",
            "Train Epoch: 85 [1200/10000 (12%)]\tLoss: 0.000010 (1220/1220)\n",
            "Train Epoch: 85 [1400/10000 (14%)]\tLoss: 0.000005 (1420/1420)\n",
            "Train Epoch: 85 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 85 [1800/10000 (18%)]\tLoss: 0.000002 (1820/1820)\n",
            "Train Epoch: 85 [2000/10000 (20%)]\tLoss: 0.000008 (2020/2020)\n",
            "Train Epoch: 85 [2200/10000 (22%)]\tLoss: 0.000014 (2220/2220)\n",
            "Train Epoch: 85 [2400/10000 (24%)]\tLoss: 0.000000 (2420/2420)\n",
            "Train Epoch: 85 [2600/10000 (26%)]\tLoss: 0.000009 (2620/2620)\n",
            "Train Epoch: 85 [2800/10000 (28%)]\tLoss: 0.000004 (2820/2820)\n",
            "Train Epoch: 85 [3000/10000 (30%)]\tLoss: 0.000002 (3020/3020)\n",
            "Train Epoch: 85 [3200/10000 (32%)]\tLoss: 0.000004 (3220/3220)\n",
            "Train Epoch: 85 [3400/10000 (34%)]\tLoss: 0.000006 (3420/3420)\n",
            "Train Epoch: 85 [3600/10000 (36%)]\tLoss: 0.000032 (3620/3620)\n",
            "Train Epoch: 85 [3800/10000 (38%)]\tLoss: 0.000002 (3820/3820)\n",
            "Train Epoch: 85 [4000/10000 (40%)]\tLoss: 0.000026 (4020/4020)\n",
            "Train Epoch: 85 [4200/10000 (42%)]\tLoss: 0.000002 (4220/4220)\n",
            "Train Epoch: 85 [4400/10000 (44%)]\tLoss: 0.000006 (4420/4420)\n",
            "Train Epoch: 85 [4600/10000 (46%)]\tLoss: 0.000001 (4620/4620)\n",
            "Train Epoch: 85 [4800/10000 (48%)]\tLoss: 0.000012 (4820/4820)\n",
            "Train Epoch: 85 [5000/10000 (50%)]\tLoss: 0.000012 (5020/5020)\n",
            "Train Epoch: 85 [5200/10000 (52%)]\tLoss: 0.000010 (5220/5220)\n",
            "Train Epoch: 85 [5400/10000 (54%)]\tLoss: 0.000014 (5420/5420)\n",
            "Train Epoch: 85 [5600/10000 (56%)]\tLoss: 0.000016 (5620/5620)\n",
            "Train Epoch: 85 [5800/10000 (58%)]\tLoss: 0.000021 (5820/5820)\n",
            "Train Epoch: 85 [6000/10000 (60%)]\tLoss: 0.000008 (6020/6020)\n",
            "Train Epoch: 85 [6200/10000 (62%)]\tLoss: 0.000000 (6220/6220)\n",
            "Train Epoch: 85 [6400/10000 (64%)]\tLoss: 0.000001 (6420/6420)\n",
            "Train Epoch: 85 [6600/10000 (66%)]\tLoss: 0.000008 (6620/6620)\n",
            "Train Epoch: 85 [6800/10000 (68%)]\tLoss: 0.000013 (6820/6820)\n",
            "Train Epoch: 85 [7000/10000 (70%)]\tLoss: 0.000005 (7020/7020)\n",
            "Train Epoch: 85 [7200/10000 (72%)]\tLoss: 0.000000 (7220/7220)\n",
            "Train Epoch: 85 [7400/10000 (74%)]\tLoss: 0.000004 (7420/7420)\n",
            "Train Epoch: 85 [7600/10000 (76%)]\tLoss: 0.000013 (7620/7620)\n",
            "Train Epoch: 85 [7800/10000 (78%)]\tLoss: 0.000005 (7820/7820)\n",
            "Train Epoch: 85 [8000/10000 (80%)]\tLoss: 0.000003 (8020/8020)\n",
            "Train Epoch: 85 [8200/10000 (82%)]\tLoss: 0.000006 (8220/8220)\n",
            "Train Epoch: 85 [8400/10000 (84%)]\tLoss: 0.000010 (8420/8420)\n",
            "Train Epoch: 85 [8600/10000 (86%)]\tLoss: 0.000002 (8620/8620)\n",
            "Train Epoch: 85 [8800/10000 (88%)]\tLoss: 0.000001 (8820/8820)\n",
            "Train Epoch: 85 [9000/10000 (90%)]\tLoss: 0.000000 (9020/9020)\n",
            "Train Epoch: 85 [9200/10000 (92%)]\tLoss: 0.000012 (9220/9220)\n",
            "Train Epoch: 85 [9400/10000 (94%)]\tLoss: 0.000059 (9420/9420)\n",
            "Train Epoch: 85 [9600/10000 (96%)]\tLoss: 0.000001 (9620/9620)\n",
            "Train Epoch: 85 [9800/10000 (98%)]\tLoss: 0.000003 (9820/9820)\n",
            "\n",
            "85 0.004696488380432129\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 85 [0/4356 (0%)]\tLoss: 3.801227 (19/20)\n",
            "Test Epoch: 85 [200/4356 (5%)]\tLoss: 42.830578 (199/220)\n",
            "Test Epoch: 85 [400/4356 (9%)]\tLoss: 3.053462 (379/420)\n",
            "Test Epoch: 85 [600/4356 (14%)]\tLoss: 24.176807 (561/620)\n",
            "Test Epoch: 85 [800/4356 (18%)]\tLoss: 2.913882 (744/820)\n",
            "Test Epoch: 85 [1000/4356 (23%)]\tLoss: 4.241645 (933/1020)\n",
            "Test Epoch: 85 [1200/4356 (28%)]\tLoss: 0.000492 (1119/1220)\n",
            "Test Epoch: 85 [1400/4356 (32%)]\tLoss: 24.472113 (1299/1420)\n",
            "Test Epoch: 85 [1600/4356 (37%)]\tLoss: 39.353767 (1477/1620)\n",
            "Test Epoch: 85 [1800/4356 (41%)]\tLoss: 22.394249 (1663/1820)\n",
            "Test Epoch: 85 [2000/4356 (46%)]\tLoss: 2.142046 (1847/2020)\n",
            "Test Epoch: 85 [2200/4356 (50%)]\tLoss: 8.106387 (2036/2220)\n",
            "Test Epoch: 85 [2400/4356 (55%)]\tLoss: 83.938622 (2222/2420)\n",
            "Test Epoch: 85 [2600/4356 (60%)]\tLoss: 21.295870 (2405/2620)\n",
            "Test Epoch: 85 [2800/4356 (64%)]\tLoss: 22.190445 (2591/2820)\n",
            "Test Epoch: 85 [3000/4356 (69%)]\tLoss: 25.979591 (2776/3020)\n",
            "Test Epoch: 85 [3200/4356 (73%)]\tLoss: 9.463530 (2954/3220)\n",
            "Test Epoch: 85 [3400/4356 (78%)]\tLoss: 59.936760 (3137/3420)\n",
            "Test Epoch: 85 [3600/4356 (83%)]\tLoss: 14.292500 (3315/3620)\n",
            "Test Epoch: 85 [3800/4356 (87%)]\tLoss: 1.785287 (3502/3820)\n",
            "Test Epoch: 85 [4000/4356 (92%)]\tLoss: 0.214350 (3685/4020)\n",
            "Test Epoch: 85 [4200/4356 (96%)]\tLoss: 2.723644 (3867/4220)\n",
            "\n",
            "85 5407.1598472595215\n",
            "\n",
            "acc =  91.66666666666667\n",
            "Train Epoch: 86 [0/10000 (0%)]\tLoss: 0.000072 (20/20)\n",
            "Train Epoch: 86 [200/10000 (2%)]\tLoss: 0.000004 (220/220)\n",
            "Train Epoch: 86 [400/10000 (4%)]\tLoss: 0.000005 (420/420)\n",
            "Train Epoch: 86 [600/10000 (6%)]\tLoss: 0.000014 (620/620)\n",
            "Train Epoch: 86 [800/10000 (8%)]\tLoss: 0.000001 (820/820)\n",
            "Train Epoch: 86 [1000/10000 (10%)]\tLoss: 0.000002 (1020/1020)\n",
            "Train Epoch: 86 [1200/10000 (12%)]\tLoss: 0.000004 (1220/1220)\n",
            "Train Epoch: 86 [1400/10000 (14%)]\tLoss: 0.000002 (1420/1420)\n",
            "Train Epoch: 86 [1600/10000 (16%)]\tLoss: 0.000002 (1620/1620)\n",
            "Train Epoch: 86 [1800/10000 (18%)]\tLoss: 0.000000 (1820/1820)\n",
            "Train Epoch: 86 [2000/10000 (20%)]\tLoss: 0.000002 (2020/2020)\n",
            "Train Epoch: 86 [2200/10000 (22%)]\tLoss: 0.000011 (2220/2220)\n",
            "Train Epoch: 86 [2400/10000 (24%)]\tLoss: 0.000031 (2420/2420)\n",
            "Train Epoch: 86 [2600/10000 (26%)]\tLoss: 0.000013 (2620/2620)\n",
            "Train Epoch: 86 [2800/10000 (28%)]\tLoss: 0.000002 (2820/2820)\n",
            "Train Epoch: 86 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 86 [3200/10000 (32%)]\tLoss: 0.000002 (3220/3220)\n",
            "Train Epoch: 86 [3400/10000 (34%)]\tLoss: 0.000006 (3420/3420)\n",
            "Train Epoch: 86 [3600/10000 (36%)]\tLoss: 0.000000 (3620/3620)\n",
            "Train Epoch: 86 [3800/10000 (38%)]\tLoss: 0.000011 (3820/3820)\n",
            "Train Epoch: 86 [4000/10000 (40%)]\tLoss: 0.000004 (4020/4020)\n",
            "Train Epoch: 86 [4200/10000 (42%)]\tLoss: 0.000006 (4220/4220)\n",
            "Train Epoch: 86 [4400/10000 (44%)]\tLoss: 0.000002 (4420/4420)\n",
            "Train Epoch: 86 [4600/10000 (46%)]\tLoss: 0.000009 (4620/4620)\n",
            "Train Epoch: 86 [4800/10000 (48%)]\tLoss: 0.000006 (4820/4820)\n",
            "Train Epoch: 86 [5000/10000 (50%)]\tLoss: 0.000006 (5020/5020)\n",
            "Train Epoch: 86 [5200/10000 (52%)]\tLoss: 0.000010 (5220/5220)\n",
            "Train Epoch: 86 [5400/10000 (54%)]\tLoss: 0.000019 (5420/5420)\n",
            "Train Epoch: 86 [5600/10000 (56%)]\tLoss: 0.000003 (5620/5620)\n",
            "Train Epoch: 86 [5800/10000 (58%)]\tLoss: 0.000000 (5820/5820)\n",
            "Train Epoch: 86 [6000/10000 (60%)]\tLoss: 0.000016 (6020/6020)\n",
            "Train Epoch: 86 [6200/10000 (62%)]\tLoss: 0.000002 (6220/6220)\n",
            "Train Epoch: 86 [6400/10000 (64%)]\tLoss: 0.000015 (6420/6420)\n",
            "Train Epoch: 86 [6600/10000 (66%)]\tLoss: 0.000001 (6620/6620)\n",
            "Train Epoch: 86 [6800/10000 (68%)]\tLoss: 0.000011 (6820/6820)\n",
            "Train Epoch: 86 [7000/10000 (70%)]\tLoss: 0.000011 (7020/7020)\n",
            "Train Epoch: 86 [7200/10000 (72%)]\tLoss: 0.000003 (7220/7220)\n",
            "Train Epoch: 86 [7400/10000 (74%)]\tLoss: 0.000000 (7420/7420)\n",
            "Train Epoch: 86 [7600/10000 (76%)]\tLoss: 0.000002 (7620/7620)\n",
            "Train Epoch: 86 [7800/10000 (78%)]\tLoss: 0.000024 (7820/7820)\n",
            "Train Epoch: 86 [8000/10000 (80%)]\tLoss: 0.000004 (8020/8020)\n",
            "Train Epoch: 86 [8200/10000 (82%)]\tLoss: 0.000002 (8220/8220)\n",
            "Train Epoch: 86 [8400/10000 (84%)]\tLoss: 0.000016 (8420/8420)\n",
            "Train Epoch: 86 [8600/10000 (86%)]\tLoss: 0.000035 (8620/8620)\n",
            "Train Epoch: 86 [8800/10000 (88%)]\tLoss: 0.000002 (8820/8820)\n",
            "Train Epoch: 86 [9000/10000 (90%)]\tLoss: 0.000021 (9020/9020)\n",
            "Train Epoch: 86 [9200/10000 (92%)]\tLoss: 0.000006 (9220/9220)\n",
            "Train Epoch: 86 [9400/10000 (94%)]\tLoss: 0.000015 (9420/9420)\n",
            "Train Epoch: 86 [9600/10000 (96%)]\tLoss: 0.000008 (9620/9620)\n",
            "Train Epoch: 86 [9800/10000 (98%)]\tLoss: 0.000000 (9820/9820)\n",
            "\n",
            "86 0.006026744842529297\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 86 [0/4356 (0%)]\tLoss: 4.153009 (19/20)\n",
            "Test Epoch: 86 [200/4356 (5%)]\tLoss: 43.513908 (197/220)\n",
            "Test Epoch: 86 [400/4356 (9%)]\tLoss: 3.278466 (378/420)\n",
            "Test Epoch: 86 [600/4356 (14%)]\tLoss: 24.431061 (559/620)\n",
            "Test Epoch: 86 [800/4356 (18%)]\tLoss: 2.516366 (742/820)\n",
            "Test Epoch: 86 [1000/4356 (23%)]\tLoss: 3.471597 (929/1020)\n",
            "Test Epoch: 86 [1200/4356 (28%)]\tLoss: 0.000620 (1115/1220)\n",
            "Test Epoch: 86 [1400/4356 (32%)]\tLoss: 22.977993 (1293/1420)\n",
            "Test Epoch: 86 [1600/4356 (37%)]\tLoss: 37.023720 (1470/1620)\n",
            "Test Epoch: 86 [1800/4356 (41%)]\tLoss: 24.005308 (1654/1820)\n",
            "Test Epoch: 86 [2000/4356 (46%)]\tLoss: 2.677109 (1839/2020)\n",
            "Test Epoch: 86 [2200/4356 (50%)]\tLoss: 7.460898 (2027/2220)\n",
            "Test Epoch: 86 [2400/4356 (55%)]\tLoss: 80.392914 (2214/2420)\n",
            "Test Epoch: 86 [2600/4356 (60%)]\tLoss: 22.456631 (2397/2620)\n",
            "Test Epoch: 86 [2800/4356 (64%)]\tLoss: 22.902050 (2583/2820)\n",
            "Test Epoch: 86 [3000/4356 (69%)]\tLoss: 25.197889 (2766/3020)\n",
            "Test Epoch: 86 [3200/4356 (73%)]\tLoss: 9.673212 (2945/3220)\n",
            "Test Epoch: 86 [3400/4356 (78%)]\tLoss: 60.651245 (3128/3420)\n",
            "Test Epoch: 86 [3600/4356 (83%)]\tLoss: 16.873558 (3306/3620)\n",
            "Test Epoch: 86 [3800/4356 (87%)]\tLoss: 2.067846 (3493/3820)\n",
            "Test Epoch: 86 [4000/4356 (92%)]\tLoss: 0.195052 (3675/4020)\n",
            "Test Epoch: 86 [4200/4356 (96%)]\tLoss: 5.981742 (3858/4220)\n",
            "\n",
            "86 5389.41690646112\n",
            "\n",
            "acc =  91.46005509641873\n",
            "Train Epoch: 87 [0/10000 (0%)]\tLoss: 0.000000 (20/20)\n",
            "Train Epoch: 87 [200/10000 (2%)]\tLoss: 0.000002 (220/220)\n",
            "Train Epoch: 87 [400/10000 (4%)]\tLoss: 0.000006 (420/420)\n",
            "Train Epoch: 87 [600/10000 (6%)]\tLoss: 0.000000 (620/620)\n",
            "Train Epoch: 87 [800/10000 (8%)]\tLoss: 0.000004 (820/820)\n",
            "Train Epoch: 87 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 87 [1200/10000 (12%)]\tLoss: 0.000000 (1220/1220)\n",
            "Train Epoch: 87 [1400/10000 (14%)]\tLoss: 0.000001 (1420/1420)\n",
            "Train Epoch: 87 [1600/10000 (16%)]\tLoss: 0.000017 (1620/1620)\n",
            "Train Epoch: 87 [1800/10000 (18%)]\tLoss: 0.000012 (1820/1820)\n",
            "Train Epoch: 87 [2000/10000 (20%)]\tLoss: 0.000009 (2020/2020)\n",
            "Train Epoch: 87 [2200/10000 (22%)]\tLoss: 0.000003 (2220/2220)\n",
            "Train Epoch: 87 [2400/10000 (24%)]\tLoss: 0.000008 (2420/2420)\n",
            "Train Epoch: 87 [2600/10000 (26%)]\tLoss: 0.000000 (2620/2620)\n",
            "Train Epoch: 87 [2800/10000 (28%)]\tLoss: 0.000000 (2820/2820)\n",
            "Train Epoch: 87 [3000/10000 (30%)]\tLoss: 0.000008 (3020/3020)\n",
            "Train Epoch: 87 [3200/10000 (32%)]\tLoss: 0.000010 (3220/3220)\n",
            "Train Epoch: 87 [3400/10000 (34%)]\tLoss: 0.000010 (3420/3420)\n",
            "Train Epoch: 87 [3600/10000 (36%)]\tLoss: 0.000011 (3620/3620)\n",
            "Train Epoch: 87 [3800/10000 (38%)]\tLoss: 0.000013 (3820/3820)\n",
            "Train Epoch: 87 [4000/10000 (40%)]\tLoss: 0.000014 (4020/4020)\n",
            "Train Epoch: 87 [4200/10000 (42%)]\tLoss: 0.000010 (4220/4220)\n",
            "Train Epoch: 87 [4400/10000 (44%)]\tLoss: 0.000062 (4420/4420)\n",
            "Train Epoch: 87 [4600/10000 (46%)]\tLoss: 0.000039 (4620/4620)\n",
            "Train Epoch: 87 [4800/10000 (48%)]\tLoss: 0.000005 (4820/4820)\n",
            "Train Epoch: 87 [5000/10000 (50%)]\tLoss: 0.000004 (5020/5020)\n",
            "Train Epoch: 87 [5200/10000 (52%)]\tLoss: 0.000000 (5220/5220)\n",
            "Train Epoch: 87 [5400/10000 (54%)]\tLoss: 0.000004 (5420/5420)\n",
            "Train Epoch: 87 [5600/10000 (56%)]\tLoss: 0.000001 (5620/5620)\n",
            "Train Epoch: 87 [5800/10000 (58%)]\tLoss: 0.000004 (5820/5820)\n",
            "Train Epoch: 87 [6000/10000 (60%)]\tLoss: 0.000015 (6020/6020)\n",
            "Train Epoch: 87 [6200/10000 (62%)]\tLoss: 0.000010 (6220/6220)\n",
            "Train Epoch: 87 [6400/10000 (64%)]\tLoss: 0.000016 (6420/6420)\n",
            "Train Epoch: 87 [6600/10000 (66%)]\tLoss: 0.000020 (6620/6620)\n",
            "Train Epoch: 87 [6800/10000 (68%)]\tLoss: 0.000000 (6820/6820)\n",
            "Train Epoch: 87 [7000/10000 (70%)]\tLoss: 0.000008 (7020/7020)\n",
            "Train Epoch: 87 [7200/10000 (72%)]\tLoss: 0.000020 (7220/7220)\n",
            "Train Epoch: 87 [7400/10000 (74%)]\tLoss: 0.000000 (7420/7420)\n",
            "Train Epoch: 87 [7600/10000 (76%)]\tLoss: 0.000010 (7620/7620)\n",
            "Train Epoch: 87 [7800/10000 (78%)]\tLoss: 0.000001 (7820/7820)\n",
            "Train Epoch: 87 [8000/10000 (80%)]\tLoss: 0.000054 (8020/8020)\n",
            "Train Epoch: 87 [8200/10000 (82%)]\tLoss: 0.000015 (8220/8220)\n",
            "Train Epoch: 87 [8400/10000 (84%)]\tLoss: 0.000004 (8420/8420)\n",
            "Train Epoch: 87 [8600/10000 (86%)]\tLoss: 0.000015 (8620/8620)\n",
            "Train Epoch: 87 [8800/10000 (88%)]\tLoss: 0.000004 (8820/8820)\n",
            "Train Epoch: 87 [9000/10000 (90%)]\tLoss: 0.000006 (9020/9020)\n",
            "Train Epoch: 87 [9200/10000 (92%)]\tLoss: 0.000001 (9220/9220)\n",
            "Train Epoch: 87 [9400/10000 (94%)]\tLoss: 0.000021 (9420/9420)\n",
            "Train Epoch: 87 [9600/10000 (96%)]\tLoss: 0.000002 (9620/9620)\n",
            "Train Epoch: 87 [9800/10000 (98%)]\tLoss: 0.000022 (9820/9820)\n",
            "\n",
            "87 0.014513969421386719\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 87 [0/4356 (0%)]\tLoss: 4.191217 (19/20)\n",
            "Test Epoch: 87 [200/4356 (5%)]\tLoss: 47.613834 (198/220)\n",
            "Test Epoch: 87 [400/4356 (9%)]\tLoss: 6.268338 (375/420)\n",
            "Test Epoch: 87 [600/4356 (14%)]\tLoss: 25.434002 (556/620)\n",
            "Test Epoch: 87 [800/4356 (18%)]\tLoss: 0.811766 (738/820)\n",
            "Test Epoch: 87 [1000/4356 (23%)]\tLoss: 4.913727 (927/1020)\n",
            "Test Epoch: 87 [1200/4356 (28%)]\tLoss: 0.001122 (1114/1220)\n",
            "Test Epoch: 87 [1400/4356 (32%)]\tLoss: 19.130054 (1290/1420)\n",
            "Test Epoch: 87 [1600/4356 (37%)]\tLoss: 38.888645 (1469/1620)\n",
            "Test Epoch: 87 [1800/4356 (41%)]\tLoss: 22.110086 (1652/1820)\n",
            "Test Epoch: 87 [2000/4356 (46%)]\tLoss: 0.360233 (1838/2020)\n",
            "Test Epoch: 87 [2200/4356 (50%)]\tLoss: 9.379333 (2026/2220)\n",
            "Test Epoch: 87 [2400/4356 (55%)]\tLoss: 77.722961 (2209/2420)\n",
            "Test Epoch: 87 [2600/4356 (60%)]\tLoss: 15.780614 (2392/2620)\n",
            "Test Epoch: 87 [2800/4356 (64%)]\tLoss: 23.716595 (2576/2820)\n",
            "Test Epoch: 87 [3000/4356 (69%)]\tLoss: 25.727665 (2757/3020)\n",
            "Test Epoch: 87 [3200/4356 (73%)]\tLoss: 9.698974 (2935/3220)\n",
            "Test Epoch: 87 [3400/4356 (78%)]\tLoss: 79.072945 (3117/3420)\n",
            "Test Epoch: 87 [3600/4356 (83%)]\tLoss: 18.424067 (3293/3620)\n",
            "Test Epoch: 87 [3800/4356 (87%)]\tLoss: 2.772483 (3480/3820)\n",
            "Test Epoch: 87 [4000/4356 (92%)]\tLoss: 0.570143 (3664/4020)\n",
            "Test Epoch: 87 [4200/4356 (96%)]\tLoss: 4.518339 (3846/4220)\n",
            "\n",
            "87 5536.566560506821\n",
            "\n",
            "acc =  91.1386593204775\n",
            "Train Epoch: 88 [0/10000 (0%)]\tLoss: 0.000183 (20/20)\n",
            "Train Epoch: 88 [200/10000 (2%)]\tLoss: 0.000012 (220/220)\n",
            "Train Epoch: 88 [400/10000 (4%)]\tLoss: 0.041005 (420/420)\n",
            "Train Epoch: 88 [600/10000 (6%)]\tLoss: 0.000389 (620/620)\n",
            "Train Epoch: 88 [800/10000 (8%)]\tLoss: 0.200542 (819/820)\n",
            "Train Epoch: 88 [1000/10000 (10%)]\tLoss: 0.001305 (1019/1020)\n",
            "Train Epoch: 88 [1200/10000 (12%)]\tLoss: 0.000356 (1219/1220)\n",
            "Train Epoch: 88 [1400/10000 (14%)]\tLoss: 0.000037 (1419/1420)\n",
            "Train Epoch: 88 [1600/10000 (16%)]\tLoss: 0.000556 (1619/1620)\n",
            "Train Epoch: 88 [1800/10000 (18%)]\tLoss: 0.002688 (1819/1820)\n",
            "Train Epoch: 88 [2000/10000 (20%)]\tLoss: 0.000036 (2019/2020)\n",
            "Train Epoch: 88 [2200/10000 (22%)]\tLoss: 0.000081 (2219/2220)\n",
            "Train Epoch: 88 [2400/10000 (24%)]\tLoss: 0.000027 (2419/2420)\n",
            "Train Epoch: 88 [2600/10000 (26%)]\tLoss: 0.028399 (2619/2620)\n",
            "Train Epoch: 88 [2800/10000 (28%)]\tLoss: 0.000022 (2819/2820)\n",
            "Train Epoch: 88 [3000/10000 (30%)]\tLoss: 0.000917 (3019/3020)\n",
            "Train Epoch: 88 [3200/10000 (32%)]\tLoss: 0.000068 (3219/3220)\n",
            "Train Epoch: 88 [3400/10000 (34%)]\tLoss: 0.000079 (3419/3420)\n",
            "Train Epoch: 88 [3600/10000 (36%)]\tLoss: 0.000067 (3619/3620)\n",
            "Train Epoch: 88 [3800/10000 (38%)]\tLoss: 0.003554 (3819/3820)\n",
            "Train Epoch: 88 [4000/10000 (40%)]\tLoss: 0.000243 (4019/4020)\n",
            "Train Epoch: 88 [4200/10000 (42%)]\tLoss: 0.000021 (4219/4220)\n",
            "Train Epoch: 88 [4400/10000 (44%)]\tLoss: 0.000362 (4419/4420)\n",
            "Train Epoch: 88 [4600/10000 (46%)]\tLoss: 0.000004 (4619/4620)\n",
            "Train Epoch: 88 [4800/10000 (48%)]\tLoss: 0.000029 (4819/4820)\n",
            "Train Epoch: 88 [5000/10000 (50%)]\tLoss: 0.000142 (5019/5020)\n",
            "Train Epoch: 88 [5200/10000 (52%)]\tLoss: 0.000019 (5219/5220)\n",
            "Train Epoch: 88 [5400/10000 (54%)]\tLoss: 0.000035 (5419/5420)\n",
            "Train Epoch: 88 [5600/10000 (56%)]\tLoss: 0.000051 (5619/5620)\n",
            "Train Epoch: 88 [5800/10000 (58%)]\tLoss: 0.000000 (5819/5820)\n",
            "Train Epoch: 88 [6000/10000 (60%)]\tLoss: 0.000032 (6019/6020)\n",
            "Train Epoch: 88 [6200/10000 (62%)]\tLoss: 0.000559 (6219/6220)\n",
            "Train Epoch: 88 [6400/10000 (64%)]\tLoss: 0.000017 (6419/6420)\n",
            "Train Epoch: 88 [6600/10000 (66%)]\tLoss: 0.000017 (6619/6620)\n",
            "Train Epoch: 88 [6800/10000 (68%)]\tLoss: 0.001004 (6819/6820)\n",
            "Train Epoch: 88 [7000/10000 (70%)]\tLoss: 0.000000 (7019/7020)\n",
            "Train Epoch: 88 [7200/10000 (72%)]\tLoss: 0.000094 (7219/7220)\n",
            "Train Epoch: 88 [7400/10000 (74%)]\tLoss: 0.000071 (7419/7420)\n",
            "Train Epoch: 88 [7600/10000 (76%)]\tLoss: 0.008809 (7619/7620)\n",
            "Train Epoch: 88 [7800/10000 (78%)]\tLoss: 0.000108 (7819/7820)\n",
            "Train Epoch: 88 [8000/10000 (80%)]\tLoss: 0.000341 (8019/8020)\n",
            "Train Epoch: 88 [8200/10000 (82%)]\tLoss: 0.000003 (8219/8220)\n",
            "Train Epoch: 88 [8400/10000 (84%)]\tLoss: 0.000031 (8419/8420)\n",
            "Train Epoch: 88 [8600/10000 (86%)]\tLoss: 0.000016 (8619/8620)\n",
            "Train Epoch: 88 [8800/10000 (88%)]\tLoss: 0.000004 (8819/8820)\n",
            "Train Epoch: 88 [9000/10000 (90%)]\tLoss: 0.000005 (9019/9020)\n",
            "Train Epoch: 88 [9200/10000 (92%)]\tLoss: 0.000001 (9219/9220)\n",
            "Train Epoch: 88 [9400/10000 (94%)]\tLoss: 0.000002 (9419/9420)\n",
            "Train Epoch: 88 [9600/10000 (96%)]\tLoss: 0.000000 (9619/9620)\n",
            "Train Epoch: 88 [9800/10000 (98%)]\tLoss: 0.000840 (9819/9820)\n",
            "\n",
            "88 3.0723429694771767\n",
            "\n",
            "acc =  tensor(99, device='cuda:0')\n",
            "Test Epoch: 88 [0/4356 (0%)]\tLoss: 6.228285 (19/20)\n",
            "Test Epoch: 88 [200/4356 (5%)]\tLoss: 34.326363 (197/220)\n",
            "Test Epoch: 88 [400/4356 (9%)]\tLoss: 17.293158 (374/420)\n",
            "Test Epoch: 88 [600/4356 (14%)]\tLoss: 13.904157 (557/620)\n",
            "Test Epoch: 88 [800/4356 (18%)]\tLoss: 1.920602 (736/820)\n",
            "Test Epoch: 88 [1000/4356 (23%)]\tLoss: 0.513568 (925/1020)\n",
            "Test Epoch: 88 [1200/4356 (28%)]\tLoss: 0.012593 (1110/1220)\n",
            "Test Epoch: 88 [1400/4356 (32%)]\tLoss: 19.546274 (1288/1420)\n",
            "Test Epoch: 88 [1600/4356 (37%)]\tLoss: 31.248451 (1467/1620)\n",
            "Test Epoch: 88 [1800/4356 (41%)]\tLoss: 20.282589 (1651/1820)\n",
            "Test Epoch: 88 [2000/4356 (46%)]\tLoss: 4.398281 (1835/2020)\n",
            "Test Epoch: 88 [2200/4356 (50%)]\tLoss: 6.895209 (2023/2220)\n",
            "Test Epoch: 88 [2400/4356 (55%)]\tLoss: 78.477188 (2207/2420)\n",
            "Test Epoch: 88 [2600/4356 (60%)]\tLoss: 34.578671 (2391/2620)\n",
            "Test Epoch: 88 [2800/4356 (64%)]\tLoss: 23.214809 (2577/2820)\n",
            "Test Epoch: 88 [3000/4356 (69%)]\tLoss: 24.149410 (2755/3020)\n",
            "Test Epoch: 88 [3200/4356 (73%)]\tLoss: 7.702434 (2933/3220)\n",
            "Test Epoch: 88 [3400/4356 (78%)]\tLoss: 50.723923 (3117/3420)\n",
            "Test Epoch: 88 [3600/4356 (83%)]\tLoss: 17.624462 (3293/3620)\n",
            "Test Epoch: 88 [3800/4356 (87%)]\tLoss: 9.248035 (3479/3820)\n",
            "Test Epoch: 88 [4000/4356 (92%)]\tLoss: 0.311639 (3661/4020)\n",
            "Test Epoch: 88 [4200/4356 (96%)]\tLoss: 7.283344 (3844/4220)\n",
            "\n",
            "88 5079.288427710533\n",
            "\n",
            "acc =  91.11570247933884\n",
            "Train Epoch: 89 [0/10000 (0%)]\tLoss: 0.000002 (20/20)\n",
            "Train Epoch: 89 [200/10000 (2%)]\tLoss: 0.000002 (220/220)\n",
            "Train Epoch: 89 [400/10000 (4%)]\tLoss: 0.000003 (420/420)\n",
            "Train Epoch: 89 [600/10000 (6%)]\tLoss: 0.000318 (620/620)\n",
            "Train Epoch: 89 [800/10000 (8%)]\tLoss: 0.000012 (820/820)\n",
            "Train Epoch: 89 [1000/10000 (10%)]\tLoss: 0.000006 (1020/1020)\n",
            "Train Epoch: 89 [1200/10000 (12%)]\tLoss: 0.000018 (1220/1220)\n",
            "Train Epoch: 89 [1400/10000 (14%)]\tLoss: 0.000003 (1420/1420)\n",
            "Train Epoch: 89 [1600/10000 (16%)]\tLoss: 0.000268 (1620/1620)\n",
            "Train Epoch: 89 [1800/10000 (18%)]\tLoss: 0.000120 (1820/1820)\n",
            "Train Epoch: 89 [2000/10000 (20%)]\tLoss: 0.000366 (2020/2020)\n",
            "Train Epoch: 89 [2200/10000 (22%)]\tLoss: 0.000000 (2220/2220)\n",
            "Train Epoch: 89 [2400/10000 (24%)]\tLoss: 0.000055 (2420/2420)\n",
            "Train Epoch: 89 [2600/10000 (26%)]\tLoss: 0.000001 (2620/2620)\n",
            "Train Epoch: 89 [2800/10000 (28%)]\tLoss: 0.000010 (2820/2820)\n",
            "Train Epoch: 89 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 89 [3200/10000 (32%)]\tLoss: 0.000000 (3220/3220)\n",
            "Train Epoch: 89 [3400/10000 (34%)]\tLoss: 0.000000 (3420/3420)\n",
            "Train Epoch: 89 [3600/10000 (36%)]\tLoss: 0.000313 (3620/3620)\n",
            "Train Epoch: 89 [3800/10000 (38%)]\tLoss: 0.000003 (3820/3820)\n",
            "Train Epoch: 89 [4000/10000 (40%)]\tLoss: 0.000098 (4020/4020)\n",
            "Train Epoch: 89 [4200/10000 (42%)]\tLoss: 0.000003 (4220/4220)\n",
            "Train Epoch: 89 [4400/10000 (44%)]\tLoss: 0.000054 (4420/4420)\n",
            "Train Epoch: 89 [4600/10000 (46%)]\tLoss: 0.000001 (4620/4620)\n",
            "Train Epoch: 89 [4800/10000 (48%)]\tLoss: 0.000002 (4820/4820)\n",
            "Train Epoch: 89 [5000/10000 (50%)]\tLoss: 0.000000 (5020/5020)\n",
            "Train Epoch: 89 [5200/10000 (52%)]\tLoss: 0.000028 (5220/5220)\n",
            "Train Epoch: 89 [5400/10000 (54%)]\tLoss: 0.000003 (5420/5420)\n",
            "Train Epoch: 89 [5600/10000 (56%)]\tLoss: 0.000000 (5620/5620)\n",
            "Train Epoch: 89 [5800/10000 (58%)]\tLoss: 0.000038 (5820/5820)\n",
            "Train Epoch: 89 [6000/10000 (60%)]\tLoss: 0.000082 (6020/6020)\n",
            "Train Epoch: 89 [6200/10000 (62%)]\tLoss: 0.000032 (6220/6220)\n",
            "Train Epoch: 89 [6400/10000 (64%)]\tLoss: 0.000008 (6420/6420)\n",
            "Train Epoch: 89 [6600/10000 (66%)]\tLoss: 0.000007 (6620/6620)\n",
            "Train Epoch: 89 [6800/10000 (68%)]\tLoss: 0.000079 (6820/6820)\n",
            "Train Epoch: 89 [7000/10000 (70%)]\tLoss: 0.000011 (7020/7020)\n",
            "Train Epoch: 89 [7200/10000 (72%)]\tLoss: 0.000001 (7220/7220)\n",
            "Train Epoch: 89 [7400/10000 (74%)]\tLoss: 0.000023 (7420/7420)\n",
            "Train Epoch: 89 [7600/10000 (76%)]\tLoss: 0.000003 (7620/7620)\n",
            "Train Epoch: 89 [7800/10000 (78%)]\tLoss: 0.000023 (7820/7820)\n",
            "Train Epoch: 89 [8000/10000 (80%)]\tLoss: 0.000002 (8020/8020)\n",
            "Train Epoch: 89 [8200/10000 (82%)]\tLoss: 0.000251 (8220/8220)\n",
            "Train Epoch: 89 [8400/10000 (84%)]\tLoss: 0.000214 (8420/8420)\n",
            "Train Epoch: 89 [8600/10000 (86%)]\tLoss: 0.000000 (8620/8620)\n",
            "Train Epoch: 89 [8800/10000 (88%)]\tLoss: 0.000000 (8820/8820)\n",
            "Train Epoch: 89 [9000/10000 (90%)]\tLoss: 0.000028 (9020/9020)\n",
            "Train Epoch: 89 [9200/10000 (92%)]\tLoss: 0.000032 (9220/9220)\n",
            "Train Epoch: 89 [9400/10000 (94%)]\tLoss: 0.000010 (9420/9420)\n",
            "Train Epoch: 89 [9600/10000 (96%)]\tLoss: 0.000071 (9620/9620)\n",
            "Train Epoch: 89 [9800/10000 (98%)]\tLoss: 0.000026 (9820/9820)\n",
            "\n",
            "89 0.06028318405151367\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 89 [0/4356 (0%)]\tLoss: 4.186778 (19/20)\n",
            "Test Epoch: 89 [200/4356 (5%)]\tLoss: 34.154568 (199/220)\n",
            "Test Epoch: 89 [400/4356 (9%)]\tLoss: 13.394239 (378/420)\n",
            "Test Epoch: 89 [600/4356 (14%)]\tLoss: 17.595900 (560/620)\n",
            "Test Epoch: 89 [800/4356 (18%)]\tLoss: 0.311800 (740/820)\n",
            "Test Epoch: 89 [1000/4356 (23%)]\tLoss: 1.004711 (927/1020)\n",
            "Test Epoch: 89 [1200/4356 (28%)]\tLoss: 0.013032 (1114/1220)\n",
            "Test Epoch: 89 [1400/4356 (32%)]\tLoss: 16.677891 (1293/1420)\n",
            "Test Epoch: 89 [1600/4356 (37%)]\tLoss: 32.217701 (1473/1620)\n",
            "Test Epoch: 89 [1800/4356 (41%)]\tLoss: 18.051765 (1659/1820)\n",
            "Test Epoch: 89 [2000/4356 (46%)]\tLoss: 0.551224 (1844/2020)\n",
            "Test Epoch: 89 [2200/4356 (50%)]\tLoss: 6.498837 (2033/2220)\n",
            "Test Epoch: 89 [2400/4356 (55%)]\tLoss: 74.246422 (2218/2420)\n",
            "Test Epoch: 89 [2600/4356 (60%)]\tLoss: 21.740149 (2402/2620)\n",
            "Test Epoch: 89 [2800/4356 (64%)]\tLoss: 20.672441 (2587/2820)\n",
            "Test Epoch: 89 [3000/4356 (69%)]\tLoss: 26.430025 (2766/3020)\n",
            "Test Epoch: 89 [3200/4356 (73%)]\tLoss: 6.476099 (2943/3220)\n",
            "Test Epoch: 89 [3400/4356 (78%)]\tLoss: 52.850861 (3126/3420)\n",
            "Test Epoch: 89 [3600/4356 (83%)]\tLoss: 14.529026 (3304/3620)\n",
            "Test Epoch: 89 [3800/4356 (87%)]\tLoss: 6.303638 (3492/3820)\n",
            "Test Epoch: 89 [4000/4356 (92%)]\tLoss: 0.556070 (3676/4020)\n",
            "Test Epoch: 89 [4200/4356 (96%)]\tLoss: 5.729614 (3861/4220)\n",
            "\n",
            "89 4929.513730704784\n",
            "\n",
            "acc =  91.50596877869606\n",
            "Train Epoch: 90 [0/10000 (0%)]\tLoss: 0.000001 (20/20)\n",
            "Train Epoch: 90 [200/10000 (2%)]\tLoss: 0.000000 (220/220)\n",
            "Train Epoch: 90 [400/10000 (4%)]\tLoss: 0.000015 (420/420)\n",
            "Train Epoch: 90 [600/10000 (6%)]\tLoss: 0.000061 (620/620)\n",
            "Train Epoch: 90 [800/10000 (8%)]\tLoss: 0.000000 (820/820)\n",
            "Train Epoch: 90 [1000/10000 (10%)]\tLoss: 0.000000 (1020/1020)\n",
            "Train Epoch: 90 [1200/10000 (12%)]\tLoss: 0.000017 (1220/1220)\n",
            "Train Epoch: 90 [1400/10000 (14%)]\tLoss: 0.000018 (1420/1420)\n",
            "Train Epoch: 90 [1600/10000 (16%)]\tLoss: 0.000000 (1620/1620)\n",
            "Train Epoch: 90 [1800/10000 (18%)]\tLoss: 0.000014 (1820/1820)\n",
            "Train Epoch: 90 [2000/10000 (20%)]\tLoss: 0.000010 (2020/2020)\n",
            "Train Epoch: 90 [2200/10000 (22%)]\tLoss: 0.000013 (2220/2220)\n",
            "Train Epoch: 90 [2400/10000 (24%)]\tLoss: 0.000001 (2420/2420)\n",
            "Train Epoch: 90 [2600/10000 (26%)]\tLoss: 0.000002 (2620/2620)\n",
            "Train Epoch: 90 [2800/10000 (28%)]\tLoss: 0.000026 (2820/2820)\n",
            "Train Epoch: 90 [3000/10000 (30%)]\tLoss: 0.000000 (3020/3020)\n",
            "Train Epoch: 90 [3200/10000 (32%)]\tLoss: 0.000011 (3220/3220)\n",
            "Train Epoch: 90 [3400/10000 (34%)]\tLoss: 0.000005 (3420/3420)\n",
            "Train Epoch: 90 [3600/10000 (36%)]\tLoss: 0.000024 (3620/3620)\n",
            "Train Epoch: 90 [3800/10000 (38%)]\tLoss: 0.000000 (3820/3820)\n",
            "Train Epoch: 90 [4000/10000 (40%)]\tLoss: 0.000014 (4020/4020)\n",
            "Train Epoch: 90 [4200/10000 (42%)]\tLoss: 0.000008 (4220/4220)\n",
            "Train Epoch: 90 [4400/10000 (44%)]\tLoss: 0.000013 (4420/4420)\n",
            "Train Epoch: 90 [4600/10000 (46%)]\tLoss: 0.000039 (4620/4620)\n",
            "Train Epoch: 90 [4800/10000 (48%)]\tLoss: 0.000002 (4820/4820)\n",
            "Train Epoch: 90 [5000/10000 (50%)]\tLoss: 0.000011 (5020/5020)\n",
            "Train Epoch: 90 [5200/10000 (52%)]\tLoss: 0.000001 (5220/5220)\n",
            "Train Epoch: 90 [5400/10000 (54%)]\tLoss: 0.000007 (5420/5420)\n",
            "Train Epoch: 90 [5600/10000 (56%)]\tLoss: 0.000000 (5620/5620)\n",
            "Train Epoch: 90 [5800/10000 (58%)]\tLoss: 0.000019 (5820/5820)\n",
            "Train Epoch: 90 [6000/10000 (60%)]\tLoss: 0.000046 (6020/6020)\n",
            "Train Epoch: 90 [6200/10000 (62%)]\tLoss: 0.000004 (6220/6220)\n",
            "Train Epoch: 90 [6400/10000 (64%)]\tLoss: 0.000000 (6420/6420)\n",
            "Train Epoch: 90 [6600/10000 (66%)]\tLoss: 0.000066 (6620/6620)\n",
            "Train Epoch: 90 [6800/10000 (68%)]\tLoss: 0.000021 (6820/6820)\n",
            "Train Epoch: 90 [7000/10000 (70%)]\tLoss: 0.000037 (7020/7020)\n",
            "Train Epoch: 90 [7200/10000 (72%)]\tLoss: 0.000006 (7220/7220)\n",
            "Train Epoch: 90 [7400/10000 (74%)]\tLoss: 0.000000 (7420/7420)\n",
            "Train Epoch: 90 [7600/10000 (76%)]\tLoss: 0.000006 (7620/7620)\n",
            "Train Epoch: 90 [7800/10000 (78%)]\tLoss: 0.000004 (7820/7820)\n",
            "Train Epoch: 90 [8000/10000 (80%)]\tLoss: 0.000002 (8020/8020)\n",
            "Train Epoch: 90 [8200/10000 (82%)]\tLoss: 0.000052 (8220/8220)\n",
            "Train Epoch: 90 [8400/10000 (84%)]\tLoss: 0.000005 (8420/8420)\n",
            "Train Epoch: 90 [8600/10000 (86%)]\tLoss: 0.000000 (8620/8620)\n",
            "Train Epoch: 90 [8800/10000 (88%)]\tLoss: 0.000007 (8820/8820)\n",
            "Train Epoch: 90 [9000/10000 (90%)]\tLoss: 0.000001 (9020/9020)\n",
            "Train Epoch: 90 [9200/10000 (92%)]\tLoss: 0.000002 (9220/9220)\n",
            "Train Epoch: 90 [9400/10000 (94%)]\tLoss: 0.000000 (9420/9420)\n",
            "Train Epoch: 90 [9600/10000 (96%)]\tLoss: 0.000009 (9620/9620)\n",
            "Train Epoch: 90 [9800/10000 (98%)]\tLoss: 0.000002 (9820/9820)\n",
            "\n",
            "90 0.007546544075012207\n",
            "\n",
            "acc =  tensor(100, device='cuda:0')\n",
            "Test Epoch: 90 [0/4356 (0%)]\tLoss: 4.502282 (19/20)\n",
            "Test Epoch: 90 [200/4356 (5%)]\tLoss: 34.343407 (200/220)\n",
            "Test Epoch: 90 [400/4356 (9%)]\tLoss: 13.904966 (378/420)\n",
            "Test Epoch: 90 [600/4356 (14%)]\tLoss: 17.570864 (560/620)\n",
            "Test Epoch: 90 [800/4356 (18%)]\tLoss: 0.399073 (740/820)\n",
            "Test Epoch: 90 [1000/4356 (23%)]\tLoss: 0.883797 (927/1020)\n",
            "Test Epoch: 90 [1200/4356 (28%)]\tLoss: 0.012390 (1114/1220)\n",
            "Test Epoch: 90 [1400/4356 (32%)]\tLoss: 16.712816 (1294/1420)\n",
            "Test Epoch: 90 [1600/4356 (37%)]\tLoss: 31.790358 (1474/1620)\n",
            "Test Epoch: 90 [1800/4356 (41%)]\tLoss: 17.964148 (1660/1820)\n",
            "Test Epoch: 90 [2000/4356 (46%)]\tLoss: 0.875169 (1843/2020)\n",
            "Test Epoch: 90 [2200/4356 (50%)]\tLoss: 6.416105 (2032/2220)\n",
            "Test Epoch: 90 [2400/4356 (55%)]\tLoss: 74.960434 (2217/2420)\n",
            "Test Epoch: 90 [2600/4356 (60%)]\tLoss: 22.016968 (2401/2620)\n",
            "Test Epoch: 90 [2800/4356 (64%)]\tLoss: 20.804810 (2587/2820)\n",
            "Test Epoch: 90 [3000/4356 (69%)]\tLoss: 26.536324 (2766/3020)\n",
            "Test Epoch: 90 [3200/4356 (73%)]\tLoss: 6.231642 (2942/3220)\n",
            "Test Epoch: 90 [3400/4356 (78%)]\tLoss: 52.662865 (3125/3420)\n",
            "Test Epoch: 90 [3600/4356 (83%)]\tLoss: 15.538444 (3303/3620)\n",
            "Test Epoch: 90 [3800/4356 (87%)]\tLoss: 6.207192 (3489/3820)\n",
            "Test Epoch: 90 [4000/4356 (92%)]\tLoss: 0.472177 (3673/4020)\n",
            "Test Epoch: 90 [4200/4356 (96%)]\tLoss: 5.514039 (3858/4220)\n",
            "\n",
            "90 4938.169059693813\n",
            "\n",
            "acc =  91.43709825528008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3H-PhAUZdtta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42614849-95aa-4480-87fb-bb109ebc821d"
      },
      "cell_type": "code",
      "source": [
        "#@title 학습 데이터 저장\n",
        "save_learn_data = True #@param {type:\"boolean\"}\n",
        "\n",
        "if save_learn_data == True:\n",
        "  \n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  from google.colab import files\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "\n",
        "  # Text file.\n",
        "  file = drive.CreateFile({'parents':[{u'id':'1BLb9XdJS8WuMLyVipEi-XuDNNYFgxPeF'}]})\n",
        "  file.SetContentFile('./checkpoint/ckpt.t7')  # VM에 저장되어 있는  example.txt 파일을 업로드\n",
        "  file.Upload()\n",
        "  print('Uploaded file with ID {}'.format(file.get('id')))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1G_bjkdnExlbOoYqOW90oCSpg8IdVvZuG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WRcPkJdm2pS-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Validation ##"
      ]
    },
    {
      "metadata": {
        "id": "hn0OHAtN7mCn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dirs = os.listdir(TEST_DATA_PATH) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVkkv9l-3gsj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWls4LT73ibM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_test_data = pd.DataFrame(test_dirs, columns=[\"filename\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zw7UbFUE3mdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "dc4525c8-d26e-4f07-b664-f919cb7f926f"
      },
      "cell_type": "code",
      "source": [
        "pd_test_data.tail()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>22990.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>64268.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>00493.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>64088.jpeg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>64066.jpeg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       filename\n",
              "103  22990.jpeg\n",
              "104  64268.jpeg\n",
              "105  00493.jpeg\n",
              "106  64088.jpeg\n",
              "107  64066.jpeg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "metadata": {
        "id": "g78pVTRR4AK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_test_data[\"output\"] = pd_test_data[\"filename\"].str.extract('([0-9]+)', expand=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSTIlxgp4bcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "1c740563-b29a-411c-a656-c30371d2fc9c"
      },
      "cell_type": "code",
      "source": [
        "pd_test_data.head()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43453.jpeg</td>\n",
              "      <td>43453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00424.jpeg</td>\n",
              "      <td>00424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43432.jpeg</td>\n",
              "      <td>43432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54826.jpeg</td>\n",
              "      <td>54826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00422.jpeg</td>\n",
              "      <td>00422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename output\n",
              "0  43453.jpeg  43453\n",
              "1  00424.jpeg  00424\n",
              "2  43432.jpeg  43432\n",
              "3  54826.jpeg  54826\n",
              "4  00422.jpeg  00422"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "metadata": {
        "id": "9rXNTPYME2TW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_test_data[\"output0\"] = pd_test_data[\"output\"] + \"0\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "duKm5dHOE4QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "d9ec3a8d-abc9-4645-9eb8-beb62241d252"
      },
      "cell_type": "code",
      "source": [
        "pd_test_data.head()"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "      <th>output0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43453.jpeg</td>\n",
              "      <td>43453</td>\n",
              "      <td>434530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00424.jpeg</td>\n",
              "      <td>00424</td>\n",
              "      <td>004240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43432.jpeg</td>\n",
              "      <td>43432</td>\n",
              "      <td>434320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54826.jpeg</td>\n",
              "      <td>54826</td>\n",
              "      <td>548260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00422.jpeg</td>\n",
              "      <td>00422</td>\n",
              "      <td>004220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename output output0\n",
              "0  43453.jpeg  43453  434530\n",
              "1  00424.jpeg  00424  004240\n",
              "2  43432.jpeg  43432  434320\n",
              "3  54826.jpeg  54826  548260\n",
              "4  00422.jpeg  00422  004220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "metadata": {
        "id": "yYDgfUt54zOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_index = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uHuVRbRN4gCk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image = default_loader(TEST_DATA_PATH+pd_test_data['filename'][test_index])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38mYBVLD48LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "80ea1895-e9fe-4bac-f3f9-17910c106277"
      },
      "cell_type": "code",
      "source": [
        "image"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAAA8CAAAAADEAO7JAAAPG0lEQVR4nMWae7Sd453Hv+/z3vb9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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=160x60 at 0x7FBCFBF8EDA0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "metadata": {
        "id": "tUqL-_oX4_ez",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_tensor = to_tensor(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j_n-LGGt5Gbs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_tensors = image_tensor.unsqueeze(0).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pmiWlak5PxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7e994ecd-2233-4d9c-f859-2e406c2ee6ae"
      },
      "cell_type": "code",
      "source": [
        "# do forward\n",
        "result = model(image_tensors)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "f-mKrFuE5SIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "428b78d3-88f7-4d1b-db0a-8a8068c532bc"
      },
      "cell_type": "code",
      "source": [
        "result"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-41.9463, -40.1143, -48.4192, -40.9898,   0.0000, -59.4636,\n",
              "          -50.4026, -40.1143, -36.1130, -65.6782]], device='cuda:0'),\n",
              " tensor([[-123.9182,  -65.6727,  -56.9678,    0.0000,  -82.5702,  -55.4258,\n",
              "          -103.1885,  -65.6727,  -73.7598,  -82.1815]], device='cuda:0'),\n",
              " tensor([[-35.2372, -27.4754, -26.0107, -33.2411,   0.0000, -40.4847,\n",
              "          -53.6365, -27.4754, -21.7203, -31.5233]], device='cuda:0'),\n",
              " tensor([[ -95.9697,  -63.9159, -108.5431,  -59.4012,  -67.9300,    0.0000,\n",
              "           -39.0378,  -60.2607,  -62.0431,  -52.2742]], device='cuda:0'),\n",
              " tensor([[-80.7025, -38.2891, -32.3610,   0.0000, -42.8394, -37.7909,\n",
              "          -69.0849, -38.2891, -30.4762, -35.0401]], device='cuda:0'),\n",
              " tensor([[  0.0000, -48.6290, -48.8625, -43.4186, -48.9253, -49.3887,\n",
              "          -42.8840, -38.5821, -50.6318, -39.6352]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "metadata": {
        "id": "2GaSrM2i5WyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d8a37e9-fd3a-4946-be5f-e889eca8144f"
      },
      "cell_type": "code",
      "source": [
        "print(\"{}{}{}{}{}{}\".format(\n",
        "    result[0].argmax().item(),result[1].argmax().item(), result[2].argmax().item(),\n",
        "    result[3].argmax().item(),result[4].argmax().item(), result[5].argmax().item() ) ) "
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "434530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Qh9Y-TH8o1i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c95bf124-d173-47ec-d493-6bb08efc7988"
      },
      "cell_type": "code",
      "source": [
        "result_list = []\n",
        "for idx in range(len(pd_test_data)):\n",
        "  image = default_loader(TEST_DATA_PATH+pd_test_data['filename'][idx])\n",
        "  image_tensor = to_tensor(image)\n",
        "  image_tensors = image_tensor.unsqueeze(0).to(device)\n",
        "  result = model(image_tensors)\n",
        "  results=\"{}{}{}{}{}{}\".format(\n",
        "    result[0].argmax().item(),result[1].argmax().item(), result[2].argmax().item(),\n",
        "    result[3].argmax().item(),result[4].argmax().item(), result[5].argmax().item() )\n",
        "  result_list.append(results)  "
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Gn7g5kS8_Oy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1918
        },
        "outputId": "065a213a-97d5-4f2f-e280-b0de494b28d9"
      },
      "cell_type": "code",
      "source": [
        "result_list"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['434530',\n",
              " '004240',\n",
              " '434320',\n",
              " '548260',\n",
              " '000220',\n",
              " '838380',\n",
              " '836460',\n",
              " '004950',\n",
              " '640630',\n",
              " '022986',\n",
              " '836900',\n",
              " '548460',\n",
              " '932430',\n",
              " '548540',\n",
              " '838090',\n",
              " '932650',\n",
              " '642690',\n",
              " '004490',\n",
              " '836650',\n",
              " '640850',\n",
              " '332360',\n",
              " '229640',\n",
              " '838300',\n",
              " '093302',\n",
              " '932590',\n",
              " '230480',\n",
              " '230200',\n",
              " '434890',\n",
              " '640950',\n",
              " '836890',\n",
              " '004880',\n",
              " '933290',\n",
              " '434250',\n",
              " '932640',\n",
              " '838030',\n",
              " '932530',\n",
              " '004480',\n",
              " '836260',\n",
              " '642200',\n",
              " '230340',\n",
              " '332590',\n",
              " '932480',\n",
              " '332930',\n",
              " '230420',\n",
              " '454590',\n",
              " '004080',\n",
              " '932950',\n",
              " '434930',\n",
              " '083640',\n",
              " '229860',\n",
              " '332650',\n",
              " '838360',\n",
              " '932340',\n",
              " '434350',\n",
              " '229690',\n",
              " '838340',\n",
              " '434360',\n",
              " '642450',\n",
              " '548360',\n",
              " '332830',\n",
              " '548500',\n",
              " '836300',\n",
              " '434300',\n",
              " '640640',\n",
              " '004850',\n",
              " '332520',\n",
              " '932880',\n",
              " '434660',\n",
              " '004260',\n",
              " '434090',\n",
              " '054830',\n",
              " '064084',\n",
              " '064068',\n",
              " '004990',\n",
              " '434520',\n",
              " '230490',\n",
              " '004000',\n",
              " '230360',\n",
              " '434450',\n",
              " '836420',\n",
              " '932660',\n",
              " '004500',\n",
              " '838320',\n",
              " '434850',\n",
              " '640540',\n",
              " '033259',\n",
              " '933230',\n",
              " '434580',\n",
              " '229880',\n",
              " '004620',\n",
              " '933000',\n",
              " '230550',\n",
              " '642430',\n",
              " '932850',\n",
              " '548390',\n",
              " '332580',\n",
              " '004600',\n",
              " '932580',\n",
              " '640430',\n",
              " '434290',\n",
              " '229840',\n",
              " '640530',\n",
              " '836350',\n",
              " '229900',\n",
              " '642680',\n",
              " '004930',\n",
              " '640880',\n",
              " '640660']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "Ro-TQiqz-K5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd_test_data[\"result\"] = result_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sSVfri7f_Y5F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.options.display.max_rows = 108"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2JmxqYjL_Qp5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "list0_correct = pd_test_data[\"output\"] == pd_test_data[\"result\"]\n",
        "list1_correct = pd_test_data[\"output0\"] == pd_test_data[\"result\"]\n",
        "list_correct = list0_correct |  list1_correct\n",
        "pd_test_data[\"Compare\"] = list_correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gu3ihVnPBm2P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3244
        },
        "outputId": "6a5c4ee4-244e-492f-eab3-99cfed2f5860"
      },
      "cell_type": "code",
      "source": [
        "pd_test_data"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>output</th>\n",
              "      <th>output0</th>\n",
              "      <th>result</th>\n",
              "      <th>Compare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>43453.jpeg</td>\n",
              "      <td>43453</td>\n",
              "      <td>434530</td>\n",
              "      <td>434530</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00424.jpeg</td>\n",
              "      <td>00424</td>\n",
              "      <td>004240</td>\n",
              "      <td>004240</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43432.jpeg</td>\n",
              "      <td>43432</td>\n",
              "      <td>434320</td>\n",
              "      <td>434320</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54826.jpeg</td>\n",
              "      <td>54826</td>\n",
              "      <td>548260</td>\n",
              "      <td>548260</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00422.jpeg</td>\n",
              "      <td>00422</td>\n",
              "      <td>004220</td>\n",
              "      <td>000220</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>83838.jpeg</td>\n",
              "      <td>83838</td>\n",
              "      <td>838380</td>\n",
              "      <td>838380</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>83646.jpeg</td>\n",
              "      <td>83646</td>\n",
              "      <td>836460</td>\n",
              "      <td>836460</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00495.jpeg</td>\n",
              "      <td>00495</td>\n",
              "      <td>004950</td>\n",
              "      <td>004950</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64063.jpeg</td>\n",
              "      <td>64063</td>\n",
              "      <td>640630</td>\n",
              "      <td>640630</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>022986.jpeg</td>\n",
              "      <td>022986</td>\n",
              "      <td>0229860</td>\n",
              "      <td>022986</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>83690.jpeg</td>\n",
              "      <td>83690</td>\n",
              "      <td>836900</td>\n",
              "      <td>836900</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>54846.jpeg</td>\n",
              "      <td>54846</td>\n",
              "      <td>548460</td>\n",
              "      <td>548460</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>93243.jpeg</td>\n",
              "      <td>93243</td>\n",
              "      <td>932430</td>\n",
              "      <td>932430</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>54854.jpeg</td>\n",
              "      <td>54854</td>\n",
              "      <td>548540</td>\n",
              "      <td>548540</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>83809.jpeg</td>\n",
              "      <td>83809</td>\n",
              "      <td>838090</td>\n",
              "      <td>838090</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>93265.jpeg</td>\n",
              "      <td>93265</td>\n",
              "      <td>932650</td>\n",
              "      <td>932650</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>64269.jpeg</td>\n",
              "      <td>64269</td>\n",
              "      <td>642690</td>\n",
              "      <td>642690</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>00449.jpeg</td>\n",
              "      <td>00449</td>\n",
              "      <td>004490</td>\n",
              "      <td>004490</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>83665.jpeg</td>\n",
              "      <td>83665</td>\n",
              "      <td>836650</td>\n",
              "      <td>836650</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>64085.jpeg</td>\n",
              "      <td>64085</td>\n",
              "      <td>640850</td>\n",
              "      <td>640850</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>33236.jpeg</td>\n",
              "      <td>33236</td>\n",
              "      <td>332360</td>\n",
              "      <td>332360</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22964.jpeg</td>\n",
              "      <td>22964</td>\n",
              "      <td>229640</td>\n",
              "      <td>229640</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>83830.jpeg</td>\n",
              "      <td>83830</td>\n",
              "      <td>838300</td>\n",
              "      <td>838300</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>093302.jpeg</td>\n",
              "      <td>093302</td>\n",
              "      <td>0933020</td>\n",
              "      <td>093302</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>93259.jpeg</td>\n",
              "      <td>93259</td>\n",
              "      <td>932590</td>\n",
              "      <td>932590</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>23048.jpeg</td>\n",
              "      <td>23048</td>\n",
              "      <td>230480</td>\n",
              "      <td>230480</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>23020.jpeg</td>\n",
              "      <td>23020</td>\n",
              "      <td>230200</td>\n",
              "      <td>230200</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>43489.jpeg</td>\n",
              "      <td>43489</td>\n",
              "      <td>434890</td>\n",
              "      <td>434890</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>64095.jpeg</td>\n",
              "      <td>64095</td>\n",
              "      <td>640950</td>\n",
              "      <td>640950</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>83689.jpeg</td>\n",
              "      <td>83689</td>\n",
              "      <td>836890</td>\n",
              "      <td>836890</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>00488.jpeg</td>\n",
              "      <td>00488</td>\n",
              "      <td>004880</td>\n",
              "      <td>004880</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>93329.jpeg</td>\n",
              "      <td>93329</td>\n",
              "      <td>933290</td>\n",
              "      <td>933290</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>43425.jpeg</td>\n",
              "      <td>43425</td>\n",
              "      <td>434250</td>\n",
              "      <td>434250</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>93264.jpeg</td>\n",
              "      <td>93264</td>\n",
              "      <td>932640</td>\n",
              "      <td>932640</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>83803.jpeg</td>\n",
              "      <td>83803</td>\n",
              "      <td>838030</td>\n",
              "      <td>838030</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>93253.jpeg</td>\n",
              "      <td>93253</td>\n",
              "      <td>932530</td>\n",
              "      <td>932530</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>00448.jpeg</td>\n",
              "      <td>00448</td>\n",
              "      <td>004480</td>\n",
              "      <td>004480</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>83626.jpeg</td>\n",
              "      <td>83626</td>\n",
              "      <td>836260</td>\n",
              "      <td>836260</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>64220.jpeg</td>\n",
              "      <td>64220</td>\n",
              "      <td>642200</td>\n",
              "      <td>642200</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>23034.jpeg</td>\n",
              "      <td>23034</td>\n",
              "      <td>230340</td>\n",
              "      <td>230340</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>33259.jpeg</td>\n",
              "      <td>33259</td>\n",
              "      <td>332590</td>\n",
              "      <td>332590</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>93248.jpeg</td>\n",
              "      <td>93248</td>\n",
              "      <td>932480</td>\n",
              "      <td>932480</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>33293.jpeg</td>\n",
              "      <td>33293</td>\n",
              "      <td>332930</td>\n",
              "      <td>332930</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>23042.jpeg</td>\n",
              "      <td>23042</td>\n",
              "      <td>230420</td>\n",
              "      <td>230420</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43459.jpeg</td>\n",
              "      <td>43459</td>\n",
              "      <td>434590</td>\n",
              "      <td>454590</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>00408.jpeg</td>\n",
              "      <td>00408</td>\n",
              "      <td>004080</td>\n",
              "      <td>004080</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>93295.jpeg</td>\n",
              "      <td>93295</td>\n",
              "      <td>932950</td>\n",
              "      <td>932950</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>43493.jpeg</td>\n",
              "      <td>43493</td>\n",
              "      <td>434930</td>\n",
              "      <td>434930</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>083640.jpeg</td>\n",
              "      <td>083640</td>\n",
              "      <td>0836400</td>\n",
              "      <td>083640</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>22986.jpeg</td>\n",
              "      <td>22986</td>\n",
              "      <td>229860</td>\n",
              "      <td>229860</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>33265.jpeg</td>\n",
              "      <td>33265</td>\n",
              "      <td>332650</td>\n",
              "      <td>332650</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>83836.jpeg</td>\n",
              "      <td>83836</td>\n",
              "      <td>838360</td>\n",
              "      <td>838360</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>93234.jpeg</td>\n",
              "      <td>93234</td>\n",
              "      <td>932340</td>\n",
              "      <td>932340</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>43435.jpeg</td>\n",
              "      <td>43435</td>\n",
              "      <td>434350</td>\n",
              "      <td>434350</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>22969.jpeg</td>\n",
              "      <td>22969</td>\n",
              "      <td>229690</td>\n",
              "      <td>229690</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>83834.jpeg</td>\n",
              "      <td>83834</td>\n",
              "      <td>838340</td>\n",
              "      <td>838340</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>43436.jpeg</td>\n",
              "      <td>43436</td>\n",
              "      <td>434360</td>\n",
              "      <td>434360</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>64245.jpeg</td>\n",
              "      <td>64245</td>\n",
              "      <td>642450</td>\n",
              "      <td>642450</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>54836.jpeg</td>\n",
              "      <td>54836</td>\n",
              "      <td>548360</td>\n",
              "      <td>548360</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>33283.jpeg</td>\n",
              "      <td>33283</td>\n",
              "      <td>332830</td>\n",
              "      <td>332830</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>54850.jpeg</td>\n",
              "      <td>54850</td>\n",
              "      <td>548500</td>\n",
              "      <td>548500</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>83630.jpeg</td>\n",
              "      <td>83630</td>\n",
              "      <td>836300</td>\n",
              "      <td>836300</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>43430.jpeg</td>\n",
              "      <td>43430</td>\n",
              "      <td>434300</td>\n",
              "      <td>434300</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>64064.jpeg</td>\n",
              "      <td>64064</td>\n",
              "      <td>640640</td>\n",
              "      <td>640640</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>00485.jpeg</td>\n",
              "      <td>00485</td>\n",
              "      <td>004850</td>\n",
              "      <td>004850</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>33252.jpeg</td>\n",
              "      <td>33252</td>\n",
              "      <td>332520</td>\n",
              "      <td>332520</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>93288.jpeg</td>\n",
              "      <td>93288</td>\n",
              "      <td>932880</td>\n",
              "      <td>932880</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>43466.jpeg</td>\n",
              "      <td>43466</td>\n",
              "      <td>434660</td>\n",
              "      <td>434660</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>00426.jpeg</td>\n",
              "      <td>00426</td>\n",
              "      <td>004260</td>\n",
              "      <td>004260</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>43409.jpeg</td>\n",
              "      <td>43409</td>\n",
              "      <td>434090</td>\n",
              "      <td>434090</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>054830.jpeg</td>\n",
              "      <td>054830</td>\n",
              "      <td>0548300</td>\n",
              "      <td>054830</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>064084.jpeg</td>\n",
              "      <td>064084</td>\n",
              "      <td>0640840</td>\n",
              "      <td>064084</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>064068.jpeg</td>\n",
              "      <td>064068</td>\n",
              "      <td>0640680</td>\n",
              "      <td>064068</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>00499.jpeg</td>\n",
              "      <td>00499</td>\n",
              "      <td>004990</td>\n",
              "      <td>004990</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>43452.jpeg</td>\n",
              "      <td>43452</td>\n",
              "      <td>434520</td>\n",
              "      <td>434520</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>23049.jpeg</td>\n",
              "      <td>23049</td>\n",
              "      <td>230490</td>\n",
              "      <td>230490</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>00400.jpeg</td>\n",
              "      <td>00400</td>\n",
              "      <td>004000</td>\n",
              "      <td>004000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>23036.jpeg</td>\n",
              "      <td>23036</td>\n",
              "      <td>230360</td>\n",
              "      <td>230360</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>43445.jpeg</td>\n",
              "      <td>43445</td>\n",
              "      <td>434450</td>\n",
              "      <td>434450</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>83642.jpeg</td>\n",
              "      <td>83642</td>\n",
              "      <td>836420</td>\n",
              "      <td>836420</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>93266.jpeg</td>\n",
              "      <td>93266</td>\n",
              "      <td>932660</td>\n",
              "      <td>932660</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>00450.jpeg</td>\n",
              "      <td>00450</td>\n",
              "      <td>004500</td>\n",
              "      <td>004500</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>83832.jpeg</td>\n",
              "      <td>83832</td>\n",
              "      <td>838320</td>\n",
              "      <td>838320</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>43485.jpeg</td>\n",
              "      <td>43485</td>\n",
              "      <td>434850</td>\n",
              "      <td>434850</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>64054.jpeg</td>\n",
              "      <td>64054</td>\n",
              "      <td>640540</td>\n",
              "      <td>640540</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>033259.jpeg</td>\n",
              "      <td>033259</td>\n",
              "      <td>0332590</td>\n",
              "      <td>033259</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>93323.jpeg</td>\n",
              "      <td>93323</td>\n",
              "      <td>933230</td>\n",
              "      <td>933230</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>43458.jpeg</td>\n",
              "      <td>43458</td>\n",
              "      <td>434580</td>\n",
              "      <td>434580</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>22988.jpeg</td>\n",
              "      <td>22988</td>\n",
              "      <td>229880</td>\n",
              "      <td>229880</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>00462.jpeg</td>\n",
              "      <td>00462</td>\n",
              "      <td>004620</td>\n",
              "      <td>004620</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>93300.jpeg</td>\n",
              "      <td>93300</td>\n",
              "      <td>933000</td>\n",
              "      <td>933000</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>23055.jpeg</td>\n",
              "      <td>23055</td>\n",
              "      <td>230550</td>\n",
              "      <td>230550</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>64243.jpeg</td>\n",
              "      <td>64243</td>\n",
              "      <td>642430</td>\n",
              "      <td>642430</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93285.jpeg</td>\n",
              "      <td>93285</td>\n",
              "      <td>932850</td>\n",
              "      <td>932850</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>54839.jpeg</td>\n",
              "      <td>54839</td>\n",
              "      <td>548390</td>\n",
              "      <td>548390</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>33258.jpeg</td>\n",
              "      <td>33258</td>\n",
              "      <td>332580</td>\n",
              "      <td>332580</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>00460.jpeg</td>\n",
              "      <td>00460</td>\n",
              "      <td>004600</td>\n",
              "      <td>004600</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>93258.jpeg</td>\n",
              "      <td>93258</td>\n",
              "      <td>932580</td>\n",
              "      <td>932580</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>64043.jpeg</td>\n",
              "      <td>64043</td>\n",
              "      <td>640430</td>\n",
              "      <td>640430</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>43429.jpeg</td>\n",
              "      <td>43429</td>\n",
              "      <td>434290</td>\n",
              "      <td>434290</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>22984.jpeg</td>\n",
              "      <td>22984</td>\n",
              "      <td>229840</td>\n",
              "      <td>229840</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>64053.jpeg</td>\n",
              "      <td>64053</td>\n",
              "      <td>640530</td>\n",
              "      <td>640530</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>83635.jpeg</td>\n",
              "      <td>83635</td>\n",
              "      <td>836350</td>\n",
              "      <td>836350</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>22990.jpeg</td>\n",
              "      <td>22990</td>\n",
              "      <td>229900</td>\n",
              "      <td>229900</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>64268.jpeg</td>\n",
              "      <td>64268</td>\n",
              "      <td>642680</td>\n",
              "      <td>642680</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>00493.jpeg</td>\n",
              "      <td>00493</td>\n",
              "      <td>004930</td>\n",
              "      <td>004930</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>64088.jpeg</td>\n",
              "      <td>64088</td>\n",
              "      <td>640880</td>\n",
              "      <td>640880</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>64066.jpeg</td>\n",
              "      <td>64066</td>\n",
              "      <td>640660</td>\n",
              "      <td>640660</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        filename  output  output0  result  Compare\n",
              "0     43453.jpeg   43453   434530  434530     True\n",
              "1     00424.jpeg   00424   004240  004240     True\n",
              "2     43432.jpeg   43432   434320  434320     True\n",
              "3     54826.jpeg   54826   548260  548260     True\n",
              "4     00422.jpeg   00422   004220  000220    False\n",
              "5     83838.jpeg   83838   838380  838380     True\n",
              "6     83646.jpeg   83646   836460  836460     True\n",
              "7     00495.jpeg   00495   004950  004950     True\n",
              "8     64063.jpeg   64063   640630  640630     True\n",
              "9    022986.jpeg  022986  0229860  022986     True\n",
              "10    83690.jpeg   83690   836900  836900     True\n",
              "11    54846.jpeg   54846   548460  548460     True\n",
              "12    93243.jpeg   93243   932430  932430     True\n",
              "13    54854.jpeg   54854   548540  548540     True\n",
              "14    83809.jpeg   83809   838090  838090     True\n",
              "15    93265.jpeg   93265   932650  932650     True\n",
              "16    64269.jpeg   64269   642690  642690     True\n",
              "17    00449.jpeg   00449   004490  004490     True\n",
              "18    83665.jpeg   83665   836650  836650     True\n",
              "19    64085.jpeg   64085   640850  640850     True\n",
              "20    33236.jpeg   33236   332360  332360     True\n",
              "21    22964.jpeg   22964   229640  229640     True\n",
              "22    83830.jpeg   83830   838300  838300     True\n",
              "23   093302.jpeg  093302  0933020  093302     True\n",
              "24    93259.jpeg   93259   932590  932590     True\n",
              "25    23048.jpeg   23048   230480  230480     True\n",
              "26    23020.jpeg   23020   230200  230200     True\n",
              "27    43489.jpeg   43489   434890  434890     True\n",
              "28    64095.jpeg   64095   640950  640950     True\n",
              "29    83689.jpeg   83689   836890  836890     True\n",
              "30    00488.jpeg   00488   004880  004880     True\n",
              "31    93329.jpeg   93329   933290  933290     True\n",
              "32    43425.jpeg   43425   434250  434250     True\n",
              "33    93264.jpeg   93264   932640  932640     True\n",
              "34    83803.jpeg   83803   838030  838030     True\n",
              "35    93253.jpeg   93253   932530  932530     True\n",
              "36    00448.jpeg   00448   004480  004480     True\n",
              "37    83626.jpeg   83626   836260  836260     True\n",
              "38    64220.jpeg   64220   642200  642200     True\n",
              "39    23034.jpeg   23034   230340  230340     True\n",
              "40    33259.jpeg   33259   332590  332590     True\n",
              "41    93248.jpeg   93248   932480  932480     True\n",
              "42    33293.jpeg   33293   332930  332930     True\n",
              "43    23042.jpeg   23042   230420  230420     True\n",
              "44    43459.jpeg   43459   434590  454590    False\n",
              "45    00408.jpeg   00408   004080  004080     True\n",
              "46    93295.jpeg   93295   932950  932950     True\n",
              "47    43493.jpeg   43493   434930  434930     True\n",
              "48   083640.jpeg  083640  0836400  083640     True\n",
              "49    22986.jpeg   22986   229860  229860     True\n",
              "50    33265.jpeg   33265   332650  332650     True\n",
              "51    83836.jpeg   83836   838360  838360     True\n",
              "52    93234.jpeg   93234   932340  932340     True\n",
              "53    43435.jpeg   43435   434350  434350     True\n",
              "54    22969.jpeg   22969   229690  229690     True\n",
              "55    83834.jpeg   83834   838340  838340     True\n",
              "56    43436.jpeg   43436   434360  434360     True\n",
              "57    64245.jpeg   64245   642450  642450     True\n",
              "58    54836.jpeg   54836   548360  548360     True\n",
              "59    33283.jpeg   33283   332830  332830     True\n",
              "60    54850.jpeg   54850   548500  548500     True\n",
              "61    83630.jpeg   83630   836300  836300     True\n",
              "62    43430.jpeg   43430   434300  434300     True\n",
              "63    64064.jpeg   64064   640640  640640     True\n",
              "64    00485.jpeg   00485   004850  004850     True\n",
              "65    33252.jpeg   33252   332520  332520     True\n",
              "66    93288.jpeg   93288   932880  932880     True\n",
              "67    43466.jpeg   43466   434660  434660     True\n",
              "68    00426.jpeg   00426   004260  004260     True\n",
              "69    43409.jpeg   43409   434090  434090     True\n",
              "70   054830.jpeg  054830  0548300  054830     True\n",
              "71   064084.jpeg  064084  0640840  064084     True\n",
              "72   064068.jpeg  064068  0640680  064068     True\n",
              "73    00499.jpeg   00499   004990  004990     True\n",
              "74    43452.jpeg   43452   434520  434520     True\n",
              "75    23049.jpeg   23049   230490  230490     True\n",
              "76    00400.jpeg   00400   004000  004000     True\n",
              "77    23036.jpeg   23036   230360  230360     True\n",
              "78    43445.jpeg   43445   434450  434450     True\n",
              "79    83642.jpeg   83642   836420  836420     True\n",
              "80    93266.jpeg   93266   932660  932660     True\n",
              "81    00450.jpeg   00450   004500  004500     True\n",
              "82    83832.jpeg   83832   838320  838320     True\n",
              "83    43485.jpeg   43485   434850  434850     True\n",
              "84    64054.jpeg   64054   640540  640540     True\n",
              "85   033259.jpeg  033259  0332590  033259     True\n",
              "86    93323.jpeg   93323   933230  933230     True\n",
              "87    43458.jpeg   43458   434580  434580     True\n",
              "88    22988.jpeg   22988   229880  229880     True\n",
              "89    00462.jpeg   00462   004620  004620     True\n",
              "90    93300.jpeg   93300   933000  933000     True\n",
              "91    23055.jpeg   23055   230550  230550     True\n",
              "92    64243.jpeg   64243   642430  642430     True\n",
              "93    93285.jpeg   93285   932850  932850     True\n",
              "94    54839.jpeg   54839   548390  548390     True\n",
              "95    33258.jpeg   33258   332580  332580     True\n",
              "96    00460.jpeg   00460   004600  004600     True\n",
              "97    93258.jpeg   93258   932580  932580     True\n",
              "98    64043.jpeg   64043   640430  640430     True\n",
              "99    43429.jpeg   43429   434290  434290     True\n",
              "100   22984.jpeg   22984   229840  229840     True\n",
              "101   64053.jpeg   64053   640530  640530     True\n",
              "102   83635.jpeg   83635   836350  836350     True\n",
              "103   22990.jpeg   22990   229900  229900     True\n",
              "104   64268.jpeg   64268   642680  642680     True\n",
              "105   00493.jpeg   00493   004930  004930     True\n",
              "106   64088.jpeg   64088   640880  640880     True\n",
              "107   64066.jpeg   64066   640660  640660     True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "metadata": {
        "id": "IiI1lB8IFeFw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}